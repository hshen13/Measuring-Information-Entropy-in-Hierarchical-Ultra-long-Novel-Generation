{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad0d646-213d-4cd8-8800-e735b6df82bf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # ============================================================\n",
    "# # ğŸ“š å…¨æµç¨‹æ¨¡å—ï¼ˆDeepSeek + OpenRouter/Claude 3.7 åŒåç«¯ï¼‰\n",
    "# #   1. æ‹†ç« èŠ‚ split_novels()\n",
    "# #   2. æ‰¹é‡ LLM åˆ†æ process()   â†’ ç« çº§ *_processed.txt\n",
    "# #   3. æ‰©å±•ï¼šprovider å¯é€‰ \"deepseek\" / \"openrouter\"\n",
    "# #      - ä¸¤ç«¯å‡æ”¯æŒ response_format={\"type\":\"json_object\"}\n",
    "# # ============================================================\n",
    "\n",
    "# # â”€â”€ å®‰è£…å¿…éœ€åŒ… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# !pip -q install --upgrade openai tqdm chardet pandas matplotlib jieba networkx requests\n",
    "\n",
    "# # â”€â”€ é€šç”¨åº“ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# import os, re, json, logging, unicodedata, chardet, requests\n",
    "# from pathlib import Path\n",
    "# from typing import List, Dict, Tuple\n",
    "# from collections import defaultdict\n",
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "# from tqdm.auto import tqdm\n",
    "\n",
    "# # â”€â”€ DeepSeek / OpenRouter é…ç½® â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# class Provider(str):\n",
    "#     DEEPSEEK   = \"deepseek\"\n",
    "#     OPENROUTER = \"openrouter\"\n",
    "\n",
    "# DEEPSEEK_API_KEY  = os.getenv(\"DEEPSEEK_API_KEY\")   or \"your-default-api-key\"\n",
    "# DEEPSEEK_URL      = \"https://api.deepseek.com\"\n",
    "# DEEPSEEK_MODEL    = \"deepseek-chat\"\n",
    "\n",
    "# OPENROUTER_API_KEY= os.getenv(\"OPENROUTER_API_KEY\") or \"your-default-api-key\"\n",
    "# OPENROUTER_URL    = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "# OPENROUTER_MODEL  = \"anthropic/claude-3.7-sonnet\"\n",
    "\n",
    "# import openai                                # åªç»™ DeepSeek ç”¨\n",
    "# deep_client = openai.OpenAI(api_key=DEEPSEEK_API_KEY, base_url=DEEPSEEK_URL)\n",
    "\n",
    "# logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "\n",
    "# # ============================================================\n",
    "# # 1ï¸âƒ£ æ‹†ç« èŠ‚ split_novels()\n",
    "# # ============================================================\n",
    "# _CHAPTER_PAT = re.compile(\n",
    "#     r\"\"\"\n",
    "#     ^\\s*(\n",
    "#         ç¬¬[\\dé›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡]+\\s*[ç« èŠ‚å·å›]\\s* |\n",
    "#         [é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡]{1,4}[\\.ï¼ã€\\s]+ |\n",
    "#         (?:Chapter|CHAPTER)\\s+\\d+               |\n",
    "#         \\d{1,3}[\\.ï¼ã€]\\s*                      |\n",
    "#         \\d{1,3}\\s+\n",
    "#     )\\s*(.*?)$\n",
    "#     \"\"\", re.MULTILINE | re.IGNORECASE | re.VERBOSE\n",
    "# )\n",
    "\n",
    "# def _safe_name(s: str) -> str:\n",
    "#     s = unicodedata.normalize(\"NFKC\", s)\n",
    "#     s = re.sub(r\"[\\r\\n\\t]+\", \" \", s)\n",
    "#     s = re.sub(r'[\\\\/:*?\"<>|]', \"_\", s)\n",
    "#     s = re.sub(r\"\\s+\", \"\", s)\n",
    "#     return s[:80] or \"æœªçŸ¥\"\n",
    "\n",
    "# def _auto_decode(path: Path) -> str:\n",
    "#     raw = path.read_bytes()\n",
    "#     enc = chardet.detect(raw)[\"encoding\"] or \"utf-8\"\n",
    "#     return raw.decode(enc, errors=\"ignore\")\n",
    "\n",
    "# def split_novels(input_dir: str, output_base: str | None = None) -> Dict[str, List[Path]]:\n",
    "#     in_p, out_p = Path(input_dir), Path(output_base or f\"{input_dir.rstrip('/')}_chapters\")\n",
    "#     out_p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     novels: Dict[str, List[Path]] = {}\n",
    "#     for txt in in_p.glob(\"*.txt\"):\n",
    "#         book_dir = out_p / _safe_name(txt.stem); book_dir.mkdir(exist_ok=True)\n",
    "#         data = _auto_decode(txt)\n",
    "#         ms = list(_CHAPTER_PAT.finditer(data))\n",
    "#         blocks = [(ms[i].group().strip(),\n",
    "#                    data[ms[i].end():ms[i+1].start()] if i+1<len(ms) else data[ms[i].end():])\n",
    "#                   for i in range(len(ms))] if ms else \\\n",
    "#                  [(f\"æœªçŸ¥ç« èŠ‚{i+1}\", data[s:s+5000]) for i,s in enumerate(range(0,len(data),5000))]\n",
    "#         paths=[]\n",
    "#         for i,(title,body) in enumerate(blocks,1):\n",
    "#             p=book_dir/f\"{i:03d}_{_safe_name(title)}.txt\"\n",
    "#             p.write_text(body.strip(),encoding=\"utf-8\"); paths.append(p)\n",
    "#         novels[book_dir.name]=paths\n",
    "#         logging.info(f\"ã€Š{txt.stem}ã€‹â†’ {len(paths)} ç« \")\n",
    "#     return novels\n",
    "# #============================================================ \n",
    "# # 2ï¸âƒ£ ç»Ÿä¸€ LLM è°ƒç”¨ _call_llm()\n",
    "# # ============================================================\n",
    "# def _call_llm(prompt:str, content:str,\n",
    "#               *, provider:Provider=Provider.DEEPSEEK,\n",
    "#               json_mode:bool=False) -> str:\n",
    "#     if provider==Provider.DEEPSEEK:\n",
    "#         rsp = deep_client.chat.completions.create(\n",
    "#             model=DEEPSEEK_MODEL,\n",
    "#             messages=[{\"role\":\"system\",\"content\":prompt},\n",
    "#                       {\"role\":\"user\",\"content\":content}],\n",
    "#             temperature=0.3,\n",
    "#             max_tokens=4096,\n",
    "#             response_format={\"type\":\"json_object\"} if json_mode else None\n",
    "#         )\n",
    "#         return rsp.choices[0].message.content.strip()\n",
    "\n",
    "#     if provider==Provider.OPENROUTER:\n",
    "#         body = {\n",
    "#             \"model\": OPENROUTER_MODEL,\n",
    "#             \"messages\":[\n",
    "#                 {\"role\":\"system\",\"content\":prompt},\n",
    "#                 {\"role\":\"user\",\"content\":content}\n",
    "#             ]\n",
    "#         }\n",
    "#         if json_mode:\n",
    "#             body[\"response_format\"]={\"type\":\"json_object\"}\n",
    "#         r = requests.post(OPENROUTER_URL,\n",
    "#                           headers={\n",
    "#                               \"Authorization\":f\"Bearer {OPENROUTER_API_KEY}\",\n",
    "#                               \"Content-Type\":\"application/json\"\n",
    "#                           },\n",
    "#                           data=json.dumps(body))\n",
    "#         if r.status_code!=200:\n",
    "#             raise RuntimeError(f\"OpenRouter {r.status_code}: {r.text[:200]}\")\n",
    "#         return r.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "#     raise ValueError(\"Unknown provider\")\n",
    "\n",
    "# # ============================================================\n",
    "# # 3ï¸âƒ£ process_chapters() / process()\n",
    "# # ============================================================\n",
    "# def process_chapters(chapter_files: List[Path],\n",
    "#                      prompt: str,\n",
    "#                      *,\n",
    "#                      provider:Provider = Provider.DEEPSEEK,\n",
    "#                      json_mode: bool = True,\n",
    "#                      workers:int = 4,\n",
    "#                      suffix=\"_processed.txt\"):\n",
    "#     def _run(fp:Path):\n",
    "#         res=_call_llm(prompt,fp.read_text(encoding=\"utf-8\"),\n",
    "#                       provider=provider,json_mode=json_mode)\n",
    "#         out=fp.with_name(fp.stem+suffix); out.write_text(res,encoding=\"utf-8\")\n",
    "#         return out\n",
    "#     with ThreadPoolExecutor(max_workers=workers) as ex:\n",
    "#         list(ex.map(_run, chapter_files))\n",
    "\n",
    "# def _gather(root:Path)->List[Path]:\n",
    "#     return sorted(root.rglob(\"*.txt\"))\n",
    "\n",
    "# def process(chapter_root:str,*,\n",
    "#             prompt:str,\n",
    "#             provider:Provider=Provider.DEEPSEEK,\n",
    "#             out_dir:str=\"/content/json_results\",\n",
    "#             json_mode:bool=True,\n",
    "#             chapters:Tuple[int,int]|None=None):\n",
    "#     s,e = chapters or (1,float(\"inf\"))\n",
    "#     root, out_base = Path(chapter_root), Path(out_dir); out_base.mkdir(parents=True,exist_ok=True)\n",
    "#     books = [d for d in root.iterdir() if d.is_dir()] or [root]\n",
    "\n",
    "#     for book in tqdm(books, desc=\"ğŸ“š ä¹¦åº“\"):\n",
    "#         files=[p for p in _gather(book) if s<=int(p.stem.split(\"_\")[0])<=e]\n",
    "#         for group_idx in range(0,len(files),10):\n",
    "#             grp=files[group_idx:group_idx+10]\n",
    "#             if not grp: continue\n",
    "#             start=int(grp[0].stem[:3]); end=start+len(grp)-1\n",
    "#             sub=out_base/book.name/f\"{start:03d}-{end:03d}\"; sub.mkdir(parents=True,exist_ok=True)\n",
    "#             todo=[p for p in grp if not (sub/f\"{p.stem}_processed.txt\").exists()]\n",
    "#             if todo:\n",
    "#                 process_chapters(todo,prompt,\n",
    "#                                  provider=provider,json_mode=json_mode)\n",
    "#                 for tp in todo:\n",
    "#                     (sub/f\"{tp.stem}_processed.txt\").write_text(\n",
    "#                         (tp.parent/f\"{tp.stem}_processed.txt\").read_text(encoding=\"utf-8\"),\n",
    "#                         encoding=\"utf-8\")\n",
    "#                     (tp.parent/f\"{tp.stem}_processed.txt\").unlink()\n",
    "#     print(f\"âœ… è¾“å‡ºç›®å½•ï¼š{out_base}\")\n",
    "\n",
    "\n",
    "# def run_analysis(\n",
    "#     chapter_root: str,\n",
    "#     *,\n",
    "#     prompt: str,\n",
    "#     provider: Provider = Provider.DEEPSEEK,\n",
    "#     out_dir: str = \"/content/json_results\",\n",
    "#     mode: str | tuple[int, int] = \"full\",   # â† å…³é”®å‚æ•°\n",
    "#     json_mode: bool = True,\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     mode ç”¨æ³•\n",
    "#     --------\n",
    "#     â€¢ \"full\"          â†’ åˆ†ææ•´æœ¬\n",
    "#     â€¢ 100             â†’ åªåˆ†æ 1~100 ç« \n",
    "#     â€¢ (51, 150)       â†’ åˆ†æ 51~150 ç« \n",
    "#     \"\"\"\n",
    "#     if mode == \"full\":\n",
    "#         chapters = None\n",
    "#     elif isinstance(mode, int):\n",
    "#         chapters = (1, mode)\n",
    "#     elif isinstance(mode, tuple) and len(mode) == 2:\n",
    "#         chapters = mode\n",
    "#     else:\n",
    "#         raise ValueError(\"mode å¿…é¡»æ˜¯ 'full'ã€æ•´æ•° Nï¼Œæˆ– (start, end) å…ƒç»„\")\n",
    "\n",
    "#     process(\n",
    "#         chapter_root=chapter_root,\n",
    "#         prompt=prompt,\n",
    "#         provider=provider,\n",
    "#         out_dir=out_dir,\n",
    "#         json_mode=json_mode,\n",
    "#         chapters=chapters\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09090f2f-f67d-40c6-8a75-373f657b4947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ============================================================\n",
    "# # ğŸ“Š å°è¯´ç« èŠ‚ JSON ç»Ÿè®¡ï¼ˆåº“çº§æ‰¹é‡ç‰ˆï¼ŒåŒºé—´å‹ç¼© + ä¿å­˜ï¼‰\n",
    "# # ============================================================\n",
    "# import json, re\n",
    "# from pathlib import Path\n",
    "# from collections import defaultdict\n",
    "# from typing import Dict, List, Tuple\n",
    "\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from IPython.display import display\n",
    "\n",
    "# # ---------- å·¥å…· ----------\n",
    "# _DIGIT_RE = re.compile(r\"(\\d{3})\")\n",
    "# def _extract_no(p: Path) -> int:\n",
    "#     m = _DIGIT_RE.search(p.stem) or re.match(r\"(\\d{3})-\", p.parent.name)\n",
    "#     return int(m.group(1)) if m else -1\n",
    "\n",
    "# def _compress(nums: List[int]) -> List[str]:\n",
    "#     if not nums: return []\n",
    "#     nums = sorted(nums)\n",
    "#     res, s, prev = [], nums[0], nums[0]\n",
    "#     for n in nums[1:]:\n",
    "#         if n == prev + 1: prev = n; continue\n",
    "#         res.append(f\"{s}-{prev}\" if s != prev else f\"{s}\")\n",
    "#         s = prev = n\n",
    "#     res.append(f\"{s}-{prev}\" if s != prev else f\"{s}\")\n",
    "#     return res\n",
    "\n",
    "# # ---------- å•æœ¬ ----------\n",
    "# # ---------- ä¿®æ­£ç‰ˆ stat_book ----------\n",
    "# # ---------- å·¥å…·ï¼šå‡ºç°æ˜ å°„ ----------\n",
    "# def _map_occ(df: pd.DataFrame, col: str) -> Dict[str, List[int]]:\n",
    "#     mp = defaultdict(list)\n",
    "#     for _, row in df.iterrows():\n",
    "#         for item in row[col]:\n",
    "#             mp[item].append(row[\"chapter\"])\n",
    "#     return mp\n",
    "\n",
    "# def _build(mp: Dict[str,List[int]], *, min_chaps=1, top_n=20):\n",
    "#     data = [\n",
    "#         {\"name\": k, \"count\": len(v), \"chapters\": _compress(v)}\n",
    "#         for k, v in mp.items() if len(v) >= min_chaps\n",
    "#     ]\n",
    "#     return sorted(data, key=lambda x: x[\"count\"], reverse=True)[:top_n]\n",
    "\n",
    "# # ---------- å•æœ¬ç»Ÿè®¡ ----------\n",
    "# def stat_book(book_dir: str | Path,\n",
    "#               *,\n",
    "#               min_chapters: int = 3,\n",
    "#               top_n: int = 30,\n",
    "#               show_plot: bool = False) -> dict:\n",
    "#     \"\"\"å¯¹å•æœ¬å°è¯´ç›®å½•ç”Ÿæˆç»Ÿè®¡ dict\"\"\"\n",
    "#     book_dir = Path(book_dir)\n",
    "#     rows, auto_idx = [], 1\n",
    "\n",
    "#     for p in sorted(book_dir.rglob(\"*_processed.txt\")):\n",
    "#         chap_no = _extract_no(p)\n",
    "#         if chap_no == -1:\n",
    "#             chap_no, auto_idx = auto_idx, auto_idx + 1   # é¡ºåºè¡¥å·\n",
    "#         try:\n",
    "#             data = json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "#         except json.JSONDecodeError:\n",
    "#             print(f\"âš ï¸ è·³è¿‡æ— æ•ˆ JSON: {p}\"); continue\n",
    "\n",
    "#         rows.append({\n",
    "#             \"chapter\":   chap_no,\n",
    "#             \"characters\": data.get(\"å‡ºç°äººç‰©\", []),\n",
    "#             \"scenes\":     data.get(\"å‡ºç°åœºæ™¯\", []),\n",
    "#             \"props\":      data.get(\"å‡ºç°é“å…·\", []),\n",
    "#             \"setup\":      data.get(\"ä¼ç¬”_è®¾ä¸‹\", []),\n",
    "#             \"recycle\":    data.get(\"ä¼ç¬”_å›æ”¶\", []),\n",
    "#         })\n",
    "\n",
    "#     if not rows:\n",
    "#         raise ValueError(f\"{book_dir} æ— æœ‰æ•ˆ *_processed.txt\")\n",
    "\n",
    "#     df = pd.DataFrame(rows).sort_values(\"chapter\").reset_index(drop=True)  # â† è¿™è¡Œä¹‹å‰ç¼ºå¤±\n",
    "\n",
    "#     char_map = _map_occ(df, \"characters\")\n",
    "#     major    = {k: v for k, v in char_map.items() if len(v) >= min_chapters}\n",
    "\n",
    "#     summary = {\n",
    "#         \"ä¸»è¦è§’è‰²\": _build(major, min_chaps=min_chapters, top_n=top_n),\n",
    "#         \"åœºæ™¯\":     _build(_map_occ(df, \"scenes\"),  top_n=top_n),\n",
    "#         \"é“å…·\":     _build(_map_occ(df, \"props\"),   top_n=top_n),\n",
    "#         \"ä¼ç¬”_è®¾ä¸‹\": _build(_map_occ(df, \"setup\"),  top_n=top_n),\n",
    "#         \"ä¼ç¬”_å›æ”¶\": _build(_map_occ(df, \"recycle\"),top_n=top_n),\n",
    "#     }\n",
    "\n",
    "#     if show_plot and major:\n",
    "#         plt.figure(figsize=(10, 4))\n",
    "#         for c, chs in major.items():\n",
    "#             plt.plot(df[\"chapter\"], [1 if n in chs else 0 for n in df[\"chapter\"]], label=c)\n",
    "#         plt.xlabel(\"ç« èŠ‚å·\"); plt.ylabel(\"å‡ºç°(1)\"); plt.title(book_dir.name); plt.legend()\n",
    "#         plt.show()\n",
    "\n",
    "#     return summary\n",
    "\n",
    "# # ---------- æ•´åº“æ‰¹é‡ ----------\n",
    "# def stat_library(root_dir: str | Path,\n",
    "#                  out_root: str | Path = \"/content/novel_stats\",\n",
    "#                  *, min_chapters: int = 3,\n",
    "#                  top_n: int = 10,\n",
    "#                  show_plot: bool = False):\n",
    "#     root_dir = Path(root_dir); out_root = Path(out_root)\n",
    "#     out_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     for book in root_dir.iterdir():\n",
    "#         if not book.is_dir(): continue\n",
    "#         try:\n",
    "#             res = stat_book(book,\n",
    "#                             min_chapters=min_chapters,\n",
    "#                             top_n=top_n,\n",
    "#                             show_plot=show_plot)\n",
    "#         except ValueError as e:\n",
    "#             print(e); continue\n",
    "\n",
    "#         out_file = out_root / book.name / f\"{book.name}_stats.json\"\n",
    "#         out_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "#         out_file.write_text(json.dumps(res, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "#         print(f\"âœ… å†™å…¥ {out_file.relative_to(out_root)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4220f539-97ff-42ca-a829-502c2b15018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. æ‹†ç« èŠ‚\n",
    "# # split_novels(\"/content/novels\", \"/content/novels_chapters\")\n",
    "\n",
    "# # 2. å®šä¹‰ç« èŠ‚åˆ†æ Prompt,æœ‰ä¸¤ç§ï¼Œjsonçš„å’Œplainçš„ï¼Œ400å­—çš„å’Œ800å­—çš„ï¼Œ200å­—çš„ã€‚\n",
    "# # prompt_chapter_json = r\"\"\"\n",
    "# # ä½ æ˜¯ä¸€ä½ä¸“ä¸šæ–‡å­¦ç¼–è¾‘ã€‚è¯·é˜…è¯»æˆ‘æ¥ä¸‹æ¥æä¾›çš„ã€ç« èŠ‚å…¨æ–‡ã€‘ï¼ŒæŒ‰ç…§ä¸‹åˆ—è¦æ±‚ç”Ÿæˆ **400-500 å­—** çš„è¯¦ç»†ç« èŠ‚åˆ†æï¼Œå¹¶ **ä»…ä»¥ JSON æ ¼å¼** è¿”å›ç»“æœï¼ˆä¸¥ç¦è¾“å‡ºä»»ä½•è§£é‡Šæˆ– Markdownï¼‰ã€‚\n",
    "\n",
    "# # JSON é¡¶å±‚å­—æ®µä¸è¦æ±‚ï¼š\n",
    "# # {\n",
    "# #   \"ç« èŠ‚å®šä½å¯¼è¯­\":         \"<100-200 å­—ï¼Œè¯´æ˜ç« èŠ‚åœ¨æ•´ä¹¦ä¸­çš„ä½ç½®å’Œä½œç”¨>\",\n",
    "# #   \"æƒ…èŠ‚æ‘˜è¦å¯¼è¯­\":         \"<200-300 å­—ï¼Œæ¦‚æ‹¬è¯¥ç« èŠ‚çš„ä¸»è¦å†…å®¹,è¯·å°½é‡æŠŠå‰§æƒ…è®²è¿°å®Œæ•´>\",\n",
    "# #   \"æƒ…æ„Ÿä¸èŠ‚å¥å¯¼è¯­\":       \"<200-300 å­—ï¼Œåˆ†æç« èŠ‚çš„æƒ…æ„Ÿå’ŒèŠ‚å¥å˜åŒ–>\",\n",
    "# #   \"å…³é”®åœºæ™¯åˆ†æ\":         \"<200-400 å­—ï¼Œæ·±å…¥åˆ†æç« èŠ‚ä¸­çš„é‡è¦åœºæ™¯>\",\n",
    "# #   \"äººç‰©è§’è‰²å˜åŒ–\":         \"<200-300 å­—ï¼Œåˆ†æç« èŠ‚ä¸­äººç‰©çš„è¡¨ç°å’Œå˜åŒ–>\",\n",
    "# #   \"æƒ…æ„Ÿå¼ åŠ›å˜åŒ–\":         \"<100-200 å­—ï¼Œåˆ†æç« èŠ‚æƒ…æ„Ÿçš„èµ·ä¼>\",\n",
    "# #   \"èŠ‚å¥ä¸ç»“æ„è§‚å¯Ÿ\":       \"<100-200 å­—ï¼Œåˆ†æç« èŠ‚èŠ‚å¥ä¸æ•´ä¹¦ä¸»é¢˜å’Œæƒ…èŠ‚çš„å…³è”>\",\n",
    "# #   \"å‡ºç°äººç‰©\":             [\"è§’è‰²A\", \"è§’è‰²B\", ...],\n",
    "# #   \"å‡ºç°é“å…·\":             [\"é“å…·1\", \"é“å…·2\", ...],\n",
    "# #   \"å‡ºç°åœºæ™¯\":             [\"åœºæ™¯1\", \"åœºæ™¯2\"],\n",
    "# #   \"ä¼ç¬”_è®¾ä¸‹\":            [\"ä¼ç¬”1 æè¿°\", \"ä¼ç¬”2 æè¿°\"],\n",
    "# #   \"ä¼ç¬”_å›æ”¶\":            [\"ä¼ç¬”A å›æ”¶æ–¹å¼\", ...]\n",
    "# # }\n",
    "\n",
    "# # ä¸¥æ ¼è¦æ±‚ï¼š\n",
    "# # 1. æ–‡æœ¬å­—æ®µé¡»ä¸ºå®Œæ•´ä¸­æ–‡æ®µè½ï¼›å­—æ•°å¿…é¡»è½åœ¨åŒºé—´å†…ã€‚\n",
    "# # 2. ä¸Šè¿° 12 ä¸ªé”®ä¸€ä¸ªéƒ½ä¸èƒ½å°‘ï¼Œä¹Ÿä¸èƒ½å¤šã€‚\n",
    "# # 3. â€œå‡ºç°äººç‰© / é“å…· / åœºæ™¯ / ä¼ç¬”â€ ç”¨ JSON æ•°ç»„ã€‚\n",
    "# # 4. å¯å¼•ç”¨åŸæ–‡â‰¤10%ï¼Œéœ€åŠ å¼•å·æ³¨æ˜æ®µè½å·ã€‚\n",
    "# # ã€ç« èŠ‚å…¨æ–‡ã€‘ï¼š\n",
    "# # \"\"\"\n",
    "\n",
    "# # prompt_chapter_json_100000_json = r\"\"\"\n",
    "# # ä½ æ˜¯ä¸€ä½ä¸“ä¸šæ–‡å­¦ç¼–è¾‘ã€‚è¯·é˜…è¯»æˆ‘æ¥ä¸‹æ¥æä¾›çš„ã€ç« èŠ‚å…¨æ–‡ã€‘ï¼ŒæŒ‰ç…§ä¸‹åˆ—è¦æ±‚ç”Ÿæˆ **400-500 å­—** çš„è¯¦ç»†ç« èŠ‚åˆ†æï¼Œå¹¶ **ä»…ä»¥ JSON æ ¼å¼** è¿”å›ç»“æœï¼ˆä¸¥ç¦è¾“å‡ºä»»ä½•è§£é‡Šæˆ– Markdownï¼‰ã€‚\n",
    "\n",
    "# # JSON é¡¶å±‚å­—æ®µä¸è¦æ±‚ï¼š\n",
    "# # {\n",
    "# #   \"ç« èŠ‚å®šä½å¯¼è¯­\":         \"<40 å­—ï¼Œè¯´æ˜ç« èŠ‚åœ¨æ•´ä¹¦ä¸­çš„ä½ç½®å’Œä½œç”¨>\",\n",
    "# #   \"æƒ…èŠ‚æ‘˜è¦å¯¼è¯­\":         \"<40 å­—ï¼Œæ¦‚æ‹¬è¯¥ç« èŠ‚çš„ä¸»è¦å†…å®¹,è¯·å°½é‡æŠŠå‰§æƒ…è®²è¿°å®Œæ•´>\",\n",
    "# #   \"æƒ…æ„Ÿä¸èŠ‚å¥å¯¼è¯­\":       \"<40 å­—ï¼Œåˆ†æç« èŠ‚çš„æƒ…æ„Ÿå’ŒèŠ‚å¥å˜åŒ–>\",\n",
    "# #   \"å…³é”®åœºæ™¯åˆ†æ\":         \"<40 å­—ï¼Œæ·±å…¥åˆ†æç« èŠ‚ä¸­çš„é‡è¦åœºæ™¯>\",\n",
    "# #   \"äººç‰©è§’è‰²å˜åŒ–\":         \"<40 å­—ï¼Œåˆ†æç« èŠ‚ä¸­äººç‰©çš„è¡¨ç°å’Œå˜åŒ–>\",\n",
    "# #   \"æƒ…æ„Ÿå¼ åŠ›å˜åŒ–\":         \"<40 å­—ï¼Œåˆ†æç« èŠ‚æƒ…æ„Ÿçš„èµ·ä¼>\",\n",
    "# #   \"èŠ‚å¥ä¸ç»“æ„è§‚å¯Ÿ\":       \"<40 å­—ï¼Œåˆ†æç« èŠ‚èŠ‚å¥ä¸æ•´ä¹¦ä¸»é¢˜å’Œæƒ…èŠ‚çš„å…³è”>\",\n",
    "# #   \"å‡ºç°äººç‰©\":             [\"è§’è‰²A\", \"è§’è‰²B\", ...],\n",
    "# #   \"å‡ºç°é“å…·\":             [\"é“å…·1\", \"é“å…·2\", ...],\n",
    "# #   \"å‡ºç°åœºæ™¯\":             [\"åœºæ™¯1\", \"åœºæ™¯2\"],\n",
    "# #   \"ä¼ç¬”_è®¾ä¸‹\":            [\"ä¼ç¬”1 æè¿°\", \"ä¼ç¬”2 æè¿°\"],\n",
    "# #   \"ä¼ç¬”_å›æ”¶\":            [\"ä¼ç¬”A å›æ”¶æ–¹å¼\", ...]\n",
    "# # }\n",
    "\n",
    "# # ä¸¥æ ¼è¦æ±‚ï¼š\n",
    "# # 1. æ–‡æœ¬å­—æ®µé¡»ä¸ºå®Œæ•´ä¸­æ–‡æ®µè½ï¼›å­—æ•°å¿…é¡»è½åœ¨åŒºé—´å†…ã€‚\n",
    "# # 2. ä¸Šè¿° 12 ä¸ªé”®ä¸€ä¸ªéƒ½ä¸èƒ½å°‘ï¼Œä¹Ÿä¸èƒ½å¤šã€‚\n",
    "# # 3. â€œå‡ºç°äººç‰© / é“å…· / åœºæ™¯ / ä¼ç¬”â€ ç”¨ JSON æ•°ç»„ã€‚\n",
    "# # 4. å¯å¼•ç”¨åŸæ–‡â‰¤10%ï¼Œéœ€åŠ å¼•å·æ³¨æ˜æ®µè½å·ã€‚\n",
    "# # ã€ç« èŠ‚å…¨æ–‡ã€‘ï¼š\n",
    "# # \"\"\"\n",
    "\n",
    "\n",
    "# prompt_chapter_json_100000_json = r\"\"\"\n",
    "# ä½ æ˜¯ä¸€ä½ä¸“ä¸šæ–‡å­¦ç¼–è¾‘ã€‚è¯·é˜…è¯»æˆ‘æ¥ä¸‹æ¥æä¾›çš„ã€ç« èŠ‚å…¨æ–‡ã€‘ï¼ŒæŒ‰ç…§ä¸‹åˆ—è¦æ±‚ç”Ÿæˆæ€»è®¡ **400-500 å­—** çš„è¯¦ç»†ç« èŠ‚åˆ†æï¼Œå¹¶ **ä»…ä»¥ JSON æ ¼å¼** è¿”å›ç»“æœï¼ˆä¸¥ç¦è¾“å‡ºä»»ä½•è§£é‡Šæˆ– Markdownï¼‰ã€‚\n",
    "\n",
    "# JSON é¡¶å±‚å­—æ®µä¸è¦æ±‚ï¼š\n",
    "# {\n",
    "#   \"æƒ…èŠ‚æ‘˜è¦å¯¼è¯­\":         \"<400 å­—ï¼Œæ¦‚æ‹¬è¯¥ç« èŠ‚çš„ä¸»è¦å†…å®¹,è¯·å°½é‡æŠŠå‰§æƒ…è®²è¿°å®Œæ•´>\",\n",
    "#   \"å‡ºç°äººç‰©\":             [\"è§’è‰²A\", \"è§’è‰²B\", ...],\n",
    "#   \"å‡ºç°é“å…·\":             [\"é“å…·1\", \"é“å…·2\", ...],\n",
    "#   \"å‡ºç°åœºæ™¯\":             [\"åœºæ™¯1\", \"åœºæ™¯2\"],\n",
    "#   \"ä¼ç¬”_è®¾ä¸‹\":            [\"ä¼ç¬”1 æè¿°\", \"ä¼ç¬”2 æè¿°\"],\n",
    "#   \"ä¼ç¬”_å›æ”¶\":            [\"ä¼ç¬”A å›æ”¶æ–¹å¼\", ...]\n",
    "# }\n",
    "\n",
    "# ä¸¥æ ¼è¦æ±‚ï¼š\n",
    "# 1. æ–‡æœ¬å­—æ®µé¡»ä¸ºå®Œæ•´ä¸­æ–‡æ®µè½ï¼›å­—æ•°å¿…é¡»è½åœ¨åŒºé—´å†…ã€‚\n",
    "# 2. ä¸Šè¿° 6 ä¸ªé”®ä¸€ä¸ªéƒ½ä¸èƒ½å°‘ï¼Œä¹Ÿä¸èƒ½å¤šã€‚\n",
    "# 3. â€œå‡ºç°äººç‰© / é“å…· / åœºæ™¯ / ä¼ç¬”â€ ç”¨ JSON æ•°ç»„ã€‚\n",
    "# 4. å¯å¼•ç”¨åŸæ–‡â‰¤10%ï¼Œéœ€åŠ å¼•å·æ³¨æ˜æ®µè½å·ã€‚\n",
    "# ã€ç« èŠ‚å…¨æ–‡ã€‘ï¼š\n",
    "# \"\"\"\n",
    "\n",
    "# prompt_chapter_json_50000_json = r\"\"\"\n",
    "# ä½ æ˜¯ä¸€ä½ä¸“ä¸šæ–‡å­¦ç¼–è¾‘ã€‚è¯·é˜…è¯»æˆ‘æ¥ä¸‹æ¥æä¾›çš„ã€ç« èŠ‚å…¨æ–‡ã€‘ï¼ŒæŒ‰ç…§ä¸‹åˆ—è¦æ±‚ç”Ÿæˆæ€»è®¡ **200-250 å­—** çš„è¯¦ç»†ç« èŠ‚åˆ†æï¼Œå¹¶ **ä»…ä»¥ JSON æ ¼å¼** è¿”å›ç»“æœï¼ˆä¸¥ç¦è¾“å‡ºä»»ä½•è§£é‡Šæˆ– Markdownï¼‰ã€‚\n",
    "\n",
    "# JSON é¡¶å±‚å­—æ®µä¸è¦æ±‚ï¼š\n",
    "# {\n",
    "#   \"æƒ…èŠ‚æ‘˜è¦å¯¼è¯­\":         \"<200 å­—ï¼Œæ¦‚æ‹¬è¯¥ç« èŠ‚çš„ä¸»è¦å†…å®¹,è¯·å°½é‡æŠŠå‰§æƒ…è®²è¿°å®Œæ•´>\",\n",
    "#   \"å‡ºç°äººç‰©\":             [\"è§’è‰²A\", \"è§’è‰²B\", ...],\n",
    "#   \"å‡ºç°é“å…·\":             [\"é“å…·1\", \"é“å…·2\", ...],\n",
    "#   \"å‡ºç°åœºæ™¯\":             [\"åœºæ™¯1\", \"åœºæ™¯2\"],\n",
    "#   \"ä¼ç¬”_è®¾ä¸‹\":            [\"ä¼ç¬”1 æè¿°\", \"ä¼ç¬”2 æè¿°\"],\n",
    "#   \"ä¼ç¬”_å›æ”¶\":            [\"ä¼ç¬”A å›æ”¶æ–¹å¼\", ...]\n",
    "# }\n",
    "\n",
    "# ä¸¥æ ¼è¦æ±‚ï¼š\n",
    "# 1. æ–‡æœ¬å­—æ®µé¡»ä¸ºå®Œæ•´ä¸­æ–‡æ®µè½ï¼›å­—æ•°å¿…é¡»è½åœ¨åŒºé—´å†…ã€‚\n",
    "# 2. ä¸Šè¿° 6 ä¸ªé”®ä¸€ä¸ªéƒ½ä¸èƒ½å°‘ï¼Œä¹Ÿä¸èƒ½å¤šã€‚\n",
    "# 3. â€œå‡ºç°äººç‰© / é“å…· / åœºæ™¯ / ä¼ç¬”â€ ç”¨ JSON æ•°ç»„ã€‚\n",
    "# 4. å¯å¼•ç”¨åŸæ–‡â‰¤10%ï¼Œéœ€åŠ å¼•å·æ³¨æ˜æ®µè½å·ã€‚\n",
    "# ã€ç« èŠ‚å…¨æ–‡ã€‘ï¼š\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "# prompt_chapter_json_200000_json = r\"\"\"\n",
    "# ä½ æ˜¯ä¸€ä½ä¸“ä¸šæ–‡å­¦ç¼–è¾‘ã€‚è¯·é˜…è¯»æˆ‘æ¥ä¸‹æ¥æä¾›çš„ã€ç« èŠ‚å…¨æ–‡ã€‘ï¼ŒæŒ‰ç…§ä¸‹åˆ—è¦æ±‚ç”Ÿæˆæ€»è®¡ **700-800 å­—** çš„è¯¦ç»†ç« èŠ‚åˆ†æï¼Œå¹¶ **ä»…ä»¥ JSON æ ¼å¼** è¿”å›ç»“æœï¼ˆä¸¥ç¦è¾“å‡ºä»»ä½•è§£é‡Šæˆ– Markdownï¼‰ã€‚\n",
    "\n",
    "# JSON é¡¶å±‚å­—æ®µä¸è¦æ±‚ï¼š\n",
    "# {\n",
    "#   \"æƒ…èŠ‚æ‘˜è¦å¯¼è¯­\":         \"<700 å­—ï¼Œæ¦‚æ‹¬è¯¥ç« èŠ‚çš„ä¸»è¦å†…å®¹,è¯·å°½é‡æŠŠå‰§æƒ…è®²è¿°å®Œæ•´>\",\n",
    "#   \"å‡ºç°äººç‰©\":             [\"è§’è‰²A\", \"è§’è‰²B\", ...],\n",
    "#   \"å‡ºç°é“å…·\":             [\"é“å…·1\", \"é“å…·2\", ...],\n",
    "#   \"å‡ºç°åœºæ™¯\":             [\"åœºæ™¯1\", \"åœºæ™¯2\"],\n",
    "#   \"ä¼ç¬”_è®¾ä¸‹\":            [\"ä¼ç¬”1 æè¿°\", \"ä¼ç¬”2 æè¿°\"],\n",
    "#   \"ä¼ç¬”_å›æ”¶\":            [\"ä¼ç¬”A å›æ”¶æ–¹å¼\", ...]\n",
    "# }\n",
    "\n",
    "# ä¸¥æ ¼è¦æ±‚ï¼š\n",
    "# 1. æ–‡æœ¬å­—æ®µé¡»ä¸ºå®Œæ•´ä¸­æ–‡æ®µè½ï¼›å­—æ•°å¿…é¡»è½åœ¨åŒºé—´å†…ã€‚\n",
    "# 2. ä¸Šè¿° 6 ä¸ªé”®ä¸€ä¸ªéƒ½ä¸èƒ½å°‘ï¼Œä¹Ÿä¸èƒ½å¤šã€‚\n",
    "# 3. â€œå‡ºç°äººç‰© / é“å…· / åœºæ™¯ / ä¼ç¬”â€ ç”¨ JSON æ•°ç»„ã€‚\n",
    "# 4. å¯å¼•ç”¨åŸæ–‡â‰¤10%ï¼Œéœ€åŠ å¼•å·æ³¨æ˜æ®µè½å·ã€‚\n",
    "# ã€ç« èŠ‚å…¨æ–‡ã€‘ï¼š\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "# # 3. æ‰¹é‡åˆ†æï¼ˆåªå¤„ç† 1â€“100 ç« ï¼‰\n",
    "# # åªåˆ†æ 1â€“100 ç« \n",
    "# # process(\n",
    "# #     chapter_root=\"/content/novels_chapters\",\n",
    "# #     prompt=prompt_chapter_json,\n",
    "# #     out_dir=\"/content/json_results\",\n",
    "# #     json_mode=True,\n",
    "# #     chapters=(1, 10)\n",
    "# # )\n",
    "\n",
    "# # # 1) åˆ†æå‰ 150 ç« ï¼ˆDeepSeekï¼‰\n",
    "# run_analysis(\n",
    "#     chapter_root=\"/content/novels_chapters\",\n",
    "#     prompt=prompt_chapter_json_50000_json,\n",
    "#     provider=Provider.DEEPSEEK,\n",
    "#     out_dir=\"/content/json_results/50000_json\",\n",
    "#     mode=(1, 150)      # æŒ‡å®šåŒºé—´\n",
    "# )\n",
    "\n",
    "# run_analysis(\n",
    "#     chapter_root=\"/content/novels_chapters\",\n",
    "#     prompt=prompt_chapter_json_100000_json,\n",
    "#     provider=Provider.DEEPSEEK,\n",
    "#     out_dir=\"/content/json_results/100000_json\",\n",
    "#     mode=(1, 150)      # æŒ‡å®šåŒºé—´\n",
    "# )\n",
    "\n",
    "# run_analysis(\n",
    "#     chapter_root=\"/content/novels_chapters\",\n",
    "#     prompt=prompt_chapter_json_200000_json,\n",
    "#     provider=Provider.DEEPSEEK,\n",
    "#     out_dir=\"/content/json_results/200000_json\",\n",
    "#     mode=(1, 150)      # æŒ‡å®šåŒºé—´\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea4c963-0a8b-43ae-b9af-41db6c18c912",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in /venv/main/lib/python3.10/site-packages (0.8.5)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /venv/main/lib/python3.10/site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /venv/main/lib/python3.10/site-packages (from google-generativeai) (2.25.0rc0)\n",
      "Requirement already satisfied: google-api-python-client in /venv/main/lib/python3.10/site-packages (from google-generativeai) (2.169.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /venv/main/lib/python3.10/site-packages (from google-generativeai) (2.39.0)\n",
      "Requirement already satisfied: protobuf in /venv/main/lib/python3.10/site-packages (from google-generativeai) (5.29.4)\n",
      "Requirement already satisfied: pydantic in /venv/main/lib/python3.10/site-packages (from google-generativeai) (2.11.3)\n",
      "Requirement already satisfied: tqdm in /venv/main/lib/python3.10/site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /venv/main/lib/python3.10/site-packages (from google-generativeai) (4.13.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /venv/main/lib/python3.10/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /venv/main/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /venv/main/lib/python3.10/site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /venv/main/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /venv/main/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /venv/main/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /venv/main/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /venv/main/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /venv/main/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /venv/main/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /venv/main/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /venv/main/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /venv/main/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /venv/main/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /venv/main/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /venv/main/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /venv/main/lib/python3.10/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /venv/main/lib/python3.10/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /venv/main/lib/python3.10/site-packages (from pydantic->google-generativeai) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /venv/main/lib/python3.10/site-packages (from pydantic->google-generativeai) (0.4.0)\n"
     ]
    }
   ],
   "source": [
    "# # =============================\n",
    "# # âœ… Gemini åˆ†æå°è¯´ç« èŠ‚ï¼Œç»“æ„åŒ–è¾“å‡º JSONï¼ˆå¼ºåˆ¶è°ƒç”¨å‡½æ•°ï¼‰\n",
    "# # =============================\n",
    "# !pip install -q --upgrade google-generativeai chardet tqdm \n",
    "# !pip install -U google-generativeai\n",
    "\n",
    "\n",
    "# import os, json, re, time, random, string, chardet, logging\n",
    "# from pathlib import Path\n",
    "# from typing import List\n",
    "# from tqdm.auto import tqdm\n",
    "# import google.generativeai as genai\n",
    "\n",
    "# # â€”â€” API åˆå§‹åŒ– â€”â€”\n",
    "# os.environ[\"GEMINI_API_KEY\"]     = \"your-api-key\"     # â˜…å¿…å¡«ç”¨ Gemini\n",
    "\n",
    "# GEMINI_MODEL = \"gemini-2.0-flash\"\n",
    "\n",
    "# genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "# gemini_model = genai.GenerativeModel(GEMINI_MODEL)\n",
    "\n",
    "# logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
    "\n",
    "# # â€”â€” é€šç”¨å‡½æ•° â€”â€”\n",
    "# def _auto_decode(path: Path) -> str:\n",
    "#     raw = path.read_bytes()\n",
    "#     enc = chardet.detect(raw)[\"encoding\"] or \"utf-8\"\n",
    "#     return raw.decode(enc, errors=\"ignore\").strip()\n",
    "\n",
    "# def _rand_tag(k=6): return ''.join(random.choices(string.ascii_uppercase, k=k))\n",
    "\n",
    "# # â€”â€” JSON è¾“å‡ºå­—æ®µè¦æ±‚ï¼ˆ6 é¡¹ï¼‰ â€”â€”\n",
    "# json_schema = {\n",
    "#     \"type\": \"object\",\n",
    "#     \"properties\": {\n",
    "#         \"æƒ…èŠ‚æ‘˜è¦å¯¼è¯­\": {\"type\": \"string\"},\n",
    "#         \"å‡ºç°äººç‰©\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "#         \"å‡ºç°é“å…·\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "#         \"å‡ºç°åœºæ™¯\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "#         \"ä¼ç¬”_è®¾ä¸‹\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "#         \"ä¼ç¬”_å›æ”¶\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
    "#     },\n",
    "#     \"required\": [\"æƒ…èŠ‚æ‘˜è¦å¯¼è¯­\", \"å‡ºç°äººç‰©\", \"å‡ºç°é“å…·\", \"å‡ºç°åœºæ™¯\", \"ä¼ç¬”_è®¾ä¸‹\", \"ä¼ç¬”_å›æ”¶\"]\n",
    "# }\n",
    "\n",
    "# # â€”â€” Prompt æ¨¡æ¿ï¼ˆå¯æ›¿æ¢ä¸ºä½ æŒ‡å®šçš„ 50k / 100k / 200kï¼‰ â€”â€”\n",
    "# prompt_chapter_json = r\"\"\"\n",
    "# ä½ æ˜¯ä¸€ä½ä¸“ä¸šæ–‡å­¦ç¼–è¾‘ã€‚è¯·é˜…è¯»æˆ‘æ¥ä¸‹æ¥æä¾›çš„ã€ç« èŠ‚å…¨æ–‡ã€‘ï¼ŒæŒ‰ç…§ä¸‹åˆ—è¦æ±‚ç”Ÿæˆæ€»è®¡ **400-500 å­—** çš„è¯¦ç»†ç« èŠ‚åˆ†æï¼Œå¹¶ **ä»…ä»¥ JSON æ ¼å¼** è¿”å›ç»“æœï¼ˆä¸¥ç¦è¾“å‡ºä»»ä½•è§£é‡Šæˆ– Markdownï¼‰ã€‚\n",
    "\n",
    "# JSON é¡¶å±‚å­—æ®µä¸è¦æ±‚ï¼š\n",
    "# {\n",
    "#   \"æƒ…èŠ‚æ‘˜è¦å¯¼è¯­\": \"<400 å­—ï¼Œæ¦‚æ‹¬è¯¥ç« èŠ‚çš„ä¸»è¦å†…å®¹,è¯·å°½é‡æŠŠå‰§æƒ…è®²è¿°å®Œæ•´>\",\n",
    "#   \"å‡ºç°äººç‰©\": [\"è§’è‰²A\", \"è§’è‰²B\", ...],\n",
    "#   \"å‡ºç°é“å…·\": [\"é“å…·1\", \"é“å…·2\", ...],\n",
    "#   \"å‡ºç°åœºæ™¯\": [\"åœºæ™¯1\", \"åœºæ™¯2\"],\n",
    "#   \"ä¼ç¬”_è®¾ä¸‹\": [\"ä¼ç¬”1 æè¿°\", \"ä¼ç¬”2 æè¿°\"],\n",
    "#   \"ä¼ç¬”_å›æ”¶\": [\"ä¼ç¬”A å›æ”¶æ–¹å¼\", ...]\n",
    "# }\n",
    "\n",
    "# ä¸¥æ ¼è¦æ±‚ï¼š\n",
    "# 1. æ–‡æœ¬å­—æ®µé¡»ä¸ºå®Œæ•´ä¸­æ–‡æ®µè½ï¼›å­—æ•°å¿…é¡»è½åœ¨åŒºé—´å†…ã€‚\n",
    "# 2. ä¸Šè¿° 6 ä¸ªé”®ä¸€ä¸ªéƒ½ä¸èƒ½å°‘ï¼Œä¹Ÿä¸èƒ½å¤šã€‚\n",
    "# 3. â€œå‡ºç°äººç‰© / é“å…· / åœºæ™¯ / ä¼ç¬”â€ ç”¨ JSON æ•°ç»„ã€‚\n",
    "# 4. å¯å¼•ç”¨åŸæ–‡â‰¤10%ï¼Œéœ€åŠ å¼•å·æ³¨æ˜æ®µè½å·ã€‚\n",
    "# ã€ç« èŠ‚å…¨æ–‡ã€‘ï¼š\n",
    "# \"\"\"\n",
    "\n",
    "# # â€”â€” åˆ†æå•ç« ï¼ˆä½¿ç”¨å·¥å…·å‡½æ•° + å¼ºåˆ¶è°ƒç”¨ï¼‰ â€”â€”\n",
    "# def analyze_chapter(path: Path, prompt: str, retries: int = 3) -> str:\n",
    "#     text = _auto_decode(path)\n",
    "#     base_prompt = f\"{prompt.strip()}\\n\\n#TAG:{_rand_tag()}\"\n",
    "\n",
    "#     for attempt in range(retries):\n",
    "#         try:\n",
    "#             rsp = gemini_model.generate_content(\n",
    "#                 [base_prompt, text],\n",
    "#                 generation_config={\"temperature\": 0.3, \"max_output_tokens\": 8096},\n",
    "#                 tools=[{\n",
    "#                     \"function_declarations\": [\n",
    "#                         {\n",
    "#                             \"name\": \"analyze_chapter\",\n",
    "#                             \"description\": \"æå–å°è¯´ç« èŠ‚ç»“æ„åŒ–ä¿¡æ¯ï¼ˆæ‘˜è¦ã€äººç‰©ã€é“å…·ã€åœºæ™¯ã€ä¼ç¬”ï¼‰\",\n",
    "#                             \"parameters\": json_schema\n",
    "#                         }\n",
    "#                     ]\n",
    "#                 }],\n",
    "#                 tool_choice={\"function_call\": {\"name\": \"analyze_chapter\"}}  # âœ… å¼ºåˆ¶è°ƒç”¨\n",
    "#             )\n",
    "#             fc = rsp.candidates[0].content.parts[0].function_call\n",
    "#             return json.dumps(fc.args, ensure_ascii=False, indent=2)\n",
    "#         except Exception as e:\n",
    "#             logging.warning(f\"Gemini é”™è¯¯é‡è¯•: {e}\")\n",
    "#             time.sleep(2 ** attempt)\n",
    "\n",
    "#     raise RuntimeError(f\"âŒ åˆ†æå¤±è´¥ï¼š{path.name}\")\n",
    "\n",
    "# # â€”â€” æ‰¹é‡å¤„ç†ç›®å½•ä¸‹æ‰€æœ‰ç« èŠ‚ â€”â€”\n",
    "# def run_analysis(\n",
    "#     chapter_root: str,\n",
    "#     prompt: str,\n",
    "#     out_dir: str,\n",
    "#     mode: tuple[int, int] = (1, 150)\n",
    "# ):\n",
    "#     root = Path(chapter_root)\n",
    "#     out_base = Path(out_dir)\n",
    "#     out_base.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     books = [d for d in root.iterdir() if d.is_dir()]\n",
    "#     s, e = mode\n",
    "\n",
    "#     for book in tqdm(books, desc=\"ğŸ“š å°è¯´ä¹¦ç›®\"):\n",
    "#         chapters = sorted([p for p in book.glob(\"*.txt\")\n",
    "#                            if s <= int(p.stem[:3]) <= e])\n",
    "#         out_book_dir = out_base / book.name\n",
    "#         out_book_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#         for chap in tqdm(chapters, desc=f\"ğŸ“– {book.name}\"):\n",
    "#             out_path = out_book_dir / f\"{chap.stem}_processed.txt\"\n",
    "#             if out_path.exists(): continue\n",
    "#             try:\n",
    "#                 result = analyze_chapter(chap, prompt)\n",
    "#                 out_path.write_text(result, encoding=\"utf-8\")\n",
    "#             except Exception as e:\n",
    "#                 logging.warning(f\"âŒ {chap.name} åˆ†æå¤±è´¥: {e}\")\n",
    "\n",
    "#     print(f\"\\nâœ… æ‰€æœ‰ç« èŠ‚ç»“æ„åŒ–å®Œæˆï¼Œç»“æœä¿å­˜åœ¨ï¼š{out_base}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a297d2ce-c93b-4817-9601-e8433c8616a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1) åˆ†æ 200â€“250 å­—ç‰ˆæœ¬ï¼ˆå¯ç”¨äºä¸­çŸ­ç« ï¼‰\n",
    "# run_analysis(\n",
    "#     chapter_root=\"/content/novels_chapters\",\n",
    "#     prompt=prompt_chapter_json.replace(\"400-500\", \"200-250\").replace(\"<400\", \"<200\"),\n",
    "#     out_dir=\"/content/json_results/50000_json_gemini\"\n",
    "# )\n",
    "\n",
    "# # 2) åˆ†æ 400â€“500 å­—ç‰ˆæœ¬ï¼ˆæ ‡å‡†åˆ†æï¼‰\n",
    "# run_analysis(\n",
    "#     chapter_root=\"/content/novels_chapters\",\n",
    "#     prompt=prompt_chapter_json,\n",
    "#     out_dir=\"/content/json_results/100000_json_gemini\"\n",
    "# )\n",
    "\n",
    "# # 3) åˆ†æ 700â€“800 å­—ç‰ˆæœ¬ï¼ˆè¶…é•¿ç« èŠ‚ï¼‰\n",
    "# run_analysis(\n",
    "#     chapter_root=\"/content/novels_chapters\",\n",
    "#     prompt=prompt_chapter_json.replace(\"400-500\", \"700-800\").replace(\"<400\", \"<700\"),\n",
    "#     out_dir=\"/content/json_results/200000_json_gemini\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11bbbc9-58be-42f2-967f-73907e4d2d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0690200-4feb-45ca-9888-458057c0c242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # =============================\n",
    "# # âœ… Gemini åˆ†æå°è¯´ç« èŠ‚ï¼Œç»“æ„åŒ–è¾“å‡º JSONï¼ˆå¼ºåˆ¶è°ƒç”¨å‡½æ•° + å¯å˜æ‘˜è¦é•¿åº¦ + JSONä¿®å¤ + ç¡¬ç¼–ç Keyï¼‰\n",
    "# # =============================\n",
    "# # !pip install -q --upgrade google-generativeai chardet tqdm\n",
    "# # !pip install -U google-generativeai # ç¡®ä¿å®‰è£…æœ€æ–°ç‰ˆæœ¬\n",
    "\n",
    "# import os\n",
    "# import json\n",
    "# import re\n",
    "# import time\n",
    "# import random\n",
    "# import string\n",
    "# import chardet\n",
    "# import logging\n",
    "# import copy  # å¯¼å…¥ copy\n",
    "# from pathlib import Path\n",
    "# from typing import List, Dict, Any\n",
    "# from tqdm.auto import tqdm\n",
    "# import google.generativeai as genai\n",
    "# from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "\n",
    "# # â€”â€” API åˆå§‹åŒ– (âš ï¸ è­¦å‘Šï¼šç›´æ¥å†™å…¥ API å¯†é’¥æä¸å®‰å…¨ï¼) â€”â€”\n",
    "# # å¼ºçƒˆå»ºè®®æ‚¨ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ– Secrets Manager ç­‰æ›´å®‰å…¨çš„æ–¹å¼ç®¡ç† API å¯†é’¥ã€‚\n",
    "# # ç›´æ¥å°†å¯†é’¥å†™å…¥ä»£ç ä¼šå¸¦æ¥ä¸¥é‡çš„å®‰å…¨é£é™©ï¼Œå°¤å…¶æ˜¯åœ¨å…±äº«æˆ–ç‰ˆæœ¬æ§åˆ¶ä»£ç æ—¶ã€‚\n",
    "\n",
    "# # âš ï¸ è¯·å°†ä¸‹é¢çš„ \"YOUR_API_KEY_HERE\" æ›¿æ¢ä¸ºæ‚¨çœŸå®çš„ Gemini API å¯†é’¥ï¼\n",
    "# api_key = \"your-default-api-key\"\n",
    "\n",
    "# # åŸºæœ¬æ£€æŸ¥ï¼Œç¡®ä¿ç”¨æˆ·æ›¿æ¢äº†å ä½ç¬¦\n",
    "# if not api_key or api_key == \"YOUR_API_KEY_HERE\":\n",
    "#     raise ValueError(\"âŒ é”™è¯¯ï¼šè¯·åŠ¡å¿…å°†ä»£ç ä¸­çš„ 'YOUR_API_KEY_HERE' æ›¿æ¢ä¸ºæ‚¨çš„çœŸå® Gemini API å¯†é’¥ã€‚\")\n",
    "\n",
    "# # ä½¿ç”¨ç›´æ¥å†™å…¥çš„å¯†é’¥é…ç½® SDK\n",
    "# try:\n",
    "#     genai.configure(api_key=api_key)\n",
    "#     logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\") # Setup logging after configure\n",
    "#     logging.info(\"Gemini API å·²ä½¿ç”¨ç›´æ¥å†™å…¥çš„å¯†é’¥è¿›è¡Œé…ç½®ã€‚\")\n",
    "# except Exception as e:\n",
    "#     # å¦‚æœé…ç½®å¤±è´¥ï¼Œæå‰è®°å½•é”™è¯¯å¹¶é€€å‡º\n",
    "#     # logging å¯èƒ½å°šæœªå®Œå…¨é…ç½®ï¼Œå°è¯•æ‰“å°é”™è¯¯\n",
    "#     print(f\"CRITICAL: ä½¿ç”¨æä¾›çš„ API å¯†é’¥é…ç½® Gemini SDK æ—¶å‡ºé”™: {e}\")\n",
    "#     raise ValueError(f\"API å¯†é’¥é…ç½®å¤±è´¥: {e}\")\n",
    "\n",
    "# # ä½¿ç”¨æ¨èçš„æœ€æ–° Flash æ¨¡å‹\n",
    "# GEMINI_MODEL = \"gemini-2.0-flash\"\n",
    "\n",
    "# # â€”â€” é€šç”¨å‡½æ•° â€”â€”\n",
    "# def _auto_decode(path: Path) -> str:\n",
    "#     \"\"\"è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶ç¼–ç å¹¶è¯»å–å†…å®¹\"\"\"\n",
    "#     try:\n",
    "#         raw = path.read_bytes()\n",
    "#         enc = chardet.detect(raw)[\"encoding\"] or \"utf-8\"\n",
    "#         # å¢åŠ å¯¹å¸¸è§ä¸­æ–‡ç¼–ç çš„å°è¯•\n",
    "#         if enc.lower() not in ['utf-8', 'gbk', 'gb2312', 'big5']:\n",
    "#              try: return raw.decode('utf-8', errors='ignore').strip()\n",
    "#              except UnicodeDecodeError:\n",
    "#                  try: return raw.decode('gbk', errors='ignore').strip()\n",
    "#                  except UnicodeDecodeError: return raw.decode(enc, errors='ignore').strip() # æœ€åå°è¯• chardet çš„ç»“æœ\n",
    "#         return raw.decode(enc, errors=\"ignore\").strip()\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"è¯»å–æ–‡ä»¶ {path.name} æ—¶å‡ºé”™: {e}\")\n",
    "#         return \"\" # è¿”å›ç©ºå­—ç¬¦ä¸²ï¼Œè®©åç»­å¤„ç†çŸ¥é“å¤±è´¥\n",
    "\n",
    "# def _rand_tag(k=6):\n",
    "#     \"\"\"ç”Ÿæˆéšæœºæ ‡ç­¾ï¼ˆå¯é€‰ï¼‰\"\"\"\n",
    "#     return ''.join(random.choices(string.ascii_uppercase, k=k))\n",
    "\n",
    "# # â€”â€” åŸºç¡€ JSON è¾“å‡ºå­—æ®µè¦æ±‚ â€”â€”\n",
    "# base_json_schema = {\n",
    "#     \"type\": \"object\",\n",
    "#     \"properties\": {\n",
    "#         \"æƒ…èŠ‚æ‘˜è¦å¯¼è¯­\": {\"type\": \"string\", \"description\": \"\"}, # æè¿°å°†åœ¨è°ƒç”¨æ—¶åŠ¨æ€è®¾ç½®\n",
    "#         \"å‡ºç°äººç‰©\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"æœ¬ç« å‡ºç°çš„æ‰€æœ‰äººç‰©åç§°åˆ—è¡¨\"},\n",
    "#         \"å‡ºç°é“å…·\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"æœ¬ç« å‡ºç°çš„å…³é”®é“å…·åˆ—è¡¨\"},\n",
    "#         \"å‡ºç°åœºæ™¯\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"æœ¬ç« å‘ç”Ÿæ•…äº‹çš„ä¸»è¦åœºæ™¯åˆ—è¡¨\"},\n",
    "#         \"ä¼ç¬”_è®¾ä¸‹\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"æœ¬ç« æ–°åŸ‹ä¸‹çš„ä¼ç¬”æè¿°\"},\n",
    "#         \"ä¼ç¬”_å›æ”¶\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"æœ¬ç« å›æ”¶æˆ–å‘¼åº”çš„è¿‡å¾€ä¼ç¬”æè¿°\"}\n",
    "#     },\n",
    "#     \"required\": [\"æƒ…èŠ‚æ‘˜è¦å¯¼è¯­\", \"å‡ºç°äººç‰©\", \"å‡ºç°é“å…·\", \"å‡ºç°åœºæ™¯\", \"ä¼ç¬”_è®¾ä¸‹\", \"ä¼ç¬”_å›æ”¶\"]\n",
    "# }\n",
    "\n",
    "# # â€”â€” Prompt æ¨¡æ¿ (å¼ºè°ƒéµå¾ªå‚æ•°æè¿°) â€”â€”\n",
    "# prompt_chapter_template = r\"\"\"\n",
    "# ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ–‡å­¦ç¼–è¾‘ã€‚è¯·ä»”ç»†é˜…è¯»æˆ‘æä¾›çš„ã€ç« èŠ‚å…¨æ–‡ã€‘ã€‚\n",
    "# ä½ çš„ä»»åŠ¡æ˜¯æå–ç»“æ„åŒ–ä¿¡æ¯ï¼Œå¹¶ **å¿…é¡»** è°ƒç”¨ `extract_chapter_details` å‡½æ•°æ¥è¿”å›ç»“æœã€‚\n",
    "# è¯·ä¸¥æ ¼æŒ‰ç…§å‡½æ•°å‚æ•°çš„æè¿°ï¼ˆç‰¹åˆ«æ˜¯å…³äºâ€œæƒ…èŠ‚æ‘˜è¦å¯¼è¯­â€çš„è¯¦ç»†ç¨‹åº¦è¦æ±‚ï¼‰æ¥å¡«å……ä¿¡æ¯ã€‚\n",
    "# **ç»å¯¹ä¸è¦** è¾“å‡ºä»»ä½• JSON æ ¼å¼ä¹‹å¤–çš„æ–‡æœ¬ã€è§£é‡Šã€ä»£ç å—æ ‡è®°ï¼ˆå¦‚ ```json ... ```ï¼‰æˆ– Markdownã€‚\n",
    "# ç›´æ¥è°ƒç”¨å‡½æ•°å¹¶å¡«å……å…¶å‚æ•°ã€‚\n",
    "\n",
    "# ã€ç« èŠ‚å…¨æ–‡ã€‘ï¼š\n",
    "# {chapter_text}\n",
    "# \"\"\"\n",
    "\n",
    "# # â€”â€” åˆ†æå•ç« ï¼ˆæ¥å— summary_descriptionï¼ŒåŒ…å« JSON ä¿®å¤ï¼‰ â€”â€”\n",
    "# def analyze_chapter(\n",
    "#     path: Path,\n",
    "#     prompt_template: str,\n",
    "#     summary_description: str, # å…·ä½“çš„æ‘˜è¦è¦æ±‚\n",
    "#     retries: int = 3\n",
    "# ) -> str | None:\n",
    "#     \"\"\"\n",
    "#     ä½¿ç”¨ Gemini åˆ†æå•ä¸ªå°è¯´ç« èŠ‚æ–‡ä»¶ï¼Œå¼ºåˆ¶è°ƒç”¨å‡½æ•°å¹¶è¿”å› JSON å­—ç¬¦ä¸²ã€‚\n",
    "#     å…è®¸é€šè¿‡ summary_description æŒ‡å®šæ‘˜è¦çš„è¯¦ç»†ç¨‹åº¦ã€‚\n",
    "#     å¦‚æœåˆ†æå¤±è´¥ï¼Œåˆ™è¿”å› Noneã€‚\n",
    "#     \"\"\"\n",
    "#     text = _auto_decode(path)\n",
    "#     if not text:\n",
    "#         logging.error(f\"æ— æ³•è¯»å–æˆ–è§£ç æ–‡ä»¶: {path.name}\")\n",
    "#         return None\n",
    "\n",
    "#     full_prompt = prompt_template.format(chapter_text=text)\n",
    "\n",
    "#     # --- åŠ¨æ€æ„å»ºå‡½æ•°å£°æ˜ ---\n",
    "#     current_schema = copy.deepcopy(base_json_schema)\n",
    "#     current_schema[\"properties\"][\"æƒ…èŠ‚æ‘˜è¦å¯¼è¯­\"][\"description\"] = summary_description\n",
    "#     extract_details_func_declaration = {\n",
    "#         \"name\": \"extract_chapter_details\",\n",
    "#         \"description\": \"æå–å°è¯´ç« èŠ‚çš„ç»“æ„åŒ–ä¿¡æ¯ï¼ŒåŒ…æ‹¬æƒ…èŠ‚æ‘˜è¦ã€äººç‰©ã€é“å…·ã€åœºæ™¯å’Œä¼ç¬”ã€‚\",\n",
    "#         \"parameters\": current_schema\n",
    "#     }\n",
    "#     # --- åŠ¨æ€æ„å»ºç»“æŸ ---\n",
    "\n",
    "#     safety_settings = {\n",
    "#         HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "#         HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "#         HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "#         HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "#     }\n",
    "#     # æ³¨æ„ï¼šå¦‚æœ API Key æ— æ•ˆï¼Œæ­¤å¤„ä¹Ÿå¯èƒ½æŠ›å‡ºå¼‚å¸¸ï¼Œå°½ç®¡ configure æ—¶å·²æ£€æŸ¥\n",
    "#     try:\n",
    "#         gemini_model = genai.GenerativeModel(\n",
    "#             GEMINI_MODEL,\n",
    "#             safety_settings=safety_settings\n",
    "#         )\n",
    "#     except Exception as model_init_err:\n",
    "#         logging.error(f\"åˆå§‹åŒ– Gemini æ¨¡å‹æ—¶å‡ºé”™: {model_init_err}\", exc_info=True)\n",
    "#         return None # æ— æ³•åˆå§‹åŒ–æ¨¡å‹ï¼Œç›´æ¥å¤±è´¥\n",
    "\n",
    "#     # --- é‡è¯•å¾ªç¯ ---\n",
    "#     for attempt in range(retries):\n",
    "#         func_call_args_raw = None # ç”¨äºåœ¨å‡ºé”™æ—¶è®°å½•åŸå§‹å‚æ•°\n",
    "#         try:\n",
    "#             logging.info(f\"å¼€å§‹åˆ†æç« èŠ‚: {path.name} (æ‘˜è¦è¦æ±‚: '{summary_description}', å°è¯• {attempt + 1}/{retries})\")\n",
    "#             rsp = gemini_model.generate_content(\n",
    "#                 full_prompt,\n",
    "#                 generation_config={\"temperature\": 0.3},\n",
    "#                 tools=[{\"function_declarations\": [extract_details_func_declaration]}],\n",
    "#                 tool_config={'function_calling_config': 'ANY'}\n",
    "#             )\n",
    "\n",
    "#             # --- å¥å£®æ€§æ£€æŸ¥ ---\n",
    "#             if not rsp.candidates:\n",
    "#                  logging.warning(f\"åˆ†æå¤±è´¥ (å°è¯• {attempt + 1}): API æœªè¿”å›å€™é€‰å†…å®¹ã€‚å“åº”: {rsp}\")\n",
    "#                  time.sleep(2 ** attempt + random.uniform(0, 1))\n",
    "#                  continue\n",
    "\n",
    "#             first_candidate = rsp.candidates[0]\n",
    "#             if not first_candidate.content or not first_candidate.content.parts:\n",
    "#                 # æ£€æŸ¥æ˜¯å¦æœ‰ block æ˜¯å› ä¸ºå®‰å…¨è®¾ç½®\n",
    "#                 if first_candidate.finish_reason == genai.types.FinishReason.SAFETY:\n",
    "#                      logging.warning(f\"åˆ†æå¤±è´¥ (å°è¯• {attempt + 1}): å†…å®¹è¢«å®‰å…¨è®¾ç½®é˜»æ­¢ã€‚å®‰å…¨è¯„çº§: {first_candidate.safety_ratings}\")\n",
    "#                 else:\n",
    "#                      logging.warning(f\"åˆ†æå¤±è´¥ (å°è¯• {attempt + 1}): å€™é€‰å†…å®¹ä¸ºç©ºæˆ–æ—  Partã€‚å®ŒæˆåŸå› : {first_candidate.finish_reason}\")\n",
    "#                 time.sleep(2 ** attempt + random.uniform(0, 1))\n",
    "#                 continue\n",
    "\n",
    "#             # --- æŸ¥æ‰¾å‡½æ•°è°ƒç”¨ ---\n",
    "#             func_call_part = None\n",
    "#             for part in first_candidate.content.parts:\n",
    "#                 if part.function_call:\n",
    "#                     func_call_part = part\n",
    "#                     break\n",
    "\n",
    "#             if func_call_part and func_call_part.function_call:\n",
    "#                 fc = func_call_part.function_call\n",
    "#                 func_call_args_raw = fc.args # ä¿å­˜åŸå§‹å‚æ•°ä»¥å¤‡è°ƒè¯•\n",
    "\n",
    "#                 if fc.name == \"extract_chapter_details\":\n",
    "#                     logging.info(f\"æˆåŠŸåˆ†æç« èŠ‚: {path.name} (æ‘˜è¦è¦æ±‚: '{summary_description}')\")\n",
    "\n",
    "#                   # --- FIX v2: Handle Nested RepeatedComposite ---\n",
    "#                     try:\n",
    "#                         # 1. Convert top-level MapComposite to dict (shallow)\n",
    "#                         args_dict_shallow = dict(fc.args)\n",
    "\n",
    "#                         # 2. Create a new dict for fully native Python types\n",
    "#                         args_dict_native = {}\n",
    "#                         for key, value in args_dict_shallow.items():\n",
    "#                             # Check if the value is the problematic list type\n",
    "#                             # Using type().__name__ is slightly brittle but targets the known issue.\n",
    "#                             # isinstance() might be better if we knew the exact class path.\n",
    "#                             if type(value).__name__ == 'RepeatedComposite':\n",
    "#                                 # Convert RepeatedComposite to a standard Python list\n",
    "#                                 # This assumes the items *within* the list are already native types\n",
    "#                                 # (like strings, which matches your schema: \"items\": {\"type\": \"string\"})\n",
    "#                                 args_dict_native[key] = list(value)\n",
    "#                             else:\n",
    "#                                 # Assume other types (like the string for 'æƒ…èŠ‚æ‘˜è¦å¯¼è¯­') are already native or serializable\n",
    "#                                 args_dict_native[key] = value\n",
    "\n",
    "#                         # 3. Now serialize the deeply converted dict\n",
    "#                         json_output = json.dumps(args_dict_native, ensure_ascii=False, indent=2)\n",
    "#                         return json_output # Success\n",
    "\n",
    "#                     except TypeError as json_err:\n",
    "#                         # Catch potential errors during the deeper conversion or final serialization\n",
    "#                         logging.error(f\"åºåˆ—åŒ–ä»APIæ¥æ”¶çš„å‚æ•°æ—¶å‡ºé”™: {json_err}\", exc_info=False)\n",
    "#                         logging.error(f\"  æœªèƒ½åºåˆ—åŒ–çš„åŸå§‹å‚æ•°ç±»å‹: {type(fc.args)}\")\n",
    "#                         # Log the shallow dict as well, as it might show the structure better\n",
    "#                         logging.error(f\"  æµ…å±‚è½¬æ¢åçš„å­—å…¸å†…å®¹ (éƒ¨åˆ†): {str(args_dict_shallow)[:500]}...\")\n",
    "#                         # Continue to the next retry attempt\n",
    "#                         time.sleep(2 ** attempt + random.uniform(0, 1))\n",
    "#                         continue # Important: go to next retry if serialization fails\n",
    "#                     # --- END FIX v2 ---\n",
    "#                     # --- END FIX ---\n",
    "\n",
    "#                 else:\n",
    "#                     logging.warning(f\"åˆ†æè­¦å‘Š (å°è¯• {attempt + 1}): æ¨¡å‹è°ƒç”¨äº†æ„å¤–çš„å‡½æ•° '{fc.name}'\")\n",
    "#             else:\n",
    "#                 # æ¨¡å‹æœªè°ƒç”¨å‡½æ•°\n",
    "#                 finish_reason = first_candidate.finish_reason\n",
    "#                 safety_ratings = first_candidate.safety_ratings\n",
    "#                 logging.warning(f\"åˆ†æå¤±è´¥ (å°è¯• {attempt + 1}): æœªæ‰¾åˆ°é¢„æœŸçš„å‡½æ•°è°ƒç”¨ã€‚\")\n",
    "#                 logging.warning(f\"  å®ŒæˆåŸå› : {finish_reason}\")\n",
    "#                 if safety_ratings: # ä»…å½“å­˜åœ¨æ—¶æ‰“å°\n",
    "#                     logging.warning(f\"  å®‰å…¨è¯„çº§: {safety_ratings}\")\n",
    "#                 # å¦‚æœæœ‰æ–‡æœ¬è¾“å‡ºï¼Œä¹Ÿè®°å½•ä¸‹æ¥å¸®åŠ©è°ƒè¯•\n",
    "#                 text_output = \"\"\n",
    "#                 try:\n",
    "#                     text_output = first_candidate.text\n",
    "#                 except ValueError: # æœ‰æ—¶è®¿é—® .text ä¼šå‡ºé”™å¦‚æœå†…å®¹ä¸æ˜¯æ–‡æœ¬\n",
    "#                      if first_candidate.content and first_candidate.content.parts:\n",
    "#                          text_output = str(first_candidate.content.parts[0]) # å°è¯•è·å–åŸå§‹éƒ¨åˆ†\n",
    "#                 if text_output:\n",
    "#                      logging.warning(f\"  æ¨¡å‹è¿”å›å†…å®¹ (éƒ¨åˆ†): {text_output[:200]}...\") # åªè®°å½•éƒ¨åˆ†æ–‡æœ¬\n",
    "\n",
    "#             # å¦‚æœä»£ç æ‰§è¡Œåˆ°è¿™é‡Œï¼Œè¡¨ç¤ºå½“å‰å°è¯•å¤±è´¥ï¼Œå‡†å¤‡ä¸‹ä¸€æ¬¡é‡è¯•\n",
    "#             time.sleep(2 ** attempt + random.uniform(0, 1))\n",
    "\n",
    "#         except Exception as e:\n",
    "#             # æ•è·æ‰€æœ‰å…¶ä»–åœ¨ API è°ƒç”¨æˆ–å¤„ç†æœŸé—´çš„å¼‚å¸¸\n",
    "#             error_context = \"\"\n",
    "#             if func_call_args_raw is not None: # å¦‚æœå‡ºé”™å‰å·²è·å–å‚æ•°\n",
    "#                  error_context = f\" | å‚æ•°ç±»å‹: {type(func_call_args_raw)}, å†…å®¹ (éƒ¨åˆ†): {str(func_call_args_raw)[:200]}...\"\n",
    "\n",
    "#             # æ£€æŸ¥æ˜¯å¦æ˜¯ç‰¹å®šçš„ API é”™è¯¯ç±»å‹ (å¯é€‰ï¼Œéœ€è¦ import)\n",
    "#             # from google.api_core.exceptions import GoogleAPIError\n",
    "#             # if isinstance(e, GoogleAPIError): ...\n",
    "\n",
    "#             logging.error(f\"Gemini API è°ƒç”¨æˆ–å¤„ç†æ—¶å‘ç”Ÿå¼‚å¸¸ (å°è¯• {attempt + 1}): {e}{error_context}\", exc_info=True) # è®°å½•å®Œæ•´å †æ ˆ\n",
    "#             time.sleep(2 ** attempt + random.uniform(0, 1)) # ç­‰å¾…åé‡è¯•\n",
    "\n",
    "#     # --- é‡è¯•ç»“æŸ ---\n",
    "#     logging.error(f\"âŒ åˆ†æå¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {path.name} (æ‘˜è¦è¦æ±‚: '{summary_description}')\")\n",
    "#     return None # æ‰€æœ‰é‡è¯•å¤±è´¥åè¿”å› None\n",
    "\n",
    "\n",
    "# # â€”â€” æ‰¹é‡å¤„ç†ç›®å½•ä¸‹æ‰€æœ‰ç« èŠ‚ (æ¥å— summary_description) â€”â€”\n",
    "# def run_analysis(\n",
    "#     chapter_root: str,\n",
    "#     prompt_template: str,\n",
    "#     summary_description: str, # æ‘˜è¦è¦æ±‚\n",
    "#     out_dir: str,\n",
    "#     mode: tuple[int, int] = (1, 150) # å¤„ç†ç« èŠ‚èŒƒå›´\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     æ‰¹é‡å¤„ç†æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰å°è¯´ç« èŠ‚ã€‚\n",
    "#     \"\"\"\n",
    "#     root = Path(chapter_root)\n",
    "#     if not root.is_dir():\n",
    "#         logging.error(f\"é”™è¯¯ï¼šè¾“å…¥ç›®å½• '{chapter_root}' ä¸å­˜åœ¨æˆ–ä¸æ˜¯ä¸€ä¸ªç›®å½•ã€‚\")\n",
    "#         return\n",
    "\n",
    "#     out_base = Path(out_dir)\n",
    "#     out_base.mkdir(parents=True, exist_ok=True)\n",
    "#     logging.info(f\"å¼€å§‹æ‰¹é‡åˆ†æ (æ‘˜è¦è¦æ±‚: '{summary_description}'), è¾“å‡ºåˆ°: {out_base}\")\n",
    "\n",
    "#     books = [d for d in root.iterdir() if d.is_dir()]\n",
    "#     if not books:\n",
    "#         logging.warning(f\"åœ¨ '{chapter_root}' ä¸‹æœªæ‰¾åˆ°ä»»ä½•å°è¯´å­ç›®å½•ã€‚\")\n",
    "#         return\n",
    "\n",
    "#     s, e = mode\n",
    "#     logging.info(f\"å¤„ç†ç« èŠ‚èŒƒå›´: {s} åˆ° {e}\")\n",
    "\n",
    "#     total_processed = 0\n",
    "#     total_failed = 0\n",
    "#     total_skipped = 0\n",
    "\n",
    "#     for book in tqdm(books, desc=\"ğŸ“š å¤„ç†å°è¯´ä¹¦ç›®\"):\n",
    "#         # æŸ¥æ‰¾ç¬¦åˆå‘½åè§„èŒƒï¼ˆä»¥3ä½æ•°å­—å¼€å¤´ï¼‰ä¸”åœ¨èŒƒå›´å†…çš„ txt æ–‡ä»¶\n",
    "#         chapters = sorted([\n",
    "#             p for p in book.glob(\"*.txt\")\n",
    "#             if p.name[:3].isdigit() and s <= int(p.name[:3]) <= e\n",
    "#         ], key=lambda p: int(p.name[:3])) # æŒ‰æ•°å­—æ’åº\n",
    "\n",
    "#         if not chapters:\n",
    "#             logging.warning(f\"åœ¨ '{book.name}' ç›®å½•ä¸­æœªæ‰¾åˆ°ç¬¦åˆèŒƒå›´ {s}-{e} çš„ç« èŠ‚æ–‡ä»¶ (ä¾‹å¦‚ '001_xxx.txt')ã€‚\")\n",
    "#             continue\n",
    "\n",
    "#         out_book_dir = out_base / book.name\n",
    "#         out_book_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#         processed_count = 0\n",
    "#         failed_count = 0\n",
    "#         skipped_count = 0\n",
    "\n",
    "#         for chap_path in tqdm(chapters, desc=f\"ğŸ“– åˆ†æ '{book.name}'\", leave=False):\n",
    "#             # è¾“å‡ºæ–‡ä»¶åä½¿ç”¨åŸå§‹ç« èŠ‚å + '_analysis.json'\n",
    "#             out_filename = f\"{chap_path.stem}_analysis.json\"\n",
    "#             out_path = out_book_dir / out_filename\n",
    "\n",
    "#             if out_path.exists():\n",
    "#                 skipped_count += 1\n",
    "#                 continue # å¦‚æœå·²å­˜åœ¨ï¼Œåˆ™è·³è¿‡\n",
    "\n",
    "#             try:\n",
    "#                 # è°ƒç”¨åˆ†æå‡½æ•°ï¼Œä¼ å…¥ summary_description\n",
    "#                 result_json = analyze_chapter(chap_path, prompt_template, summary_description)\n",
    "\n",
    "#                 if result_json:\n",
    "#                     out_path.write_text(result_json, encoding=\"utf-8\")\n",
    "#                     processed_count += 1\n",
    "#                 else:\n",
    "#                     # analyze_chapter å†…éƒ¨å·²è®°å½•é”™è¯¯ï¼Œè¿™é‡Œåªè®¡æ•°\n",
    "#                     failed_count += 1\n",
    "#             except Exception as e:\n",
    "#                 # æ•è· analyze_chapter æœªå¤„ç†çš„æ„å¤–é”™è¯¯\n",
    "#                 logging.error(f\"å¤„ç†ç« èŠ‚ {chap_path.name} æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}\", exc_info=True)\n",
    "#                 failed_count += 1\n",
    "\n",
    "#         logging.info(f\"å®Œæˆå¤„ç† '{book.name}': {processed_count} ä¸ªæˆåŠŸ, {failed_count} ä¸ªå¤±è´¥, {skipped_count} ä¸ªè·³è¿‡ã€‚\")\n",
    "#         total_processed += processed_count\n",
    "#         total_failed += failed_count\n",
    "#         total_skipped += skipped_count\n",
    "\n",
    "#     print(f\"\\nâœ… æ‰€æœ‰ç« èŠ‚ç»“æ„åŒ–åˆ†æå®Œæˆï¼ˆæˆ–å°è¯•å®Œæˆï¼‰ã€‚\")\n",
    "#     print(f\"  æ€»è®¡: {total_processed} ä¸ªæˆåŠŸ, {total_failed} ä¸ªå¤±è´¥, {total_skipped} ä¸ªè·³è¿‡ã€‚\")\n",
    "#     print(f\"  ç»“æœä¿å­˜åœ¨å¯¹åº”çš„è¾“å‡ºå­ç›®å½•ä¸­ï¼Œæ ¹ç›®å½•ä¸ºï¼š{OUTPUT_BASE_DIR}\") # æŒ‡å‘æ€»ç›®å½•\n",
    "\n",
    "\n",
    "# # --- ä¸»ç¨‹åºå…¥å£ ---\n",
    "# if __name__ == \"__main__\":\n",
    "#     # å®šä¹‰è¾“å…¥ç›®å½• (â˜…â˜…â˜… æ ¹æ®ä½ çš„å®é™…æƒ…å†µä¿®æ”¹ â˜…â˜…â˜…)\n",
    "#     CHAPTERS_INPUT_DIR = \"/content/novels_chapters\"\n",
    "#     # å®šä¹‰è¾“å‡ºæ ¹ç›®å½• (â˜…â˜…â˜… æ ¹æ®ä½ çš„å®é™…æƒ…å†µä¿®æ”¹ â˜…â˜…â˜…)\n",
    "#     OUTPUT_BASE_DIR = \"/content/json_results/json_gemini\"\n",
    "\n",
    "#     # --- å®šä¹‰ä¸åŒæ‘˜è¦é•¿åº¦çš„è¦æ±‚ ---\n",
    "#     summary_req_short = \"ç”Ÿæˆä¸€ä¸ªéå¸¸ç®€çŸ­çš„æ ¸å¿ƒæƒ…èŠ‚æ‘˜è¦ï¼ˆ çº¦ 150-200 å­—ï¼‰\"\n",
    "#     summary_req_medium = \"ç”Ÿæˆä¸€ä¸ªæ ‡å‡†çš„æƒ…èŠ‚æ‘˜è¦ï¼Œæ¦‚æ‹¬ä¸»è¦å†…å®¹ï¼ˆçº¦ 300-400 å­—ï¼‰\"\n",
    "#     summary_req_long = \"ç”Ÿæˆä¸€ä¸ªæ¯”è¾ƒè¯¦ç»†çš„æƒ…èŠ‚æ‘˜è¦ï¼ŒåŒ…å«æ›´å¤šç»†èŠ‚å’Œè½¬æŠ˜ï¼ˆçº¦ 600-700 å­—ï¼‰\"\n",
    "\n",
    "#     # --- è¿è¡Œä¸åŒç‰ˆæœ¬çš„åˆ†æ ---\n",
    "#     # (ä½ å¯ä»¥å–æ¶ˆæ³¨é‡Šæ‰ä¸æƒ³è¿è¡Œçš„ç‰ˆæœ¬)\n",
    "\n",
    "#     logging.info(\"=\"*20 + \" å¼€å§‹ç®€çŸ­æ‘˜è¦åˆ†æ \" + \"=\"*20)\n",
    "#     run_analysis(\n",
    "#         chapter_root=CHAPTERS_INPUT_DIR,\n",
    "#         prompt_template=prompt_chapter_template,\n",
    "#         summary_description=summary_req_short, # <---- ä¼ å…¥ç®€çŸ­è¦æ±‚\n",
    "#         out_dir=os.path.join(OUTPUT_BASE_DIR, \"50000_summary\"), # è¾“å‡ºåˆ°å­ç›®å½•\n",
    "#         mode=(1, 150) # åˆ†æ 1 åˆ° 150 ç« \n",
    "#     )\n",
    "\n",
    "#     logging.info(\"=\"*20 + \" å¼€å§‹æ ‡å‡†æ‘˜è¦åˆ†æ \" + \"=\"*20)\n",
    "#     run_analysis(\n",
    "#         chapter_root=CHAPTERS_INPUT_DIR,\n",
    "#         prompt_template=prompt_chapter_template,\n",
    "#         summary_description=summary_req_medium, # <---- ä¼ å…¥æ ‡å‡†è¦æ±‚\n",
    "#         out_dir=os.path.join(OUTPUT_BASE_DIR, \"100000_summary\"), # è¾“å‡ºåˆ°å­ç›®å½•\n",
    "#         mode=(1, 150)\n",
    "#     )\n",
    "\n",
    "#     logging.info(\"=\"*20 + \" å¼€å§‹è¯¦ç»†æ‘˜è¦åˆ†æ \" + \"=\"*20)\n",
    "#     run_analysis(\n",
    "#         chapter_root=CHAPTERS_INPUT_DIR,\n",
    "#         prompt_template=prompt_chapter_template,\n",
    "#         summary_description=summary_req_long, # <---- ä¼ å…¥è¯¦ç»†è¦æ±‚\n",
    "#         out_dir=os.path.join(OUTPUT_BASE_DIR, \"200000_summary\"), # è¾“å‡ºåˆ°å­ç›®å½•\n",
    "#         mode=(1, 150)\n",
    "#     )\n",
    "\n",
    "#     logging.info(\"=\"*20 + \" æ‰€æœ‰ä¸åŒæ‘˜è¦é•¿åº¦çš„åˆ†æä»»åŠ¡å·²æäº¤ \" + \"=\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c5ee3cf-0fc7-4aba-ab0e-74e899ac3714",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Gemini API å·²ä½¿ç”¨ç›´æ¥å†™å…¥çš„å¯†é’¥è¿›è¡Œé…ç½®ã€‚\n"
     ]
    }
   ],
   "source": [
    "# # =============================\n",
    "# # âœ… Gemini åˆ†æå°è¯´ç« èŠ‚ï¼Œç»“æ„åŒ–è¾“å‡º JSON + TXTç»†çº²ç”Ÿæˆ (ä¸»ç¨‹åºå‚æ•°æ›´æ–°)\n",
    "# # =============================\n",
    "# # !pip install -q --upgrade google-generativeai chardet tqdm\n",
    "# # !pip install -U google-generativeai # ç¡®ä¿å®‰è£…æœ€æ–°ç‰ˆæœ¬\n",
    "\n",
    "# import os\n",
    "# import json\n",
    "# import re\n",
    "# import time\n",
    "# import random\n",
    "# import string\n",
    "# import chardet\n",
    "# import logging\n",
    "# import copy\n",
    "# from pathlib import Path\n",
    "# from typing import List, Dict, Any, Tuple\n",
    "# from tqdm.auto import tqdm\n",
    "# import google.generativeai as genai\n",
    "# from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "\n",
    "# # --- (API åˆå§‹åŒ–, é€šç”¨å‡½æ•°, Schema, Prompt æ¨¡æ¿ - ä¸ä¸Šä¸€ç‰ˆæœ¬ç›¸åŒ) ---\n",
    "\n",
    "# # â€”â€” API åˆå§‹åŒ– (âš ï¸ è­¦å‘Šï¼šç›´æ¥å†™å…¥ API å¯†é’¥æä¸å®‰å…¨ï¼) â€”â€”\n",
    "# api_key = \"your-default-api-key\" # âš ï¸ æ›¿æ¢ä¸ºæ‚¨çš„çœŸå® API å¯†é’¥\n",
    "# if not api_key or api_key == \"YOUR_API_KEY_HERE\":\n",
    "#     raise ValueError(\"âŒ é”™è¯¯ï¼šè¯·åŠ¡å¿…å°†ä»£ç ä¸­çš„ 'YOUR_API_KEY_HERE' æ›¿æ¢ä¸ºæ‚¨çš„çœŸå® Gemini API å¯†é’¥ã€‚\")\n",
    "# try:\n",
    "#     genai.configure(api_key=api_key)\n",
    "#     logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "#     logging.info(\"Gemini API å·²ä½¿ç”¨ç›´æ¥å†™å…¥çš„å¯†é’¥è¿›è¡Œé…ç½®ã€‚\")\n",
    "# except Exception as e:\n",
    "#     print(f\"CRITICAL: ä½¿ç”¨æä¾›çš„ API å¯†é’¥é…ç½® Gemini SDK æ—¶å‡ºé”™: {e}\")\n",
    "#     raise ValueError(f\"API å¯†é’¥é…ç½®å¤±è´¥: {e}\")\n",
    "\n",
    "# GEMINI_MODEL = \"gemini-2.0-flash-latest\"\n",
    "\n",
    "# def _auto_decode(path: Path) -> str:\n",
    "#     try:\n",
    "#         raw = path.read_bytes()\n",
    "#         enc = chardet.detect(raw)[\"encoding\"] or \"utf-8\"\n",
    "#         if enc.lower() not in ['utf-8', 'gbk', 'gb2312', 'big5']:\n",
    "#              try: return raw.decode('utf-8', errors='ignore').strip()\n",
    "#              except UnicodeDecodeError:\n",
    "#                  try: return raw.decode('gbk', errors='ignore').strip()\n",
    "#                  except UnicodeDecodeError: return raw.decode(enc, errors='ignore').strip()\n",
    "#         return raw.decode(enc, errors=\"ignore\").strip()\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"è¯»å–æ–‡ä»¶ {path.name} æ—¶å‡ºé”™: {e}\")\n",
    "#         return \"\"\n",
    "\n",
    "# def _rand_tag(k=6): return ''.join(random.choices(string.ascii_uppercase, k=k))\n",
    "\n",
    "# base_json_schema = {\n",
    "#     \"type\": \"object\",\n",
    "#     \"properties\": {\n",
    "#         \"æƒ…èŠ‚æ‘˜è¦å¯¼è¯­\": {\"type\": \"string\", \"description\": \"\"},\n",
    "#         \"å‡ºç°äººç‰©\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"æœ¬ç« å‡ºç°çš„æ‰€æœ‰äººç‰©åç§°åˆ—è¡¨\"},\n",
    "#         \"å‡ºç°é“å…·\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"æœ¬ç« å‡ºç°çš„å…³é”®é“å…·åˆ—è¡¨\"},\n",
    "#         \"å‡ºç°åœºæ™¯\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"æœ¬ç« å‘ç”Ÿæ•…äº‹çš„ä¸»è¦åœºæ™¯åˆ—è¡¨\"},\n",
    "#         \"ä¼ç¬”_è®¾ä¸‹\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"æœ¬ç« æ–°åŸ‹ä¸‹çš„ä¼ç¬”æè¿°\"},\n",
    "#         \"ä¼ç¬”_å›æ”¶\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"æœ¬ç« å›æ”¶æˆ–å‘¼åº”çš„è¿‡å¾€ä¼ç¬”æè¿°\"}\n",
    "#     },\n",
    "#     \"required\": [\"æƒ…èŠ‚æ‘˜è¦å¯¼è¯­\", \"å‡ºç°äººç‰©\", \"å‡ºç°é“å…·\", \"å‡ºç°åœºæ™¯\", \"ä¼ç¬”_è®¾ä¸‹\", \"ä¼ç¬”_å›æ”¶\"]\n",
    "# }\n",
    "\n",
    "# prompt_chapter_template = r\"\"\"\n",
    "# ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ–‡å­¦ç¼–è¾‘ã€‚è¯·ä»”ç»†é˜…è¯»æˆ‘æä¾›çš„ã€ç« èŠ‚å…¨æ–‡ã€‘ã€‚\n",
    "# ä½ çš„ä»»åŠ¡æ˜¯æå–ç»“æ„åŒ–ä¿¡æ¯ï¼Œå¹¶ **å¿…é¡»** è°ƒç”¨ `extract_chapter_details` å‡½æ•°æ¥è¿”å›ç»“æœã€‚\n",
    "# è¯·ä¸¥æ ¼æŒ‰ç…§å‡½æ•°å‚æ•°çš„æè¿°ï¼ˆç‰¹åˆ«æ˜¯å…³äºâ€œæƒ…èŠ‚æ‘˜è¦å¯¼è¯­â€çš„è¯¦ç»†ç¨‹åº¦è¦æ±‚ï¼‰æ¥å¡«å……ä¿¡æ¯ã€‚\n",
    "# **ç»å¯¹ä¸è¦** è¾“å‡ºä»»ä½• JSON æ ¼å¼ä¹‹å¤–çš„æ–‡æœ¬ã€è§£é‡Šã€ä»£ç å—æ ‡è®°ï¼ˆå¦‚ ```json ... ```ï¼‰æˆ– Markdownã€‚\n",
    "# ç›´æ¥è°ƒç”¨å‡½æ•°å¹¶å¡«å……å…¶å‚æ•°ã€‚\n",
    "\n",
    "# ã€ç« èŠ‚å…¨æ–‡ã€‘ï¼š\n",
    "# {chapter_text}\n",
    "# \"\"\"\n",
    "\n",
    "# # --- (analyze_chapter å‡½æ•° - ä¸ä¸Šä¸€ç‰ˆæœ¬ä¿®å¤åç›¸åŒ) ---\n",
    "# def analyze_chapter(\n",
    "#     path: Path,\n",
    "#     prompt_template: str,\n",
    "#     summary_description: str,\n",
    "#     retries: int = 3\n",
    "# ) -> str | None:\n",
    "#     text = _auto_decode(path)\n",
    "#     if not text: return None\n",
    "#     full_prompt = prompt_template.format(chapter_text=text)\n",
    "#     current_schema = copy.deepcopy(base_json_schema)\n",
    "#     current_schema[\"properties\"][\"æƒ…èŠ‚æ‘˜è¦å¯¼è¯­\"][\"description\"] = summary_description\n",
    "#     extract_details_func_declaration = {\n",
    "#         \"name\": \"extract_chapter_details\",\n",
    "#         \"description\": \"æå–å°è¯´ç« èŠ‚çš„ç»“æ„åŒ–ä¿¡æ¯...\",\n",
    "#         \"parameters\": current_schema\n",
    "#     }\n",
    "#     safety_settings = { HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE, HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE, HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE, HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE, }\n",
    "#     try:\n",
    "#         gemini_model = genai.GenerativeModel(GEMINI_MODEL, safety_settings=safety_settings)\n",
    "#     except Exception as model_init_err:\n",
    "#         logging.error(f\"åˆå§‹åŒ– Gemini æ¨¡å‹æ—¶å‡ºé”™: {model_init_err}\", exc_info=True)\n",
    "#         return None\n",
    "\n",
    "#     for attempt in range(retries):\n",
    "#         func_call_args_raw = None\n",
    "#         try:\n",
    "#             logging.info(f\"å¼€å§‹åˆ†æç« èŠ‚: {path.name} (æ‘˜è¦è¦æ±‚: '{summary_description}', å°è¯• {attempt + 1}/{retries})\")\n",
    "#             rsp = gemini_model.generate_content(full_prompt, generation_config={\"temperature\": 0.3}, tools=[{\"function_declarations\": [extract_details_func_declaration]}], tool_config={'function_calling_config': 'ANY'})\n",
    "#             if not rsp.candidates: logging.warning(f\"åˆ†æå¤±è´¥ (å°è¯• {attempt + 1}): API æœªè¿”å›å€™é€‰å†…å®¹ã€‚\"); time.sleep(2 ** attempt + random.uniform(0, 1)); continue\n",
    "#             first_candidate = rsp.candidates[0]\n",
    "#             if not first_candidate.content or not first_candidate.content.parts:\n",
    "#                 if first_candidate.finish_reason == genai.types.FinishReason.SAFETY: logging.warning(f\"åˆ†æå¤±è´¥ (å°è¯• {attempt + 1}): å†…å®¹è¢«å®‰å…¨è®¾ç½®é˜»æ­¢ã€‚\")\n",
    "#                 else: logging.warning(f\"åˆ†æå¤±è´¥ (å°è¯• {attempt + 1}): å€™é€‰å†…å®¹ä¸ºç©ºã€‚åŸå› : {first_candidate.finish_reason}\")\n",
    "#                 time.sleep(2 ** attempt + random.uniform(0, 1)); continue\n",
    "#             func_call_part = None\n",
    "#             for part in first_candidate.content.parts:\n",
    "#                 if part.function_call: func_call_part = part; break\n",
    "#             if func_call_part and func_call_part.function_call:\n",
    "#                 fc = func_call_part.function_call\n",
    "#                 func_call_args_raw = fc.args\n",
    "#                 if fc.name == \"extract_chapter_details\":\n",
    "#                     logging.info(f\"æˆåŠŸåˆ†æç« èŠ‚: {path.name} (æ‘˜è¦è¦æ±‚: '{summary_description}')\")\n",
    "#                     try:\n",
    "#                         args_dict_shallow = dict(fc.args)\n",
    "#                         args_dict_native = {}\n",
    "#                         for key, value in args_dict_shallow.items():\n",
    "#                             if type(value).__name__ == 'RepeatedComposite':\n",
    "#                                 args_dict_native[key] = list(value)\n",
    "#                             else:\n",
    "#                                 args_dict_native[key] = value\n",
    "#                         json_output = json.dumps(args_dict_native, ensure_ascii=False, indent=2)\n",
    "#                         return json_output\n",
    "#                     except TypeError as json_err:\n",
    "#                         logging.error(f\"åºåˆ—åŒ–å‚æ•°æ—¶å‡ºé”™: {json_err}\", exc_info=False)\n",
    "#                         logging.error(f\"  åŸå§‹å‚æ•°ç±»å‹: {type(func_call_args_raw)}\")\n",
    "#                         logging.error(f\"  æµ…å±‚å­—å…¸ (éƒ¨åˆ†): {str(args_dict_shallow)[:500]}...\")\n",
    "#                         time.sleep(2 ** attempt + random.uniform(0, 1)); continue # Go to next retry on serialization error\n",
    "#                 else: logging.warning(f\"åˆ†æè­¦å‘Š (å°è¯• {attempt + 1}): è°ƒç”¨äº†æ„å¤–å‡½æ•° '{fc.name}'\")\n",
    "#             else:\n",
    "#                 finish_reason = first_candidate.finish_reason; safety_ratings = first_candidate.safety_ratings\n",
    "#                 logging.warning(f\"åˆ†æå¤±è´¥ (å°è¯• {attempt + 1}): æœªæ‰¾åˆ°å‡½æ•°è°ƒç”¨ã€‚åŸå› : {finish_reason}\")\n",
    "#                 if safety_ratings: logging.warning(f\"  å®‰å…¨è¯„çº§: {safety_ratings}\")\n",
    "#                 try: text_output = first_candidate.text\n",
    "#                 except ValueError: text_output = str(first_candidate.content.parts[0]) if first_candidate.content and first_candidate.content.parts else \"\"\n",
    "#                 if text_output: logging.warning(f\"  æ¨¡å‹è¿”å›å†…å®¹ (éƒ¨åˆ†): {text_output[:200]}...\")\n",
    "#             time.sleep(2 ** attempt + random.uniform(0, 1)) # Wait before next retry if this attempt failed here\n",
    "#         except Exception as e:\n",
    "#             error_context = f\" | å‚æ•°ç±»å‹: {type(func_call_args_raw)}, å†…å®¹ (éƒ¨åˆ†): {str(func_call_args_raw)[:200]}...\" if func_call_args_raw else \"\"\n",
    "#             logging.error(f\"API è°ƒç”¨æˆ–å¤„ç†æ—¶å‘ç”Ÿå¼‚å¸¸ (å°è¯• {attempt + 1}): {e}{error_context}\", exc_info=True)\n",
    "#             time.sleep(2 ** attempt + random.uniform(0, 1)) # Wait before next retry on general exception\n",
    "#     logging.error(f\"âŒ åˆ†æå¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {path.name} (æ‘˜è¦è¦æ±‚: '{summary_description}')\")\n",
    "#     return None\n",
    "\n",
    "\n",
    "# # --- (run_analysis å‡½æ•° - ä¸ä¸Šä¸€ç‰ˆæœ¬ç›¸åŒ) ---\n",
    "# def run_analysis(chapter_root: str, prompt_template: str, summary_description: str, out_dir: str, mode: tuple[int, int] = (1, 150)):\n",
    "#     root = Path(chapter_root); out_base = Path(out_dir)\n",
    "#     if not root.is_dir(): logging.error(f\"é”™è¯¯ï¼šè¾“å…¥ç›®å½• '{chapter_root}' ä¸å­˜åœ¨ã€‚\"); return\n",
    "#     out_base.mkdir(parents=True, exist_ok=True)\n",
    "#     logging.info(f\"å¼€å§‹æ‰¹é‡åˆ†æ (æ‘˜è¦è¦æ±‚: '{summary_description}'), è¾“å‡ºåˆ°: {out_base}\")\n",
    "#     books = [d for d in root.iterdir() if d.is_dir()]\n",
    "#     if not books: logging.warning(f\"åœ¨ '{chapter_root}' ä¸‹æœªæ‰¾åˆ°ä»»ä½•å°è¯´å­ç›®å½•ã€‚\"); return\n",
    "#     s, e = mode; logging.info(f\"å¤„ç†ç« èŠ‚èŒƒå›´: {s} åˆ° {e}\")\n",
    "#     total_processed, total_failed, total_skipped = 0, 0, 0\n",
    "#     for book in tqdm(books, desc=\"ğŸ“š å¤„ç†å°è¯´ä¹¦ç›®\"):\n",
    "#         chapters = sorted([p for p in book.glob(\"*.txt\") if p.name[:3].isdigit() and s <= int(p.name[:3]) <= e], key=lambda p: int(p.name[:3]))\n",
    "#         if not chapters: logging.warning(f\"åœ¨ '{book.name}' ç›®å½•ä¸­æœªæ‰¾åˆ°ç¬¦åˆèŒƒå›´ {s}-{e} çš„ç« èŠ‚æ–‡ä»¶ã€‚\"); continue\n",
    "#         out_book_dir = out_base / book.name; out_book_dir.mkdir(parents=True, exist_ok=True)\n",
    "#         processed_count, failed_count, skipped_count = 0, 0, 0\n",
    "#         for chap_path in tqdm(chapters, desc=f\"ğŸ“– åˆ†æ '{book.name}'\", leave=False):\n",
    "#             out_filename = f\"{chap_path.stem}_analysis.json\"; out_path = out_book_dir / out_filename\n",
    "#             if out_path.exists(): skipped_count += 1; continue\n",
    "#             try:\n",
    "#                 result_json = analyze_chapter(chap_path, prompt_template, summary_description)\n",
    "#                 if result_json: out_path.write_text(result_json, encoding=\"utf-8\"); processed_count += 1\n",
    "#                 else: failed_count += 1\n",
    "#             except Exception as e: logging.error(f\"å¤„ç†ç« èŠ‚ {chap_path.name} æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}\", exc_info=True); failed_count += 1\n",
    "#         logging.info(f\"å®Œæˆå¤„ç† '{book.name}': {processed_count} æˆåŠŸ, {failed_count} å¤±è´¥, {skipped_count} è·³è¿‡ã€‚\")\n",
    "#         total_processed += processed_count; total_failed += failed_count; total_skipped += skipped_count\n",
    "#     # Ensure the final message regarding where results are saved uses the correct base directory variable\n",
    "#     print(f\"\\nâœ… JSON åˆ†æå®Œæˆã€‚æ€»è®¡: {total_processed} æˆåŠŸ, {total_failed} å¤±è´¥, {total_skipped} è·³è¿‡ã€‚\")\n",
    "#     print(f\"  JSON ç»“æœä¿å­˜åœ¨: {out_dir}\") # Use out_dir specific to this run_analysis call\n",
    "\n",
    "\n",
    "# # --- (JSON è½¬ TXT åŠåˆå¹¶åŠŸèƒ½ - format_list_output, convert_json_to_txt, merge_txt_outlines, run_post_processing - ä¸ä¸Šä¸€ç‰ˆæœ¬ç›¸åŒ) ---\n",
    "\n",
    "# def format_list_output(items: List[str]) -> str:\n",
    "#     \"\"\"Helper function to format lists for TXT output.\"\"\"\n",
    "#     if not items: return \"- æ— \"\n",
    "#     return \"\\n\".join(f\"- {item}\" for item in items)\n",
    "\n",
    "# def convert_json_to_txt(json_path: Path, txt_path: Path) -> bool:\n",
    "#     \"\"\"Reads JSON analysis file, writes formatted TXT outline.\"\"\"\n",
    "#     try:\n",
    "#         with open(json_path, 'r', encoding='utf-8') as f: data = json.load(f)\n",
    "#         chapter_title = json_path.stem.replace(\"_analysis\", \"\")\n",
    "#         output_lines = [\n",
    "#             f\"ç« èŠ‚ï¼š{chapter_title}\", \"\\nã€æƒ…èŠ‚æ‘˜è¦å¯¼è¯­ã€‘\", data.get(\"æƒ…èŠ‚æ‘˜è¦å¯¼è¯­\", \"N/A\"),\n",
    "#             \"\\nã€å‡ºç°äººç‰©ã€‘\", format_list_output(data.get(\"å‡ºç°äººç‰©\", [])),\n",
    "#             \"\\nã€å‡ºç°é“å…·ã€‘\", format_list_output(data.get(\"å‡ºç°é“å…·\", [])),\n",
    "#             \"\\nã€å‡ºç°åœºæ™¯ã€‘\", format_list_output(data.get(\"å‡ºç°åœºæ™¯\", [])),\n",
    "#             \"\\nã€ä¼ç¬”_è®¾ä¸‹ã€‘\", format_list_output(data.get(\"ä¼ç¬”_è®¾ä¸‹\", [])),\n",
    "#             \"\\nã€ä¼ç¬”_å›æ”¶ã€‘\", format_list_output(data.get(\"ä¼ç¬”_å›æ”¶\", [])),\n",
    "#             \"\\n\" + \"-\" * 40 + \"\\n\"\n",
    "#         ]\n",
    "#         txt_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "#         with open(txt_path, 'w', encoding='utf-8') as f: f.write(\"\\n\".join(output_lines))\n",
    "#         return True\n",
    "#     except FileNotFoundError: logging.error(f\"JSON æ–‡ä»¶æœªæ‰¾åˆ°: {json_path}\"); return False\n",
    "#     except json.JSONDecodeError: logging.error(f\"æ— æ³•è§£æ JSON æ–‡ä»¶: {json_path}\"); return False\n",
    "#     except Exception as e: logging.error(f\"è½¬æ¢ {json_path.name} åˆ° TXT æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}\", exc_info=True); return False\n",
    "\n",
    "# def merge_txt_outlines(txt_dir: Path, output_file: Path) -> bool:\n",
    "#     \"\"\"Merges all chapter TXT outlines in a directory into a single file.\"\"\"\n",
    "#     try:\n",
    "#         chapter_files = list(txt_dir.glob(\"*_outline.txt\"))\n",
    "#         if not chapter_files: logging.warning(f\"åœ¨ç›®å½• {txt_dir} ä¸­æœªæ‰¾åˆ°è¦åˆå¹¶çš„ TXT æ–‡ä»¶ (*_outline.txt)ã€‚\"); return False\n",
    "#         def get_chapter_num(file_path: Path) -> int:\n",
    "#             try: match = re.match(r\"(\\d+)\", file_path.name); return int(match.group(1)) if match else float('inf')\n",
    "#             except ValueError: return float('inf')\n",
    "#         chapter_files.sort(key=get_chapter_num)\n",
    "#         merged_content = []\n",
    "#         logging.info(f\"å¼€å§‹åˆå¹¶ {len(chapter_files)} ä¸ª TXT æ–‡ä»¶åˆ° {output_file.name}...\")\n",
    "#         for chap_file in tqdm(chapter_files, desc=f\"  åˆå¹¶ TXT\", leave=False):\n",
    "#             try:\n",
    "#                 with open(chap_file, 'r', encoding='utf-8') as f: merged_content.append(f.read())\n",
    "#             except Exception as e: logging.error(f\"è¯»å– TXT æ–‡ä»¶ {chap_file.name} æ—¶å‡ºé”™: {e}\")\n",
    "#         if not merged_content: logging.error(f\"æœªèƒ½è¯»å–ä»»ä½• TXT æ–‡ä»¶å†…å®¹è¿›è¡Œåˆå¹¶ã€‚\"); return False\n",
    "#         output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "#         with open(output_file, 'w', encoding='utf-8') as f: f.write(\"\".join(merged_content))\n",
    "#         logging.info(f\"æˆåŠŸåˆå¹¶ TXT æ–‡ä»¶åˆ°: {output_file}\")\n",
    "#         return True\n",
    "#     except Exception as e: logging.error(f\"åˆå¹¶ TXT æ–‡ä»¶åˆ° {output_file.name} æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}\", exc_info=True); return False\n",
    "\n",
    "# def run_post_processing(base_json_dir: str):\n",
    "#     \"\"\"Runs JSON-to-TXT conversion and merging for all books in a base directory.\"\"\"\n",
    "#     base_path = Path(base_json_dir)\n",
    "#     if not base_path.is_dir(): logging.warning(f\"è·³è¿‡åæœŸå¤„ç†ï¼šç›®å½• {base_path} ä¸å­˜åœ¨ã€‚\"); return\n",
    "#     logging.info(f\"\\n{'='*20} å¼€å§‹å¯¹ '{base_path.name}' è¿›è¡ŒåæœŸå¤„ç† (TXT ç”Ÿæˆä¸åˆå¹¶) {'='*20}\")\n",
    "#     book_dirs = [d for d in base_path.iterdir() if d.is_dir()]\n",
    "#     if not book_dirs: logging.warning(f\"åœ¨ {base_path} ä¸­æœªæ‰¾åˆ°ä¹¦ç±å­ç›®å½•è¿›è¡ŒåæœŸå¤„ç†ã€‚\"); return\n",
    "#     total_books_processed, total_books_failed = 0, 0\n",
    "#     for book_json_dir in tqdm(book_dirs, desc=\"ğŸ“š å¤„ç†ä¹¦ç± (åæœŸ)\"):\n",
    "#         book_name = book_json_dir.name\n",
    "#         book_txt_outlines_dir = book_json_dir / f\"{book_name}_txt_outlines\"\n",
    "#         merged_output_file = base_path / f\"{book_name}_å®Œæ•´ç»†çº².txt\" # Save merged file one level up\n",
    "#         logging.info(f\"å¤„ç†ä¹¦ç± '{book_name}': JSON={book_json_dir}, TXT={book_txt_outlines_dir}, Merged={merged_output_file}\")\n",
    "#         json_files = list(book_json_dir.glob(\"*_analysis.json\"))\n",
    "#         if not json_files: logging.warning(f\"  åœ¨ {book_json_dir} ä¸­æœªæ‰¾åˆ° JSON æ–‡ä»¶è¿›è¡Œè½¬æ¢ã€‚\"); continue\n",
    "#         conversion_success_count, conversion_fail_count = 0, 0\n",
    "#         logging.info(f\"  å¼€å§‹è½¬æ¢ {len(json_files)} ä¸ª JSON æ–‡ä»¶åˆ° TXT...\")\n",
    "#         for json_file in tqdm(json_files, desc=f\"  è½¬æ¢ JSON\", leave=False):\n",
    "#             txt_filename = json_file.stem.replace(\"_analysis\", \"_outline.txt\")\n",
    "#             txt_file_path = book_txt_outlines_dir / txt_filename\n",
    "#             if convert_json_to_txt(json_file, txt_file_path): conversion_success_count += 1\n",
    "#             else: conversion_fail_count += 1\n",
    "#         logging.info(f\"  JSON åˆ° TXT è½¬æ¢å®Œæˆ: {conversion_success_count} æˆåŠŸ, {conversion_fail_count} å¤±è´¥ã€‚\")\n",
    "#         if conversion_success_count == 0:\n",
    "#             logging.error(f\"  æœªèƒ½æˆåŠŸè½¬æ¢ä»»ä½• JSON æ–‡ä»¶ä¸º TXTï¼Œè·³è¿‡åˆå¹¶æ­¥éª¤ã€‚\"); total_books_failed += 1; continue\n",
    "#         if merge_txt_outlines(book_txt_outlines_dir, merged_output_file): total_books_processed += 1\n",
    "#         else: total_books_failed +=1; logging.error(f\"  æœªèƒ½æˆåŠŸåˆå¹¶ '{book_name}' çš„ TXT ç»†çº²ã€‚\")\n",
    "#     logging.info(f\"\\n{'='*20} '{base_path.name}' åæœŸå¤„ç†å®Œæˆ {'='*20}\")\n",
    "#     logging.info(f\"  æˆåŠŸç”Ÿæˆå®Œæ•´ç»†çº²çš„ä¹¦ç±æ•°é‡: {total_books_processed}\")\n",
    "#     logging.info(f\"  å¤„ç†å¤±è´¥æˆ–æœªå®Œæˆçš„ä¹¦ç±æ•°é‡: {total_books_failed}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63534fe5-ddaa-44a2-a682-7d01076e0f0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # ========================================\n",
    "# # ==           ä¸»ç¨‹åºå…¥å£ (æ›´æ–°)        ==\n",
    "# # ========================================\n",
    "# if __name__ == \"__main__\":\n",
    "#     # å®šä¹‰è¾“å…¥ç›®å½• (â˜…â˜…â˜… æ ¹æ®ä½ çš„å®é™…æƒ…å†µä¿®æ”¹ â˜…â˜…â˜…)\n",
    "#     CHAPTERS_INPUT_DIR = \"/content/novels_normalized\"\n",
    "#     # å®šä¹‰è¾“å‡ºæ ¹ç›®å½• (â˜…â˜…â˜… æ ¹æ®ä½ çš„å®é™…æƒ…å†µä¿®æ”¹ â˜…â˜…â˜…)\n",
    "#     OUTPUT_BASE_DIR = \"/content/json_results/json_gemini_normalized\" # <--- æ›´æ–°\n",
    "\n",
    "#     # --- å®šä¹‰ä¸åŒæ‘˜è¦é•¿åº¦çš„è¦æ±‚ (æ›´æ–°) ---\n",
    "#     summary_req_short = \"ç”Ÿæˆä¸€ä¸ªéå¸¸ç®€çŸ­çš„æ ¸å¿ƒæƒ…èŠ‚æ‘˜è¦ï¼ˆ çº¦ 150-200 å­—ï¼‰\" # <--- æ›´æ–°\n",
    "#     summary_req_medium = \"ç”Ÿæˆä¸€ä¸ªæ ‡å‡†çš„æƒ…èŠ‚æ‘˜è¦ï¼Œæ¦‚æ‹¬ä¸»è¦å†…å®¹ï¼ˆçº¦ 300-400 å­—ï¼‰\" # <--- æ›´æ–°\n",
    "#     summary_req_long = \"ç”Ÿæˆä¸€ä¸ªæ¯”è¾ƒè¯¦ç»†çš„æƒ…èŠ‚æ‘˜è¦ï¼ŒåŒ…å«æ›´å¤šç»†èŠ‚å’Œè½¬æŠ˜ï¼ˆçº¦ 600-700 å­—ï¼‰\" # <--- æ›´æ–°\n",
    "\n",
    "#     # --- è¿è¡Œä¸åŒç‰ˆæœ¬çš„åˆ†æ ---\n",
    "#     # (ä½ å¯ä»¥å–æ¶ˆæ³¨é‡Šæ‰ä¸æƒ³è¿è¡Œçš„ç‰ˆæœ¬)\n",
    "#     analysis_dirs_to_process = [] # Store dirs for post-processing\n",
    "\n",
    "#     logging.info(\"=\"*20 + \" å¼€å§‹ç®€çŸ­æ‘˜è¦åˆ†æ (150-200å­—) \" + \"=\"*20)\n",
    "#     short_summary_dir = os.path.join(OUTPUT_BASE_DIR, \"30000_summary\") # <--- æ›´æ–°\n",
    "#     run_analysis(\n",
    "#         chapter_root=CHAPTERS_INPUT_DIR,\n",
    "#         prompt_template=prompt_chapter_template,\n",
    "#         summary_description=summary_req_short, # ä½¿ç”¨æ›´æ–°åçš„æè¿°\n",
    "#         out_dir=short_summary_dir,             # ä½¿ç”¨æ›´æ–°åçš„ç›®å½•\n",
    "#         mode=(1, 200) # åˆ†æ 1 åˆ° 150 ç« \n",
    "#     )\n",
    "#     analysis_dirs_to_process.append(short_summary_dir) # æ·»åŠ æ›´æ–°åçš„ç›®å½•\n",
    "\n",
    "#     logging.info(\"=\"*20 + \" å¼€å§‹æ ‡å‡†æ‘˜è¦åˆ†æ (300-400å­—) \" + \"=\"*20)\n",
    "#     medium_summary_dir = os.path.join(OUTPUT_BASE_DIR, \"50000_summary\") # <--- æ›´æ–°\n",
    "#     run_analysis(\n",
    "#         chapter_root=CHAPTERS_INPUT_DIR,\n",
    "#         prompt_template=prompt_chapter_template,\n",
    "#         summary_description=summary_req_medium, # ä½¿ç”¨æ›´æ–°åçš„æè¿°\n",
    "#         out_dir=medium_summary_dir,             # ä½¿ç”¨æ›´æ–°åçš„ç›®å½•\n",
    "#         mode=(1, 200)\n",
    "#     )\n",
    "#     analysis_dirs_to_process.append(medium_summary_dir) # æ·»åŠ æ›´æ–°åçš„ç›®å½•\n",
    "\n",
    "#     logging.info(\"=\"*20 + \" å¼€å§‹è¯¦ç»†æ‘˜è¦åˆ†æ (600-700å­—) \" + \"=\"*20)\n",
    "#     long_summary_dir = os.path.join(OUTPUT_BASE_DIR, \"100000_summary\") # <--- æ›´æ–°\n",
    "#     run_analysis(\n",
    "#         chapter_root=CHAPTERS_INPUT_DIR,\n",
    "#         prompt_template=prompt_chapter_template,\n",
    "#         summary_description=summary_req_long, # ä½¿ç”¨æ›´æ–°åçš„æè¿°\n",
    "#         out_dir=long_summary_dir,             # ä½¿ç”¨æ›´æ–°åçš„ç›®å½•\n",
    "#         mode=(1, 200)\n",
    "#     )\n",
    "#     analysis_dirs_to_process.append(long_summary_dir) # æ·»åŠ æ›´æ–°åçš„ç›®å½•\n",
    "\n",
    "#     logging.info(\"\\n\" + \"=\"*20 + \" æ‰€æœ‰ JSON åˆ†æä»»åŠ¡å·²å®Œæˆ/æäº¤ \" + \"=\"*20)\n",
    "\n",
    "#     # --- è¿è¡ŒåæœŸå¤„ç†ï¼šç”Ÿæˆ TXT ç»†çº² ---\n",
    "#     # (è¿™éƒ¨åˆ†ä¿æŒä¸å˜ï¼Œå®ƒä¼šä½¿ç”¨ä¸Šé¢ analysis_dirs_to_process åˆ—è¡¨ä¸­çš„æ–°ç›®å½•)\n",
    "#     logging.info(\"\\n\" + \"=\"*20 + \" å¼€å§‹è¿è¡ŒåæœŸå¤„ç† (ç”Ÿæˆ TXT ç»†çº²) \" + \"=\"*20)\n",
    "#     for dir_to_process in analysis_dirs_to_process:\n",
    "#         run_post_processing(dir_to_process)\n",
    "\n",
    "#     logging.info(\"\\n\" + \"=\"*20 + \" å…¨éƒ¨å¤„ç†æµç¨‹ç»“æŸ \" + \"=\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23063278-384a-45a7-9005-4dfd46c25485",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /content/json_results/json_gemini_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acef1755-6507-435c-afc4-890911d0f092",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š å¤„ç†ä¹¦ç±: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 45.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… å…¨éƒ¨å®Œæˆã€‚æ¦‚è§ˆï¼š\n",
      "                           book  chapters  ok  bad                                                                                          out_file\n",
      "    ã€Šå¥‹æ–—åœ¨æ–°æ˜æœã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_éšè½»é£å»_utf8       149 149    0     /content/json_results/json_gemini/30000_summary_gathered/ã€Šå¥‹æ–—åœ¨æ–°æ˜æœã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_éšè½»é£å»_utf8/å®Œæ•´ç»†çº².txt\n",
      "   ã€Šåæ­£æˆ‘æ˜¯è¶…èƒ½åŠ›è€…ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_åƒä¹¦å¦–_utf8       150 150    0    /content/json_results/json_gemini/30000_summary_gathered/ã€Šåæ­£æˆ‘æ˜¯è¶…èƒ½åŠ›è€…ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_åƒä¹¦å¦–_utf8/å®Œæ•´ç»†çº².txt\n",
      "        ã€Šå¤©å¯æ±—ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_è¥¿é£ç´§_utf8       150 150    0         /content/json_results/json_gemini/30000_summary_gathered/ã€Šå¤©å¯æ±—ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_è¥¿é£ç´§_utf8/å®Œæ•´ç»†çº².txt\n",
      "ã€Šå´©åä¸–ç•Œçš„ä¼ å¥‡å¤§å†’é™©ã€‹(ç²¾æ ¡ç‰ˆå…¨æœ¬)ä½œè€…_å›½ç‹é™›ä¸‹_utf8       145 145    0 /content/json_results/json_gemini/30000_summary_gathered/ã€Šå´©åä¸–ç•Œçš„ä¼ å¥‡å¤§å†’é™©ã€‹(ç²¾æ ¡ç‰ˆå…¨æœ¬)ä½œè€…_å›½ç‹é™›ä¸‹_utf8/å®Œæ•´ç»†çº².txt\n",
      "        ã€Šå…¨çƒè¿›åŒ–ã€‹(ç²¾æ ¡ç‰ˆå…¨æœ¬)ä½œè€…_å’¬ç‹—_utf8       150 150    0         /content/json_results/json_gemini/30000_summary_gathered/ã€Šå…¨çƒè¿›åŒ–ã€‹(ç²¾æ ¡ç‰ˆå…¨æœ¬)ä½œè€…_å’¬ç‹—_utf8/å®Œæ•´ç»†çº².txt\n",
      "      ã€Šæ­¦æ—åŠä¾ ä¼ ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_æ–‡æŠ„å…¬_utf8       150 150    0       /content/json_results/json_gemini/30000_summary_gathered/ã€Šæ­¦æ—åŠä¾ ä¼ ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_æ–‡æŠ„å…¬_utf8/å®Œæ•´ç»†çº².txt\n",
      "                        å›½å®´å¤§å¨åœ¨å…«é›¶       659 659    0                         /content/json_results/json_gemini/30000_summary_gathered/å›½å®´å¤§å¨åœ¨å…«é›¶/å®Œæ•´ç»†çº².txt\n",
      "       ã€Šæœç¥è®°ã€‹(ç²¾æ ¡ç‰ˆå…¨æœ¬)ä½œè€…_æ ‘ä¸‹é‡ç‹_utf8       131 131    0        /content/json_results/json_gemini/30000_summary_gathered/ã€Šæœç¥è®°ã€‹(ç²¾æ ¡ç‰ˆå…¨æœ¬)ä½œè€…_æ ‘ä¸‹é‡ç‹_utf8/å®Œæ•´ç»†çº².txt\n",
      "                     é‡ç”Ÿå…«é›¶_æ¯’å¦»ä¸å¥½æƒ¹       149 149    0                      /content/json_results/json_gemini/30000_summary_gathered/é‡ç”Ÿå…«é›¶_æ¯’å¦»ä¸å¥½æƒ¹/å®Œæ•´ç»†çº².txt\n",
      "    ã€Šçªƒæ˜ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_å¤§çˆ†ç‚¸(ç°ç†ŠçŒ«)_utf8       143 143    0     /content/json_results/json_gemini/30000_summary_gathered/ã€Šçªƒæ˜ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_å¤§çˆ†ç‚¸(ç°ç†ŠçŒ«)_utf8/å®Œæ•´ç»†çº².txt\n",
      "       ã€Šèœ€å±±ã€‹(ç²¾æ ¡ç‰ˆå…¨æœ¬)ä½œè€…_æµæµªçš„è›¤èŸ†_utf8       141 141    0        /content/json_results/json_gemini/30000_summary_gathered/ã€Šèœ€å±±ã€‹(ç²¾æ ¡ç‰ˆå…¨æœ¬)ä½œè€…_æµæµªçš„è›¤èŸ†_utf8/å®Œæ•´ç»†çº².txt\n",
      " ã€Šé™ˆäºŒç‹—çš„å¦–å­½äººç”Ÿã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_çƒ½ç«æˆè¯¸ä¾¯_utf8       141 141    0  /content/json_results/json_gemini/30000_summary_gathered/ã€Šé™ˆäºŒç‹—çš„å¦–å­½äººç”Ÿã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_çƒ½ç«æˆè¯¸ä¾¯_utf8/å®Œæ•´ç»†çº².txt\n",
      "        ã€Šè´©ç½ªã€‹(ç²¾æ ¡ç‰ˆå…¨æœ¬)ä½œè€…_ä¸‰å¤©ä¸¤è§‰_utf8       147 147    0         /content/json_results/json_gemini/30000_summary_gathered/ã€Šè´©ç½ªã€‹(ç²¾æ ¡ç‰ˆå…¨æœ¬)ä½œè€…_ä¸‰å¤©ä¸¤è§‰_utf8/å®Œæ•´ç»†çº².txt\n",
      "  ã€Šé‡ç”Ÿä¹‹å‡ºäººå¤´åœ°ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_é—¹é—¹ä¸çˆ±é—¹_utf8       149 149    0   /content/json_results/json_gemini/30000_summary_gathered/ã€Šé‡ç”Ÿä¹‹å‡ºäººå¤´åœ°ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_é—¹é—¹ä¸çˆ±é—¹_utf8/å®Œæ•´ç»†çº².txt\n",
      "                   å…«é›¶å–œäº‹_å½“å®¶è‚¥å¦»å¤§ç¿»èº«       660 660    0                    /content/json_results/json_gemini/30000_summary_gathered/å…«é›¶å–œäº‹_å½“å®¶è‚¥å¦»å¤§ç¿»èº«/å®Œæ•´ç»†çº².txt\n",
      "        ã€Šè‚†è™éŸ©å¨±ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_å§¬å‰_utf8       146 146    0         /content/json_results/json_gemini/30000_summary_gathered/ã€Šè‚†è™éŸ©å¨±ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_å§¬å‰_utf8/å®Œæ•´ç»†çº².txt\n",
      "                        å…«é›¶å¹´ä»£å¥½æ—¶å…‰       436 436    0                         /content/json_results/json_gemini/30000_summary_gathered/å…«é›¶å¹´ä»£å¥½æ—¶å…‰/å®Œæ•´ç»†çº².txt\n",
      "   ã€Šé£Ÿç‰©é“¾é¡¶ç«¯çš„ç”·äººã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_ç†Šç‹¼ç‹—_utf8       150 150    0    /content/json_results/json_gemini/30000_summary_gathered/ã€Šé£Ÿç‰©é“¾é¡¶ç«¯çš„ç”·äººã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_ç†Šç‹¼ç‹—_utf8/å®Œæ•´ç»†çº².txt\n",
      "     ã€Šé«˜æ‰‹å¯‚å¯2ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_å…°å¸é­…æ™¨_utf8       646 646    0      /content/json_results/json_gemini/30000_summary_gathered/ã€Šé«˜æ‰‹å¯‚å¯2ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_å…°å¸é­…æ™¨_utf8/å®Œæ•´ç»†çº².txt\n",
      "        ã€Šé»‘é¾™æ³•å…¸ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_æ¬¢å£°_utf8       148 148    0         /content/json_results/json_gemini/30000_summary_gathered/ã€Šé»‘é¾™æ³•å…¸ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_æ¬¢å£°_utf8/å®Œæ•´ç»†çº².txt\n",
      "          ã€Šè¯›ä»™ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_è§é¼_utf8       150 150    0           /content/json_results/json_gemini/30000_summary_gathered/ã€Šè¯›ä»™ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_è§é¼_utf8/å®Œæ•´ç»†çº².txt\n",
      "   ã€Šå›åˆ°è¿‡å»å˜æˆçŒ«ã€‹(ç²¾æ ¡ç‰ˆå…¨æœ¬)ä½œè€…_é™ˆè¯æ‡’è°ƒ_utf8       149 149    0    /content/json_results/json_gemini/30000_summary_gathered/ã€Šå›åˆ°è¿‡å»å˜æˆçŒ«ã€‹(ç²¾æ ¡ç‰ˆå…¨æœ¬)ä½œè€…_é™ˆè¯æ‡’è°ƒ_utf8/å®Œæ•´ç»†çº².txt\n",
      "       ã€Šç¥æ¸¸ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_å¾å…¬å­èƒœæ²»_utf8       125 125    0        /content/json_results/json_gemini/30000_summary_gathered/ã€Šç¥æ¸¸ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_å¾å…¬å­èƒœæ²»_utf8/å®Œæ•´ç»†çº².txt\n",
      "   ã€Šè€å­æ˜¯ç™è›¤èŸ†ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_çƒ½ç«æˆè¯¸ä¾¯_utf8       150 150    0    /content/json_results/json_gemini/30000_summary_gathered/ã€Šè€å­æ˜¯ç™è›¤èŸ†ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_çƒ½ç«æˆè¯¸ä¾¯_utf8/å®Œæ•´ç»†çº².txt\n",
      "      ã€Šæœªæ¥å¤©ç‹ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_é™ˆè¯æ‡’è°ƒ_utf8       150 150    0       /content/json_results/json_gemini/30000_summary_gathered/ã€Šæœªæ¥å¤©ç‹ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_é™ˆè¯æ‡’è°ƒ_utf8/å®Œæ•´ç»†çº².txt\n",
      "         ã€Šå¤§ç”»å®¶ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_é†›çŸ³_utf8       150 150    0          /content/json_results/json_gemini/30000_summary_gathered/ã€Šå¤§ç”»å®¶ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_é†›çŸ³_utf8/å®Œæ•´ç»†çº².txt\n",
      "       ã€Šäººé“å¤©å ‚ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_è†æŸ¯å®ˆ_utf8       148 148    0        /content/json_results/json_gemini/30000_summary_gathered/ã€Šäººé“å¤©å ‚ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_è†æŸ¯å®ˆ_utf8/å®Œæ•´ç»†çº².txt\n",
      "           ã€Šè¶…çº§æƒŠæ‚šç›´æ’­ã€‹ä½œè€…_å®‡æ–‡é•¿å¼“_utf8       150 150    0            /content/json_results/json_gemini/30000_summary_gathered/ã€Šè¶…çº§æƒŠæ‚šç›´æ’­ã€‹ä½œè€…_å®‡æ–‡é•¿å¼“_utf8/å®Œæ•´ç»†çº².txt\n",
      "      ã€Šé“ç¼˜æµ®å›¾ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_çƒŸé›¨æ±Ÿå—_utf8       150 150    0       /content/json_results/json_gemini/30000_summary_gathered/ã€Šé“ç¼˜æµ®å›¾ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_çƒŸé›¨æ±Ÿå—_utf8/å®Œæ•´ç»†çº².txt\n",
      "         ã€Šé‡æ´»äº†ã€‹(ç²¾æ ¡ç‰ˆå…¨æœ¬)ä½œè€…_å°è°•_utf8       150 150    0          /content/json_results/json_gemini/30000_summary_gathered/ã€Šé‡æ´»äº†ã€‹(ç²¾æ ¡ç‰ˆå…¨æœ¬)ä½œè€…_å°è°•_utf8/å®Œæ•´ç»†çº².txt\n",
      "        ã€Šé›…éªšã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_è´¼é“ä¸‰ç—´_utf8       150 150    0         /content/json_results/json_gemini/30000_summary_gathered/ã€Šé›…éªšã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_è´¼é“ä¸‰ç—´_utf8/å®Œæ•´ç»†çº².txt\n",
      "                        å…«é›¶ç¦æ˜Ÿä¿åª³å¦‡       298 298    0                         /content/json_results/json_gemini/30000_summary_gathered/å…«é›¶ç¦æ˜Ÿä¿åª³å¦‡/å®Œæ•´ç»†çº².txt\n",
      "      ã€Šä¸Šå“å¯’å£«ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_è´¼é“ä¸‰ç—´_utf8       150 150    0       /content/json_results/json_gemini/30000_summary_gathered/ã€Šä¸Šå“å¯’å£«ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_è´¼é“ä¸‰ç—´_utf8/å®Œæ•´ç»†çº².txt\n",
      "       ã€Šåå·é£äº‘å¿—ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_çŸ¥ç§‹_utf8       142 142    0        /content/json_results/json_gemini/30000_summary_gathered/ã€Šåå·é£äº‘å¿—ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_çŸ¥ç§‹_utf8/å®Œæ•´ç»†çº².txt\n",
      "     ã€Šå²ä¸Šç¬¬ä¸€æ··ä¹±ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_å¼ å°èŠ±_utf8       148 148    0      /content/json_results/json_gemini/30000_summary_gathered/ã€Šå²ä¸Šç¬¬ä¸€æ··ä¹±ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_å¼ å°èŠ±_utf8/å®Œæ•´ç»†çº².txt\n",
      " ã€Šéšæ³¢é€æµä¹‹ä¸€ä»£å†›å¸ˆã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_éšæ³¢é€æµ_utf8       150 150    0  /content/json_results/json_gemini/30000_summary_gathered/ã€Šéšæ³¢é€æµä¹‹ä¸€ä»£å†›å¸ˆã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_éšæ³¢é€æµ_utf8/å®Œæ•´ç»†çº².txt\n",
      "                     é‡ç”Ÿå…«é›¶_ä½³å¦»è‡´å¯Œå¿™       659 659    0                      /content/json_results/json_gemini/30000_summary_gathered/é‡ç”Ÿå…«é›¶_ä½³å¦»è‡´å¯Œå¿™/å®Œæ•´ç»†çº².txt\n",
      "                       é‡å›å…«é›¶è¿‡å¥½æ—¥å­       660 660    0                        /content/json_results/json_gemini/30000_summary_gathered/é‡å›å…«é›¶è¿‡å¥½æ—¥å­/å®Œæ•´ç»†çº².txt\n",
      "     ã€Šç»å¯¹ä¸€ç•ªã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_æµ·åº•æ¼«æ­¥è€…_utf8       147 147    0      /content/json_results/json_gemini/30000_summary_gathered/ã€Šç»å¯¹ä¸€ç•ªã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_æµ·åº•æ¼«æ­¥è€…_utf8/å®Œæ•´ç»†çº².txt\n",
      "  ã€Šæˆ‘çš„å¥³å‹æ˜¯æ¶å¥³ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_æµ·åº•æ¼«æ­¥è€…_utf8       150 150    0   /content/json_results/json_gemini/30000_summary_gathered/ã€Šæˆ‘çš„å¥³å‹æ˜¯æ¶å¥³ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_æµ·åº•æ¼«æ­¥è€…_utf8/å®Œæ•´ç»†çº².txt\n",
      "\n",
      "æ‰€æœ‰ TXT å·²è¾“å‡ºè‡³ï¼š/content/json_results/json_gemini/30000_summary_gathered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# # ===============================================================\n",
    "# # ä¸€é”®æŠŠ *_analysis.json â†’ æ¯æœ¬ä¹¦ä¸€ä¸ªã€Šå®Œæ•´ç»†çº².txtã€‹\n",
    "# # æ”¯æŒæ–‡ä»¶åå½¢æ€ï¼š\n",
    "# #   118_ç¬¬äºŒåå…«ç« xxx_analysis.json\n",
    "# #   ç¬¬005ç« _xxx_analysis.json\n",
    "# #   ä¹¦å_001_analysis.jsonï¼ˆä¹ŸOKï¼‰\n",
    "# #   â€”â€”æ ¸å¿ƒï¼šæ–‡ä»¶åé‡Œ**ç¬¬ä¸€ä¸ªæ•°å­—**è®¤ä¸ºæ˜¯ç« å·ï¼Œ\n",
    "# #   ä¹¦åç›´æ¥å–æœ€å¤–å±‚æ–‡ä»¶å¤¹åã€‚\n",
    "# # ===============================================================\n",
    "\n",
    "# #!pip install -q tqdm pandas          # â† å¦‚æœ¬ç¯å¢ƒå·²è£…å¯æ³¨é‡Š\n",
    "\n",
    "# from pathlib import Path\n",
    "# import re, json, tqdm, logging, pandas as pd\n",
    "\n",
    "# # ================= ä¿®æ”¹è¿™é‡Œ =================\n",
    "# JSON_ROOT    = Path(\"/content/json_results/json_gemini_normalized/30000_summary\")   # æ”¾ JSON çš„æ ¹ç›®å½•\n",
    "# TXT_OUT_ROOT = Path(\"/content/json_results/json_gemini_normalized/30000_summary_gathered\")                # è¾“å‡ºæ ¹ç›®å½•\n",
    "# # ============================================\n",
    "# TXT_OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# logging.basicConfig(level=logging.INFO,\n",
    "#                     format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "# # ---------- ç®€å•å·¥å…· ----------\n",
    "# DIGIT_RE = re.compile(r\"(\\d{1,4})\")          # æŠ“ 1-4 ä½ç« å·\n",
    "\n",
    "# def pick_book_and_chapter(path: Path):\n",
    "#     \"\"\"è¿”å› (book_id, chap_no)ï¼›è¯†åˆ«å¤±è´¥ â†’ None\"\"\"\n",
    "#     book_id = path.parent.name               # çˆ¶æ–‡ä»¶å¤¹åå³ä¹¦å\n",
    "#     m = DIGIT_RE.match(path.stem) or DIGIT_RE.search(path.stem)\n",
    "#     if not m:\n",
    "#         return None\n",
    "#     return book_id, int(m.group(1))\n",
    "\n",
    "# def bullets(lst):\n",
    "#     return \"- æ— \" if not lst else \"\\n\".join(f\"- {x}\" for x in lst)\n",
    "\n",
    "# def json_to_outline(jp: Path) -> str:\n",
    "#     data = json.loads(jp.read_text(encoding=\"utf-8\"))\n",
    "#     chap_tag = jp.stem.replace(\"_analysis\", \"\")\n",
    "#     return \"\\n\".join([\n",
    "#         f\"ç« èŠ‚ï¼š{chap_tag}\",\n",
    "#         \"\\nã€æƒ…èŠ‚æ‘˜è¦å¯¼è¯­ã€‘\",\n",
    "#         data.get(\"æƒ…èŠ‚æ‘˜è¦å¯¼è¯­\",\"N/A\"),\n",
    "#         \"\\nã€å‡ºç°äººç‰©ã€‘\",\n",
    "#         bullets(data.get(\"å‡ºç°äººç‰©\", [])),\n",
    "#         \"\\nã€å‡ºç°é“å…·ã€‘\",\n",
    "#         bullets(data.get(\"å‡ºç°é“å…·\", [])),\n",
    "#         \"\\nã€å‡ºç°åœºæ™¯ã€‘\",\n",
    "#         bullets(data.get(\"å‡ºç°åœºæ™¯\", [])),\n",
    "#         \"\\nã€ä¼ç¬”_è®¾ä¸‹ã€‘\",\n",
    "#         bullets(data.get(\"ä¼ç¬”_è®¾ä¸‹\", [])),\n",
    "#         \"\\nã€ä¼ç¬”_å›æ”¶ã€‘\",\n",
    "#         bullets(data.get(\"ä¼ç¬”_å›æ”¶\", [])),\n",
    "#         \"\\n\" + \"-\"*40 + \"\\n\"\n",
    "#     ])\n",
    "\n",
    "# # ---------- æŠŠæ‰€æœ‰ JSON å½’ç°‡ ----------\n",
    "# book_files = {}\n",
    "# for jp in JSON_ROOT.rglob(\"*_analysis.json\"):\n",
    "#     res = pick_book_and_chapter(jp)\n",
    "#     if not res:\n",
    "#         logging.warning(f\"è·³è¿‡æ— æ³•è¯†åˆ«æ–‡ä»¶å: {jp}\")\n",
    "#         continue\n",
    "#     book, chap = res\n",
    "#     book_files.setdefault(book, []).append((chap, jp))\n",
    "\n",
    "# if not book_files:\n",
    "#     raise SystemExit(f\"âŒ åœ¨ {JSON_ROOT} ä¸‹æ²¡æ‰¾åˆ° *_analysis.json\")\n",
    "\n",
    "# # ---------- é€ä¹¦å†™ TXT ----------\n",
    "# stats = []\n",
    "# for book, lst in tqdm.tqdm(book_files.items(), desc=\"ğŸ“š å¤„ç†ä¹¦ç±\"):\n",
    "#     lst.sort(key=lambda x: x[0])                     # æŒ‰ç« å·\n",
    "#     out_dir = TXT_OUT_ROOT / book\n",
    "#     out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     merged, ok, bad = [], 0, 0\n",
    "#     for num, jp in lst:\n",
    "#         try:\n",
    "#             outline = json_to_outline(jp)\n",
    "#             (out_dir / f\"{num:03}_outline.txt\").write_text(outline, \"utf-8\")\n",
    "#             merged.append(outline); ok += 1\n",
    "#         except Exception as e:\n",
    "#             logging.error(f\"è§£æ {jp} å‡ºé”™: {e}\"); bad += 1\n",
    "\n",
    "#     (out_dir / \"å®Œæ•´ç»†çº².txt\").write_text(\"\".join(merged), \"utf-8\")\n",
    "#     stats.append(dict(book=book, chapters=len(lst), ok=ok, bad=bad,\n",
    "#                       out_file=str(out_dir / 'å®Œæ•´ç»†çº².txt')))\n",
    "\n",
    "# # ---------- æ±‡æ€»æ˜¾ç¤º ----------\n",
    "# df = pd.DataFrame(stats)\n",
    "# print(\"\\nâœ… å…¨éƒ¨å®Œæˆã€‚æ¦‚è§ˆï¼š\")\n",
    "# print(df.to_string(index=False))\n",
    "# print(f\"\\næ‰€æœ‰ TXT å·²è¾“å‡ºè‡³ï¼š{TXT_OUT_ROOT.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "54b69f27-d2e2-4a41-8e12-c67c6b82e386",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š å¤„ç†ä¹¦ç±:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 15/40 [00:00<00:00, 141.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“˜ ã€ã€Šå¥‹æ–—åœ¨æ–°æ˜æœã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šéšè½»é£å»_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 199 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€ã€Šåæ­£æˆ‘æ˜¯è¶…èƒ½åŠ›è€…ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šåƒä¹¦å¦–_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 199 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€ã€Šå¤©å¯æ±—ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šè¥¿é£ç´§_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 198 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€ã€Šå´©åä¸–ç•Œçš„ä¼ å¥‡å¤§å†’é™©ã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå›½ç‹é™›ä¸‹_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 198 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€ã€Šå…¨çƒè¿›åŒ–ã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå’¬ç‹—_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 197 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€ã€Šæ­¦æ—åŠä¾ ä¼ ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šæ–‡æŠ„å…¬_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 200 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€å›½å®´å¤§å¨åœ¨å…«é›¶ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 200 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€ã€Šæœç¥è®°ã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šæ ‘ä¸‹é‡ç‹_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 199 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€é‡ç”Ÿå…«é›¶ï¼šæ¯’å¦»ä¸å¥½æƒ¹ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 200 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€ã€Šçªƒæ˜ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå¤§çˆ†ç‚¸(ç°ç†ŠçŒ«)_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 200 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€ã€Šèœ€å±±ã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šæµæµªçš„è›¤èŸ†_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 200 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€ã€Šé™ˆäºŒç‹—çš„å¦–å­½äººç”Ÿã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šçƒ½ç«æˆè¯¸ä¾¯_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 200 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€ã€Šè´©ç½ªã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šä¸‰å¤©ä¸¤è§‰_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 200 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€ã€Šé‡ç”Ÿä¹‹å‡ºäººå¤´åœ°ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šé—¹é—¹ä¸çˆ±é—¹_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 197 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€å…«é›¶å–œäº‹ï¼šå½“å®¶è‚¥å¦»å¤§ç¿»èº«ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 199 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€ã€Šè‚†è™éŸ©å¨±ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå§¬å‰_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 197 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€å…«é›¶å¹´ä»£å¥½æ—¶å…‰ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 200 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€ã€Šé£Ÿç‰©é“¾é¡¶ç«¯çš„ç”·äººã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šç†Šç‹¼ç‹—_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 199 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€ã€Šé«˜æ‰‹å¯‚å¯2ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå…°å¸é­…æ™¨_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 197 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€ã€Šé»‘é¾™æ³•å…¸ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šæ¬¢å£°_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 200 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€ã€Šè¯›ä»™ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šè§é¼_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 200 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€ã€Šå›åˆ°è¿‡å»å˜æˆçŒ«ã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šé™ˆè¯æ‡’è°ƒ_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 198 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€ã€Šç¥æ¸¸ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå¾å…¬å­èƒœæ²»_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 198 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€ã€Šè€å­æ˜¯ç™è›¤èŸ†ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ ä½œè€…ï¼šçƒ½ç«æˆè¯¸ä¾¯_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 197 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€ã€Šæœªæ¥å¤©ç‹ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šé™ˆè¯æ‡’è°ƒ_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 199 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€ã€Šå¤§ç”»å®¶ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šé†›çŸ³_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 200 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€ã€Šè¶…çº§æƒŠæ‚šç›´æ’­ã€‹ä½œè€…ï¼šå®‡æ–‡é•¿å¼“_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 194 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€ã€Šäººé“å¤©å ‚ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šè†æŸ¯å®ˆ_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 198 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€ã€Šé“ç¼˜æµ®å›¾ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šçƒŸé›¨æ±Ÿå—_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 200 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š å¤„ç†ä¹¦ç±: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<00:00, 137.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“˜ ã€ã€Šé‡æ´»äº†ã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼š å°è°•_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 198 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€ã€Šé›…éªšã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šè´¼é“ä¸‰ç—´_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 198 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€å…«é›¶ç¦æ˜Ÿä¿åª³å¦‡ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 200 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€ã€Šä¸Šå“å¯’å£«ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šè´¼é“ä¸‰ç—´_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 200 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€ã€Šåå·é£äº‘å¿—ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šçŸ¥ç§‹_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 198 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€ã€Šå²ä¸Šç¬¬ä¸€æ··ä¹±ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå¼ å°èŠ±_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 198 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€ã€Šéšæ³¢é€æµä¹‹ä¸€ä»£å†›å¸ˆã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šéšæ³¢é€æµ_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 199 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€é‡ç”Ÿå…«é›¶ï¼šä½³å¦»è‡´å¯Œå¿™ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 197 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€é‡å›å…«é›¶è¿‡å¥½æ—¥å­ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 200 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€ã€Šç»å¯¹ä¸€ç•ªã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šæµ·åº•æ¼«æ­¥è€…_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 198 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n",
      "\n",
      "ğŸ“˜ ã€ã€Šæˆ‘çš„å¥³å‹æ˜¯æ¶å¥³ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šæµ·åº•æ¼«æ­¥è€…_utf8ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± 195 ç« ï¼‰\n",
      "============================================================\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#æ±‡æ€»ç»†çº²\n",
    "from pathlib import Path\n",
    "import re, json, tqdm, logging\n",
    "\n",
    "# ================= ä¿®æ”¹è¿™é‡Œ =================\n",
    "JSON_ROOT    = Path(\"/content/json_results/json_gemini_normalized/50000_summary\")   # JSON è¾“å…¥ç›®å½•\n",
    "TXT_OUT_ROOT = Path(\"/content/json_results/json_gemini_normalized/100000_summary_gathered\")  # è¾“å‡ºç›®å½•\n",
    "# ============================================\n",
    "TXT_OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "DIGIT_RE = re.compile(r\"(\\d{1,4})\")\n",
    "\n",
    "def pick_book_and_chapter(path: Path):\n",
    "    book_id = path.parent.name\n",
    "    m = DIGIT_RE.match(path.stem) or DIGIT_RE.search(path.stem)\n",
    "    if not m:\n",
    "        return None\n",
    "    return book_id, int(m.group(1))\n",
    "\n",
    "def bullets(lst):\n",
    "    return \"- æ— \" if not lst else \"\\n\".join(f\"- {x}\" for x in lst)\n",
    "\n",
    "def json_to_outline(jp: Path) -> str:\n",
    "    data = json.loads(jp.read_text(encoding=\"utf-8\"))\n",
    "    chap_tag = jp.stem.replace(\"_analysis\", \"\")\n",
    "\n",
    "    # åŠ å…¥ç§»é™¤â€œç¬¬nç« â€æ¨¡å¼çš„æ­£åˆ™è¡¨è¾¾å¼\n",
    "    chapter_pattern = re.compile(r'(ç¬¬\\s*[é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡äº¿\\d]+\\s*[ç« èŠ‚å›é›†ç¯‡éƒ¨])|([é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒä¸‡äº¿\\d]+\\s*[ç« èŠ‚å›é›†ç¯‡éƒ¨])')    \n",
    "    summary_intro = chapter_pattern.sub('', data.get(\"æƒ…èŠ‚æ‘˜è¦å¯¼è¯­\", \"N/A\"))\n",
    "\n",
    "    return \"\\n\".join([\n",
    "        f\"ç« èŠ‚ï¼š{chap_tag}\",\n",
    "        \"\\nã€æƒ…èŠ‚æ‘˜è¦å¯¼è¯­ã€‘\",\n",
    "        summary_intro.strip(),\n",
    "        \"\\nã€å‡ºç°äººç‰©ã€‘\",\n",
    "        bullets(data.get(\"å‡ºç°äººç‰©\", [])),\n",
    "        \"\\nã€å‡ºç°é“å…·ã€‘\",\n",
    "        bullets(data.get(\"å‡ºç°é“å…·\", [])),\n",
    "        \"\\nã€å‡ºç°åœºæ™¯ã€‘\",\n",
    "        bullets(data.get(\"å‡ºç°åœºæ™¯\", [])),\n",
    "        \"\\nã€ä¼ç¬”_è®¾ä¸‹ã€‘\",\n",
    "        bullets(data.get(\"ä¼ç¬”_è®¾ä¸‹\", [])),\n",
    "        \"\\nã€ä¼ç¬”_å›æ”¶ã€‘\",\n",
    "        bullets(data.get(\"ä¼ç¬”_å›æ”¶\", [])),\n",
    "        \"\\n\" + \"-\" * 40 + \"\\n\"\n",
    "    ])\n",
    "\n",
    "# ---------- èšåˆ JSON ----------\n",
    "book_files = {}\n",
    "for jp in JSON_ROOT.rglob(\"*_analysis.json\"):\n",
    "    res = pick_book_and_chapter(jp)\n",
    "    if not res:\n",
    "        logging.warning(f\"è·³è¿‡æ— æ³•è¯†åˆ«æ–‡ä»¶å: {jp}\")\n",
    "        continue\n",
    "    book, chap = res\n",
    "    book_files.setdefault(book, []).append((chap, jp))\n",
    "\n",
    "if not book_files:\n",
    "    raise SystemExit(f\"âŒ åœ¨ {JSON_ROOT} ä¸‹æ²¡æ‰¾åˆ° *_analysis.json\")\n",
    "\n",
    "# ---------- æ±‡æ€»å¹¶å†™å…¥ ----------\n",
    "for book, lst in tqdm.tqdm(book_files.items(), desc=\"ğŸ“š å¤„ç†ä¹¦ç±\"):\n",
    "    lst.sort(key=lambda x: x[0])\n",
    "    merged, ok, bad = [], 0, 0\n",
    "    for _, jp in lst:\n",
    "        try:\n",
    "            outline = json_to_outline(jp)\n",
    "            merged.append(outline)\n",
    "            ok += 1\n",
    "        except Exception as e:\n",
    "            logging.error(f\"è§£æ {jp} å‡ºé”™: {e}\")\n",
    "            bad += 1\n",
    "\n",
    "    full_text = \"\".join(merged)\n",
    "    print(f\"\\nğŸ“˜ ã€{book}ã€‘ å®Œæ•´ç»†çº²ï¼ˆå…± {ok} ç« ï¼‰\")\n",
    "    print(\"=\" * 60)\n",
    "    #print(full_text)\n",
    "    print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "    out_dir = TXT_OUT_ROOT / book\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_file = out_dir / \"entire_section_outline.txt\"\n",
    "    out_file.write_text(full_text, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf92233-d584-4b01-a370-f0eceb568008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0168f246-88aa-447b-a920-e516d9ef4135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # =============================\n",
    "# # âœ… Gemini åˆ†æå°è¯´ç« èŠ‚ï¼Œç»“æ„åŒ–è¾“å‡º JSON + TXTç»†çº²ç”Ÿæˆ (ä¸»ç¨‹åºå‚æ•°æ›´æ–°)\n",
    "# # =============================\n",
    "# # !pip install -q --upgrade google-generativeai chardet tqdm\n",
    "# # !pip install -U google-generativeai # ç¡®ä¿å®‰è£…æœ€æ–°ç‰ˆæœ¬\n",
    "\n",
    "# import os\n",
    "# import json\n",
    "# import re\n",
    "# import time\n",
    "# import random\n",
    "# import string\n",
    "# import chardet\n",
    "# import logging\n",
    "# import copy\n",
    "# from pathlib import Path\n",
    "# from typing import List, Dict, Any, Tuple\n",
    "# from tqdm.auto import tqdm\n",
    "# import google.generativeai as genai\n",
    "# from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "\n",
    "# # --- (API åˆå§‹åŒ–, é€šç”¨å‡½æ•°, Schema, Prompt æ¨¡æ¿ - ä¸ä¸Šä¸€ç‰ˆæœ¬ç›¸åŒ) ---\n",
    "\n",
    "# # â€”â€” API åˆå§‹åŒ– (âš ï¸ è­¦å‘Šï¼šç›´æ¥å†™å…¥ API å¯†é’¥æä¸å®‰å…¨ï¼) â€”â€”\n",
    "# api_key = \"your-default-api-key\" # âš ï¸ æ›¿æ¢ä¸ºæ‚¨çš„çœŸå® API å¯†é’¥\n",
    "# if not api_key or api_key == \"YOUR_API_KEY_HERE\":\n",
    "#     raise ValueError(\"âŒ é”™è¯¯ï¼šè¯·åŠ¡å¿…å°†ä»£ç ä¸­çš„ 'YOUR_API_KEY_HERE' æ›¿æ¢ä¸ºæ‚¨çš„çœŸå® Gemini API å¯†é’¥ã€‚\")\n",
    "# try:\n",
    "#     genai.configure(api_key=api_key)\n",
    "#     logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "#     logging.info(\"Gemini API å·²ä½¿ç”¨ç›´æ¥å†™å…¥çš„å¯†é’¥è¿›è¡Œé…ç½®ã€‚\")\n",
    "# except Exception as e:\n",
    "#     print(f\"CRITICAL: ä½¿ç”¨æä¾›çš„ API å¯†é’¥é…ç½® Gemini SDK æ—¶å‡ºé”™: {e}\")\n",
    "#     raise ValueError(f\"API å¯†é’¥é…ç½®å¤±è´¥: {e}\")\n",
    "\n",
    "# GEMINI_MODEL = \"gemini-2.0-flash-latest\"\n",
    "\n",
    "# def _auto_decode(path: Path) -> str:\n",
    "#     try:\n",
    "#         raw = path.read_bytes()\n",
    "#         enc = chardet.detect(raw)[\"encoding\"] or \"utf-8\"\n",
    "#         if enc.lower() not in ['utf-8', 'gbk', 'gb2312', 'big5']:\n",
    "#              try: return raw.decode('utf-8', errors='ignore').strip()\n",
    "#              except UnicodeDecodeError:\n",
    "#                  try: return raw.decode('gbk', errors='ignore').strip()\n",
    "#                  except UnicodeDecodeError: return raw.decode(enc, errors='ignore').strip()\n",
    "#         return raw.decode(enc, errors=\"ignore\").strip()\n",
    "#     except Exception as e:\n",
    "#         logging.error(f\"è¯»å–æ–‡ä»¶ {path.name} æ—¶å‡ºé”™: {e}\")\n",
    "#         return \"\"\n",
    "\n",
    "# def _rand_tag(k=6): return ''.join(random.choices(string.ascii_uppercase, k=k))\n",
    "\n",
    "# base_json_schema = {\n",
    "#     \"type\": \"object\",\n",
    "#     \"properties\": {\n",
    "#         \"æƒ…èŠ‚æ‘˜è¦å¯¼è¯­\": {\"type\": \"string\", \"description\": \"\"},\n",
    "#         \"å‡ºç°äººç‰©\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"æœ¬ç« å‡ºç°çš„æ‰€æœ‰äººç‰©åç§°åˆ—è¡¨\"},\n",
    "#         \"å‡ºç°é“å…·\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"æœ¬ç« å‡ºç°çš„å…³é”®é“å…·åˆ—è¡¨\"},\n",
    "#         \"å‡ºç°åœºæ™¯\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"æœ¬ç« å‘ç”Ÿæ•…äº‹çš„ä¸»è¦åœºæ™¯åˆ—è¡¨\"},\n",
    "#         \"ä¼ç¬”_è®¾ä¸‹\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"æœ¬ç« æ–°åŸ‹ä¸‹çš„ä¼ç¬”æè¿°\"},\n",
    "#         \"ä¼ç¬”_å›æ”¶\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}, \"description\": \"æœ¬ç« å›æ”¶æˆ–å‘¼åº”çš„è¿‡å¾€ä¼ç¬”æè¿°\"}\n",
    "#     },\n",
    "#     \"required\": [\"æƒ…èŠ‚æ‘˜è¦å¯¼è¯­\", \"å‡ºç°äººç‰©\", \"å‡ºç°é“å…·\", \"å‡ºç°åœºæ™¯\", \"ä¼ç¬”_è®¾ä¸‹\", \"ä¼ç¬”_å›æ”¶\"]\n",
    "# }\n",
    "\n",
    "# prompt_chapter_template = r\"\"\"\n",
    "# ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ–‡å­¦ç¼–è¾‘ã€‚è¯·ä»”ç»†é˜…è¯»æˆ‘æä¾›çš„ã€ç« èŠ‚å…¨æ–‡ã€‘ã€‚\n",
    "# ä½ çš„ä»»åŠ¡æ˜¯æå–ç»“æ„åŒ–ä¿¡æ¯ï¼Œå¹¶ **å¿…é¡»** è°ƒç”¨ `extract_chapter_details` å‡½æ•°æ¥è¿”å›ç»“æœã€‚\n",
    "# è¯·ä¸¥æ ¼æŒ‰ç…§å‡½æ•°å‚æ•°çš„æè¿°ï¼ˆç‰¹åˆ«æ˜¯å…³äºâ€œæƒ…èŠ‚æ‘˜è¦å¯¼è¯­â€çš„è¯¦ç»†ç¨‹åº¦è¦æ±‚ï¼‰æ¥å¡«å……ä¿¡æ¯ã€‚\n",
    "# **ç»å¯¹ä¸è¦** è¾“å‡ºä»»ä½• JSON æ ¼å¼ä¹‹å¤–çš„æ–‡æœ¬ã€è§£é‡Šã€ä»£ç å—æ ‡è®°ï¼ˆå¦‚ ```json ... ```ï¼‰æˆ– Markdownã€‚\n",
    "# ç›´æ¥è°ƒç”¨å‡½æ•°å¹¶å¡«å……å…¶å‚æ•°ã€‚\n",
    "\n",
    "# ã€ç« èŠ‚å…¨æ–‡ã€‘ï¼š\n",
    "# {chapter_text}\n",
    "# \"\"\"\n",
    "\n",
    "# # --- (analyze_chapter å‡½æ•° - ä¸ä¸Šä¸€ç‰ˆæœ¬ä¿®å¤åç›¸åŒ) ---\n",
    "# def analyze_chapter(\n",
    "#     path: Path,\n",
    "#     prompt_template: str,\n",
    "#     summary_description: str,\n",
    "#     retries: int = 3\n",
    "# ) -> str | None:\n",
    "#     text = _auto_decode(path)\n",
    "#     if not text: return None\n",
    "#     full_prompt = prompt_template.format(chapter_text=text)\n",
    "#     current_schema = copy.deepcopy(base_json_schema)\n",
    "#     current_schema[\"properties\"][\"æƒ…èŠ‚æ‘˜è¦å¯¼è¯­\"][\"description\"] = summary_description\n",
    "#     extract_details_func_declaration = {\n",
    "#         \"name\": \"extract_chapter_details\",\n",
    "#         \"description\": \"æå–å°è¯´ç« èŠ‚çš„ç»“æ„åŒ–ä¿¡æ¯...\",\n",
    "#         \"parameters\": current_schema\n",
    "#     }\n",
    "#     safety_settings = { HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE, HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE, HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE, HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE, }\n",
    "#     try:\n",
    "#         gemini_model = genai.GenerativeModel(GEMINI_MODEL, safety_settings=safety_settings)\n",
    "#     except Exception as model_init_err:\n",
    "#         logging.error(f\"åˆå§‹åŒ– Gemini æ¨¡å‹æ—¶å‡ºé”™: {model_init_err}\", exc_info=True)\n",
    "#         return None\n",
    "\n",
    "#     for attempt in range(retries):\n",
    "#         func_call_args_raw = None\n",
    "#         try:\n",
    "#             logging.info(f\"å¼€å§‹åˆ†æç« èŠ‚: {path.name} (æ‘˜è¦è¦æ±‚: '{summary_description}', å°è¯• {attempt + 1}/{retries})\")\n",
    "#             rsp = gemini_model.generate_content(full_prompt, generation_config={\"temperature\": 0.3}, tools=[{\"function_declarations\": [extract_details_func_declaration]}], tool_config={'function_calling_config': 'ANY'})\n",
    "#             if not rsp.candidates: logging.warning(f\"åˆ†æå¤±è´¥ (å°è¯• {attempt + 1}): API æœªè¿”å›å€™é€‰å†…å®¹ã€‚\"); time.sleep(2 ** attempt + random.uniform(0, 1)); continue\n",
    "#             first_candidate = rsp.candidates[0]\n",
    "#             if not first_candidate.content or not first_candidate.content.parts:\n",
    "#                 if first_candidate.finish_reason == genai.types.FinishReason.SAFETY: logging.warning(f\"åˆ†æå¤±è´¥ (å°è¯• {attempt + 1}): å†…å®¹è¢«å®‰å…¨è®¾ç½®é˜»æ­¢ã€‚\")\n",
    "#                 else: logging.warning(f\"åˆ†æå¤±è´¥ (å°è¯• {attempt + 1}): å€™é€‰å†…å®¹ä¸ºç©ºã€‚åŸå› : {first_candidate.finish_reason}\")\n",
    "#                 time.sleep(2 ** attempt + random.uniform(0, 1)); continue\n",
    "#             func_call_part = None\n",
    "#             for part in first_candidate.content.parts:\n",
    "#                 if part.function_call: func_call_part = part; break\n",
    "#             if func_call_part and func_call_part.function_call:\n",
    "#                 fc = func_call_part.function_call\n",
    "#                 func_call_args_raw = fc.args\n",
    "#                 if fc.name == \"extract_chapter_details\":\n",
    "#                     logging.info(f\"æˆåŠŸåˆ†æç« èŠ‚: {path.name} (æ‘˜è¦è¦æ±‚: '{summary_description}')\")\n",
    "#                     try:\n",
    "#                         args_dict_shallow = dict(fc.args)\n",
    "#                         args_dict_native = {}\n",
    "#                         for key, value in args_dict_shallow.items():\n",
    "#                             if type(value).__name__ == 'RepeatedComposite':\n",
    "#                                 args_dict_native[key] = list(value)\n",
    "#                             else:\n",
    "#                                 args_dict_native[key] = value\n",
    "#                         json_output = json.dumps(args_dict_native, ensure_ascii=False, indent=2)\n",
    "#                         return json_output\n",
    "#                     except TypeError as json_err:\n",
    "#                         logging.error(f\"åºåˆ—åŒ–å‚æ•°æ—¶å‡ºé”™: {json_err}\", exc_info=False)\n",
    "#                         logging.error(f\"  åŸå§‹å‚æ•°ç±»å‹: {type(func_call_args_raw)}\")\n",
    "#                         logging.error(f\"  æµ…å±‚å­—å…¸ (éƒ¨åˆ†): {str(args_dict_shallow)[:500]}...\")\n",
    "#                         time.sleep(2 ** attempt + random.uniform(0, 1)); continue # Go to next retry on serialization error\n",
    "#                 else: logging.warning(f\"åˆ†æè­¦å‘Š (å°è¯• {attempt + 1}): è°ƒç”¨äº†æ„å¤–å‡½æ•° '{fc.name}'\")\n",
    "#             else:\n",
    "#                 finish_reason = first_candidate.finish_reason; safety_ratings = first_candidate.safety_ratings\n",
    "#                 logging.warning(f\"åˆ†æå¤±è´¥ (å°è¯• {attempt + 1}): æœªæ‰¾åˆ°å‡½æ•°è°ƒç”¨ã€‚åŸå› : {finish_reason}\")\n",
    "#                 if safety_ratings: logging.warning(f\"  å®‰å…¨è¯„çº§: {safety_ratings}\")\n",
    "#                 try: text_output = first_candidate.text\n",
    "#                 except ValueError: text_output = str(first_candidate.content.parts[0]) if first_candidate.content and first_candidate.content.parts else \"\"\n",
    "#                 if text_output: logging.warning(f\"  æ¨¡å‹è¿”å›å†…å®¹ (éƒ¨åˆ†): {text_output[:200]}...\")\n",
    "#             time.sleep(2 ** attempt + random.uniform(0, 1)) # Wait before next retry if this attempt failed here\n",
    "#         except Exception as e:\n",
    "#             error_context = f\" | å‚æ•°ç±»å‹: {type(func_call_args_raw)}, å†…å®¹ (éƒ¨åˆ†): {str(func_call_args_raw)[:200]}...\" if func_call_args_raw else \"\"\n",
    "#             logging.error(f\"API è°ƒç”¨æˆ–å¤„ç†æ—¶å‘ç”Ÿå¼‚å¸¸ (å°è¯• {attempt + 1}): {e}{error_context}\", exc_info=True)\n",
    "#             time.sleep(2 ** attempt + random.uniform(0, 1)) # Wait before next retry on general exception\n",
    "#     logging.error(f\"âŒ åˆ†æå¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {path.name} (æ‘˜è¦è¦æ±‚: '{summary_description}')\")\n",
    "#     return None\n",
    "\n",
    "\n",
    "# # --- (run_analysis å‡½æ•° - ä¸ä¸Šä¸€ç‰ˆæœ¬ç›¸åŒ) ---\n",
    "# def run_analysis(chapter_root: str, prompt_template: str, summary_description: str, out_dir: str, mode: tuple[int, int] = (1, 150)):\n",
    "#     root = Path(chapter_root); out_base = Path(out_dir)\n",
    "#     if not root.is_dir(): logging.error(f\"é”™è¯¯ï¼šè¾“å…¥ç›®å½• '{chapter_root}' ä¸å­˜åœ¨ã€‚\"); return\n",
    "#     out_base.mkdir(parents=True, exist_ok=True)\n",
    "#     logging.info(f\"å¼€å§‹æ‰¹é‡åˆ†æ (æ‘˜è¦è¦æ±‚: '{summary_description}'), è¾“å‡ºåˆ°: {out_base}\")\n",
    "#     books = [d for d in root.iterdir() if d.is_dir()]\n",
    "#     if not books: logging.warning(f\"åœ¨ '{chapter_root}' ä¸‹æœªæ‰¾åˆ°ä»»ä½•å°è¯´å­ç›®å½•ã€‚\"); return\n",
    "#     s, e = mode; logging.info(f\"å¤„ç†ç« èŠ‚èŒƒå›´: {s} åˆ° {e}\")\n",
    "#     total_processed, total_failed, total_skipped = 0, 0, 0\n",
    "#     for book in tqdm(books, desc=\"ğŸ“š å¤„ç†å°è¯´ä¹¦ç›®\"):\n",
    "#         chapters = sorted([p for p in book.glob(\"*.txt\") if p.name[:3].isdigit() and s <= int(p.name[:3]) <= e], key=lambda p: int(p.name[:3]))\n",
    "#         if not chapters: logging.warning(f\"åœ¨ '{book.name}' ç›®å½•ä¸­æœªæ‰¾åˆ°ç¬¦åˆèŒƒå›´ {s}-{e} çš„ç« èŠ‚æ–‡ä»¶ã€‚\"); continue\n",
    "#         out_book_dir = out_base / book.name; out_book_dir.mkdir(parents=True, exist_ok=True)\n",
    "#         processed_count, failed_count, skipped_count = 0, 0, 0\n",
    "#         for chap_path in tqdm(chapters, desc=f\"ğŸ“– åˆ†æ '{book.name}'\", leave=False):\n",
    "#             out_filename = f\"{chap_path.stem}_analysis.json\"; out_path = out_book_dir / out_filename\n",
    "#             if out_path.exists(): skipped_count += 1; continue\n",
    "#             try:\n",
    "#                 result_json = analyze_chapter(chap_path, prompt_template, summary_description)\n",
    "#                 if result_json: out_path.write_text(result_json, encoding=\"utf-8\"); processed_count += 1\n",
    "#                 else: failed_count += 1\n",
    "#             except Exception as e: logging.error(f\"å¤„ç†ç« èŠ‚ {chap_path.name} æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}\", exc_info=True); failed_count += 1\n",
    "#         logging.info(f\"å®Œæˆå¤„ç† '{book.name}': {processed_count} æˆåŠŸ, {failed_count} å¤±è´¥, {skipped_count} è·³è¿‡ã€‚\")\n",
    "#         total_processed += processed_count; total_failed += failed_count; total_skipped += skipped_count\n",
    "#     # Ensure the final message regarding where results are saved uses the correct base directory variable\n",
    "#     print(f\"\\nâœ… JSON åˆ†æå®Œæˆã€‚æ€»è®¡: {total_processed} æˆåŠŸ, {total_failed} å¤±è´¥, {total_skipped} è·³è¿‡ã€‚\")\n",
    "#     print(f\"  JSON ç»“æœä¿å­˜åœ¨: {out_dir}\") # Use out_dir specific to this run_analysis call\n",
    "\n",
    "\n",
    "# # --- (JSON è½¬ TXT åŠåˆå¹¶åŠŸèƒ½ - format_list_output, convert_json_to_txt, merge_txt_outlines, run_post_processing - ä¸ä¸Šä¸€ç‰ˆæœ¬ç›¸åŒ) ---\n",
    "\n",
    "# def format_list_output(items: List[str]) -> str:\n",
    "#     \"\"\"Helper function to format lists for TXT output.\"\"\"\n",
    "#     if not items: return \"- æ— \"\n",
    "#     return \"\\n\".join(f\"- {item}\" for item in items)\n",
    "\n",
    "# def convert_json_to_txt(json_path: Path, txt_path: Path) -> bool:\n",
    "#     \"\"\"Reads JSON analysis file, writes formatted TXT outline.\"\"\"\n",
    "#     try:\n",
    "#         with open(json_path, 'r', encoding='utf-8') as f: data = json.load(f)\n",
    "#         chapter_title = json_path.stem.replace(\"_analysis\", \"\")\n",
    "#         output_lines = [\n",
    "#             f\"ç« èŠ‚ï¼š{chapter_title}\", \"\\nã€æƒ…èŠ‚æ‘˜è¦å¯¼è¯­ã€‘\", data.get(\"æƒ…èŠ‚æ‘˜è¦å¯¼è¯­\", \"N/A\"),\n",
    "#             \"\\nã€å‡ºç°äººç‰©ã€‘\", format_list_output(data.get(\"å‡ºç°äººç‰©\", [])),\n",
    "#             \"\\nã€å‡ºç°é“å…·ã€‘\", format_list_output(data.get(\"å‡ºç°é“å…·\", [])),\n",
    "#             \"\\nã€å‡ºç°åœºæ™¯ã€‘\", format_list_output(data.get(\"å‡ºç°åœºæ™¯\", [])),\n",
    "#             \"\\nã€ä¼ç¬”_è®¾ä¸‹ã€‘\", format_list_output(data.get(\"ä¼ç¬”_è®¾ä¸‹\", [])),\n",
    "#             \"\\nã€ä¼ç¬”_å›æ”¶ã€‘\", format_list_output(data.get(\"ä¼ç¬”_å›æ”¶\", [])),\n",
    "#             \"\\n\" + \"-\" * 40 + \"\\n\"\n",
    "#         ]\n",
    "#         txt_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "#         with open(txt_path, 'w', encoding='utf-8') as f: f.write(\"\\n\".join(output_lines))\n",
    "#         return True\n",
    "#     except FileNotFoundError: logging.error(f\"JSON æ–‡ä»¶æœªæ‰¾åˆ°: {json_path}\"); return False\n",
    "#     except json.JSONDecodeError: logging.error(f\"æ— æ³•è§£æ JSON æ–‡ä»¶: {json_path}\"); return False\n",
    "#     except Exception as e: logging.error(f\"è½¬æ¢ {json_path.name} åˆ° TXT æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}\", exc_info=True); return False\n",
    "\n",
    "# def merge_txt_outlines(txt_dir: Path, output_file: Path) -> bool:\n",
    "#     \"\"\"Merges all chapter TXT outlines in a directory into a single file.\"\"\"\n",
    "#     try:\n",
    "#         chapter_files = list(txt_dir.glob(\"*_outline.txt\"))\n",
    "#         if not chapter_files: logging.warning(f\"åœ¨ç›®å½• {txt_dir} ä¸­æœªæ‰¾åˆ°è¦åˆå¹¶çš„ TXT æ–‡ä»¶ (*_outline.txt)ã€‚\"); return False\n",
    "#         def get_chapter_num(file_path: Path) -> int:\n",
    "#             try: match = re.match(r\"(\\d+)\", file_path.name); return int(match.group(1)) if match else float('inf')\n",
    "#             except ValueError: return float('inf')\n",
    "#         chapter_files.sort(key=get_chapter_num)\n",
    "#         merged_content = []\n",
    "#         logging.info(f\"å¼€å§‹åˆå¹¶ {len(chapter_files)} ä¸ª TXT æ–‡ä»¶åˆ° {output_file.name}...\")\n",
    "#         for chap_file in tqdm(chapter_files, desc=f\"  åˆå¹¶ TXT\", leave=False):\n",
    "#             try:\n",
    "#                 with open(chap_file, 'r', encoding='utf-8') as f: merged_content.append(f.read())\n",
    "#             except Exception as e: logging.error(f\"è¯»å– TXT æ–‡ä»¶ {chap_file.name} æ—¶å‡ºé”™: {e}\")\n",
    "#         if not merged_content: logging.error(f\"æœªèƒ½è¯»å–ä»»ä½• TXT æ–‡ä»¶å†…å®¹è¿›è¡Œåˆå¹¶ã€‚\"); return False\n",
    "#         output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "#         with open(output_file, 'w', encoding='utf-8') as f: f.write(\"\".join(merged_content))\n",
    "#         logging.info(f\"æˆåŠŸåˆå¹¶ TXT æ–‡ä»¶åˆ°: {output_file}\")\n",
    "#         return True\n",
    "#     except Exception as e: logging.error(f\"åˆå¹¶ TXT æ–‡ä»¶åˆ° {output_file.name} æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}\", exc_info=True); return False\n",
    "\n",
    "# def run_post_processing(base_json_dir: str):\n",
    "#     \"\"\"Runs JSON-to-TXT conversion and merging for all books in a base directory.\"\"\"\n",
    "#     base_path = Path(base_json_dir)\n",
    "#     if not base_path.is_dir(): logging.warning(f\"è·³è¿‡åæœŸå¤„ç†ï¼šç›®å½• {base_path} ä¸å­˜åœ¨ã€‚\"); return\n",
    "#     logging.info(f\"\\n{'='*20} å¼€å§‹å¯¹ '{base_path.name}' è¿›è¡ŒåæœŸå¤„ç† (TXT ç”Ÿæˆä¸åˆå¹¶) {'='*20}\")\n",
    "#     book_dirs = [d for d in base_path.iterdir() if d.is_dir()]\n",
    "#     if not book_dirs: logging.warning(f\"åœ¨ {base_path} ä¸­æœªæ‰¾åˆ°ä¹¦ç±å­ç›®å½•è¿›è¡ŒåæœŸå¤„ç†ã€‚\"); return\n",
    "#     total_books_processed, total_books_failed = 0, 0\n",
    "#     for book_json_dir in tqdm(book_dirs, desc=\"ğŸ“š å¤„ç†ä¹¦ç± (åæœŸ)\"):\n",
    "#         book_name = book_json_dir.name\n",
    "#         book_txt_outlines_dir = book_json_dir / f\"{book_name}_txt_outlines\"\n",
    "#         merged_output_file = base_path / f\"{book_name}_å®Œæ•´ç»†çº².txt\" # Save merged file one level up\n",
    "#         logging.info(f\"å¤„ç†ä¹¦ç± '{book_name}': JSON={book_json_dir}, TXT={book_txt_outlines_dir}, Merged={merged_output_file}\")\n",
    "#         json_files = list(book_json_dir.glob(\"*_analysis.json\"))\n",
    "#         if not json_files: logging.warning(f\"  åœ¨ {book_json_dir} ä¸­æœªæ‰¾åˆ° JSON æ–‡ä»¶è¿›è¡Œè½¬æ¢ã€‚\"); continue\n",
    "#         conversion_success_count, conversion_fail_count = 0, 0\n",
    "#         logging.info(f\"  å¼€å§‹è½¬æ¢ {len(json_files)} ä¸ª JSON æ–‡ä»¶åˆ° TXT...\")\n",
    "#         for json_file in tqdm(json_files, desc=f\"  è½¬æ¢ JSON\", leave=False):\n",
    "#             txt_filename = json_file.stem.replace(\"_analysis\", \"_outline.txt\")\n",
    "#             txt_file_path = book_txt_outlines_dir / txt_filename\n",
    "#             if convert_json_to_txt(json_file, txt_file_path): conversion_success_count += 1\n",
    "#             else: conversion_fail_count += 1\n",
    "#         logging.info(f\"  JSON åˆ° TXT è½¬æ¢å®Œæˆ: {conversion_success_count} æˆåŠŸ, {conversion_fail_count} å¤±è´¥ã€‚\")\n",
    "#         if conversion_success_count == 0:\n",
    "#             logging.error(f\"  æœªèƒ½æˆåŠŸè½¬æ¢ä»»ä½• JSON æ–‡ä»¶ä¸º TXTï¼Œè·³è¿‡åˆå¹¶æ­¥éª¤ã€‚\"); total_books_failed += 1; continue\n",
    "#         if merge_txt_outlines(book_txt_outlines_dir, merged_output_file): total_books_processed += 1\n",
    "#         else: total_books_failed +=1; logging.error(f\"  æœªèƒ½æˆåŠŸåˆå¹¶ '{book_name}' çš„ TXT ç»†çº²ã€‚\")\n",
    "#     logging.info(f\"\\n{'='*20} '{base_path.name}' åæœŸå¤„ç†å®Œæˆ {'='*20}\")\n",
    "#     logging.info(f\"  æˆåŠŸç”Ÿæˆå®Œæ•´ç»†çº²çš„ä¹¦ç±æ•°é‡: {total_books_processed}\")\n",
    "#     logging.info(f\"  å¤„ç†å¤±è´¥æˆ–æœªå®Œæˆçš„ä¹¦ç±æ•°é‡: {total_books_failed}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa1f843-f475-4af5-9bb2-f8a34a098b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ========================================\n",
    "# # ==           ä¸»ç¨‹åºå…¥å£ (æ›´æ–°)        ==\n",
    "# # ========================================\n",
    "# if __name__ == \"__main__\":\n",
    "#     # å®šä¹‰è¾“å…¥ç›®å½• (â˜…â˜…â˜… æ ¹æ®ä½ çš„å®é™…æƒ…å†µä¿®æ”¹ â˜…â˜…â˜…)\n",
    "#     CHAPTERS_INPUT_DIR = \"/content/novels_normalized\"\n",
    "#     # å®šä¹‰è¾“å‡ºæ ¹ç›®å½• (â˜…â˜…â˜… æ ¹æ®ä½ çš„å®é™…æƒ…å†µä¿®æ”¹ â˜…â˜…â˜…)\n",
    "#     OUTPUT_BASE_DIR = \"/content/json_results/json_gemini_normalized\" # <--- æ›´æ–°\n",
    "\n",
    "#     # --- å®šä¹‰ä¸åŒæ‘˜è¦é•¿åº¦çš„è¦æ±‚ (æ›´æ–°) ---\n",
    "#     summary_req_short = \"ç”Ÿæˆä¸€ä¸ªéå¸¸ç®€çŸ­çš„æ ¸å¿ƒæƒ…èŠ‚æ‘˜è¦ï¼ˆ çº¦ 150-200 å­—ï¼‰\" # <--- æ›´æ–°\n",
    "#     summary_req_medium = \"ç”Ÿæˆä¸€ä¸ªæ ‡å‡†çš„æƒ…èŠ‚æ‘˜è¦ï¼Œæ¦‚æ‹¬ä¸»è¦å†…å®¹ï¼ˆçº¦ 300-400 å­—ï¼‰\" # <--- æ›´æ–°\n",
    "#     summary_req_long = \"ç”Ÿæˆä¸€ä¸ªæ¯”è¾ƒè¯¦ç»†çš„æƒ…èŠ‚æ‘˜è¦ï¼ŒåŒ…å«æ›´å¤šç»†èŠ‚å’Œè½¬æŠ˜ï¼ˆçº¦ 600-700 å­—ï¼‰\" # <--- æ›´æ–°\n",
    "\n",
    "#     # --- è¿è¡Œä¸åŒç‰ˆæœ¬çš„åˆ†æ ---\n",
    "#     # (ä½ å¯ä»¥å–æ¶ˆæ³¨é‡Šæ‰ä¸æƒ³è¿è¡Œçš„ç‰ˆæœ¬)\n",
    "#     analysis_dirs_to_process = [] # Store dirs for post-processing\n",
    "\n",
    "#     logging.info(\"=\"*20 + \" å¼€å§‹ç®€çŸ­æ‘˜è¦åˆ†æ (150-200å­—) \" + \"=\"*20)\n",
    "#     short_summary_dir = os.path.join(OUTPUT_BASE_DIR, \"30000_summary\") # <--- æ›´æ–°\n",
    "#     run_analysis(\n",
    "#         chapter_root=CHAPTERS_INPUT_DIR,\n",
    "#         prompt_template=prompt_chapter_template,\n",
    "#         summary_description=summary_req_short, # ä½¿ç”¨æ›´æ–°åçš„æè¿°\n",
    "#         out_dir=short_summary_dir,             # ä½¿ç”¨æ›´æ–°åçš„ç›®å½•\n",
    "#         mode=(1, 200) # åˆ†æ 1 åˆ° 150 ç« \n",
    "#     )\n",
    "#     analysis_dirs_to_process.append(short_summary_dir) # æ·»åŠ æ›´æ–°åçš„ç›®å½•\n",
    "\n",
    "#     logging.info(\"=\"*20 + \" å¼€å§‹æ ‡å‡†æ‘˜è¦åˆ†æ (300-400å­—) \" + \"=\"*20)\n",
    "#     medium_summary_dir = os.path.join(OUTPUT_BASE_DIR, \"50000_summary\") # <--- æ›´æ–°\n",
    "#     run_analysis(\n",
    "#         chapter_root=CHAPTERS_INPUT_DIR,\n",
    "#         prompt_template=prompt_chapter_template,\n",
    "#         summary_description=summary_req_medium, # ä½¿ç”¨æ›´æ–°åçš„æè¿°\n",
    "#         out_dir=medium_summary_dir,             # ä½¿ç”¨æ›´æ–°åçš„ç›®å½•\n",
    "#         mode=(1, 200)\n",
    "#     )\n",
    "#     analysis_dirs_to_process.append(medium_summary_dir) # æ·»åŠ æ›´æ–°åçš„ç›®å½•\n",
    "\n",
    "#     logging.info(\"=\"*20 + \" å¼€å§‹è¯¦ç»†æ‘˜è¦åˆ†æ (600-700å­—) \" + \"=\"*20)\n",
    "#     long_summary_dir = os.path.join(OUTPUT_BASE_DIR, \"100000_summary\") # <--- æ›´æ–°\n",
    "#     run_analysis(\n",
    "#         chapter_root=CHAPTERS_INPUT_DIR,\n",
    "#         prompt_template=prompt_chapter_template,\n",
    "#         summary_description=summary_req_long, # ä½¿ç”¨æ›´æ–°åçš„æè¿°\n",
    "#         out_dir=long_summary_dir,             # ä½¿ç”¨æ›´æ–°åçš„ç›®å½•\n",
    "#         mode=(1, 200)\n",
    "#     )\n",
    "#     analysis_dirs_to_process.append(long_summary_dir) # æ·»åŠ æ›´æ–°åçš„ç›®å½•\n",
    "\n",
    "#     logging.info(\"\\n\" + \"=\"*20 + \" æ‰€æœ‰ JSON åˆ†æä»»åŠ¡å·²å®Œæˆ/æäº¤ \" + \"=\"*20)\n",
    "\n",
    "#     # --- è¿è¡ŒåæœŸå¤„ç†ï¼šç”Ÿæˆ TXT ç»†çº² ---\n",
    "#     # (è¿™éƒ¨åˆ†ä¿æŒä¸å˜ï¼Œå®ƒä¼šä½¿ç”¨ä¸Šé¢ analysis_dirs_to_process åˆ—è¡¨ä¸­çš„æ–°ç›®å½•)\n",
    "#     logging.info(\"\\n\" + \"=\"*20 + \" å¼€å§‹è¿è¡ŒåæœŸå¤„ç† (ç”Ÿæˆ TXT ç»†çº²) \" + \"=\"*20)\n",
    "#     for dir_to_process in analysis_dirs_to_process:\n",
    "#         run_post_processing(dir_to_process)\n",
    "\n",
    "#     logging.info(\"\\n\" + \"=\"*20 + \" å…¨éƒ¨å¤„ç†æµç¨‹ç»“æŸ \" + \"=\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54f373d0-7791-4e90-864f-5c621d157cf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“š å¤„ç†ä¹¦ç±: 0it [00:52, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 117\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_file\u001b[38;5;241m.\u001b[39mexists(): \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    116\u001b[0m prompt \u001b[38;5;241m=\u001b[39m PROMPT_TMPL\u001b[38;5;241m.\u001b[39mformat(target_len\u001b[38;5;241m=\u001b[39mtgt, outline\u001b[38;5;241m=\u001b[39moutline)\n\u001b[0;32m--> 117\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mcall_gemini\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFUNC_DECL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m# schemaé‡Œæ˜¯ç»Ÿä¸€å­—æ®µå summary â†’ é‡æ–° key\u001b[39;00m\n\u001b[1;32m    120\u001b[0m     common \u001b[38;5;241m=\u001b[39m {k: result[k] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_characters\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_scenes\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_items\u001b[39m\u001b[38;5;124m\"\u001b[39m)}\n",
      "Cell \u001b[0;32mIn[13], line 72\u001b[0m, in \u001b[0;36mcall_gemini\u001b[0;34m(prompt, func_decl, retries)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(retries):\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m         rsp \u001b[38;5;241m=\u001b[39m \u001b[43mgm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_declarations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfunc_decl\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_calling_config\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mANY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m         cand \u001b[38;5;241m=\u001b[39m rsp\u001b[38;5;241m.\u001b[39mcandidates[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;66;03m# --- è§£æ function_call ----\u001b[39;00m\n",
      "File \u001b[0;32m/venv/main/lib/python3.10/site-packages/google/generativeai/generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/venv/main/lib/python3.10/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:835\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    834\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 835\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/venv/main/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/venv/main/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:294\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    291\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    293\u001b[0m )\n\u001b[0;32m--> 294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/venv/main/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:147\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    149\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m/venv/main/lib/python3.10/site-packages/google/api_core/timeout.py:130\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         remaining_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout\n\u001b[1;32m    128\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m remaining_timeout\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/venv/main/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(callable_)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21merror_remapped_callable\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[0;32m/venv/main/lib/python3.10/site-packages/grpc/_interceptor.py:277\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    270\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    275\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 277\u001b[0m     response, ignored_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/venv/main/lib/python3.10/site-packages/grpc/_interceptor.py:329\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _FailureOutcome(exception, sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m--> 329\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interceptor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintercept_unary_unary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontinuation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call\u001b[38;5;241m.\u001b[39mresult(), call\n",
      "File \u001b[0;32m/venv/main/lib/python3.10/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/grpc.py:79\u001b[0m, in \u001b[0;36m_LoggingClientInterceptor.intercept_unary_unary\u001b[0;34m(self, continuation, client_call_details, request)\u001b[0m\n\u001b[1;32m     64\u001b[0m     grpc_request \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpayload\u001b[39m\u001b[38;5;124m\"\u001b[39m: request_payload,\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequestMethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrpc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(request_metadata),\n\u001b[1;32m     68\u001b[0m     }\n\u001b[1;32m     69\u001b[0m     _LOGGER\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_call_details\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     71\u001b[0m         extra\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m         },\n\u001b[1;32m     77\u001b[0m     )\n\u001b[0;32m---> 79\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mcontinuation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logging_enabled:  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     response_metadata \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtrailing_metadata()\n",
      "File \u001b[0;32m/venv/main/lib/python3.10/site-packages/grpc/_interceptor.py:315\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[0;34m(new_details, request)\u001b[0m\n\u001b[1;32m    306\u001b[0m (\n\u001b[1;32m    307\u001b[0m     new_method,\n\u001b[1;32m    308\u001b[0m     new_timeout,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    312\u001b[0m     new_compression,\n\u001b[1;32m    313\u001b[0m ) \u001b[38;5;241m=\u001b[39m _unwrap_client_call_details(new_details, client_call_details)\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 315\u001b[0m     response, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m rpc_error:\n",
      "File \u001b[0;32m/venv/main/lib/python3.10/site-packages/grpc/_channel.py:1195\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.with_call\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwith_call\u001b[39m(\n\u001b[1;32m   1184\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1185\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1190\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1191\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, grpc\u001b[38;5;241m.\u001b[39mCall]:\n\u001b[1;32m   1192\u001b[0m     (\n\u001b[1;32m   1193\u001b[0m         state,\n\u001b[1;32m   1194\u001b[0m         call,\n\u001b[0;32m-> 1195\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/venv/main/lib/python3.10/site-packages/grpc/_channel.py:1162\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1145\u001b[0m state\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target)\n\u001b[1;32m   1146\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel\u001b[38;5;241m.\u001b[39msegregated_call(\n\u001b[1;32m   1147\u001b[0m     cygrpc\u001b[38;5;241m.\u001b[39mPropagationConstants\u001b[38;5;241m.\u001b[39mGRPC_PROPAGATE_DEFAULTS,\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registered_call_handle,\n\u001b[1;32m   1161\u001b[0m )\n\u001b[0;32m-> 1162\u001b[0m event \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_deserializer)\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:388\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:211\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:205\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:78\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:61\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:42\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # ===============================================================\n",
    "# # â‘  ä¾èµ–\n",
    "# # ===============================================================\n",
    "# !pip install -q --upgrade google-generativeai tqdm pandas chardet\n",
    "\n",
    "# # ===============================================================\n",
    "# # â‘¡ è·¯å¾„ & KEY\n",
    "# # ===============================================================\n",
    "# from pathlib import Path\n",
    "# import google.generativeai as genai\n",
    "# from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "# import json, logging, random, time, textwrap, tqdm, pandas as pd\n",
    "\n",
    "# TXT_SRC = Path(\"/content/json_results/json_gemini/30000_summary_gathered\")\n",
    "# DIR_1000   = Path(\"/content/json_results/json_gemini/1000_global_json\")\n",
    "# DIR_5000   = Path(\"/content/json_results/json_gemini/5000_global_json\")\n",
    "# DIR_10000  = Path(\"/content/json_results/json_gemini/10000_global_json\")\n",
    "# for d in (DIR_1000, DIR_5000, DIR_10000): d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# API_KEY = \"your-default-api-key\"\n",
    "# GEMINI_MODEL = \"gemini-1.5-flash\"      # åŒç« èŠ‚è„šæœ¬é£æ ¼\n",
    "\n",
    "# genai.configure(api_key=API_KEY)\n",
    "# logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "# SAFETY_SETTINGS = {\n",
    "#     HarmCategory.HARM_CATEGORY_HARASSMENT       : HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "#     HarmCategory.HARM_CATEGORY_HATE_SPEECH      : HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "#     HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "#     HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "# }\n",
    "\n",
    "# # ===============================================================\n",
    "# # â‘¢ prompt æ¨¡æ¿ & schemas\n",
    "# # ===============================================================\n",
    "# BASE_SCHEMA = {\n",
    "#     \"type\":\"object\",\n",
    "#     \"properties\":{\n",
    "#         \"total_characters\":{\"type\":\"array\",\"items\":{\"type\":\"string\"}},\n",
    "#         \"total_scenes\"    :{\"type\":\"array\",\"items\":{\"type\":\"string\"}},\n",
    "#         \"total_items\"     :{\"type\":\"array\",\"items\":{\"type\":\"string\"}},\n",
    "#         \"summary\"         :{\"type\":\"string\"}\n",
    "#     },\n",
    "#     \"required\":[\"total_characters\",\"total_scenes\",\"total_items\",\"summary\"]\n",
    "# }\n",
    "\n",
    "# FUNC_DECL = {\n",
    "#     \"name\":\"extract_book_outline\",\n",
    "#     \"description\":\"æ•´ä¹¦å¤§çº²æç‚¼ï¼šå»é‡ä¸‰å¼ åˆ—è¡¨ + æŒ‡å®šå­—æ•°å‰§æƒ…å¤§çº²\",\n",
    "#     \"parameters\":BASE_SCHEMA\n",
    "# }\n",
    "\n",
    "# PROMPT_TMPL = textwrap.dedent(\"\"\"\n",
    "# ä½ æ˜¯ä¸€ä½ä¸¥è°¨çš„å‡ºç‰ˆç¼–è¾‘ã€‚é˜…è¯»ã€Šå®Œæ•´ç»†çº²ã€‹åï¼š\n",
    "# 1. å»é‡åˆ—å‡ºå…¨ä¹¦ã€äººç‰©ã€‘ã€åœºæ™¯ã€‘ã€é“å…·ã€‘ã€‚\n",
    "# 2. å†™ä¸€ç¯‡çº¦ {target_len} å­—ï¼ˆÂ±10%ï¼‰çš„å‰§æƒ…å¤§çº²ã€‚\n",
    "# å¿…é¡»è°ƒç”¨ extract_book_outline å‡½æ•°è¿”å› JSONï¼Œä»…å«\n",
    "#  total_characters / total_scenes / total_items / summary\n",
    "# ä¸‰ä¸ªåˆ—è¡¨ä¸ä¸€æ®µå¤§çº²ã€‚\n",
    "\n",
    "# ã€Šå®Œæ•´ç»†çº²ã€‹ï¼š\n",
    "# {outline}\n",
    "# \"\"\")\n",
    "\n",
    "# # ===============================================================\n",
    "# # â‘£ Gemini è°ƒç”¨ï¼ˆä¸ç« èŠ‚è„šæœ¬åŒé£æ ¼ï¼‰\n",
    "# # ===============================================================\n",
    "# def call_gemini(prompt: str, func_decl: dict, retries=3):\n",
    "#     gm = genai.GenerativeModel(GEMINI_MODEL, safety_settings=SAFETY_SETTINGS)\n",
    "#     for i in range(retries):\n",
    "#         try:\n",
    "#             rsp = gm.generate_content(\n",
    "#                 prompt,\n",
    "#                 generation_config={\"temperature\":0.3},\n",
    "#                 tools=[{\"function_declarations\":[func_decl]}],\n",
    "#                 tool_config={\"function_calling_config\":\"ANY\"}\n",
    "#             )\n",
    "#             cand = rsp.candidates[0]\n",
    "#             # --- è§£æ function_call ----\n",
    "#             func_part = next((p for p in cand.content.parts if p.function_call), None)\n",
    "#             if func_part and func_part.function_call and \\\n",
    "#                func_part.function_call.name == \"extract_book_outline\":\n",
    "#                 # protobuf â†’ python\n",
    "#                 def to_py(v):\n",
    "#                     if type(v).__name__ == \"RepeatedComposite\": return list(v)\n",
    "#                     return v\n",
    "#                 return {k:to_py(v) for k,v in dict(func_part.function_call.args).items()}\n",
    "#             # --- å¤‡ç”¨ï¼šæ™®é€š text è¿”å› ---\n",
    "#             if cand.content.parts and cand.content.parts[0].text:\n",
    "#                 return json.loads(cand.content.parts[0].text)\n",
    "#             if hasattr(cand,\"text\") and cand.text:\n",
    "#                 return json.loads(cand.text)\n",
    "#             logging.warning(f\"Gemini æ— æœ‰æ•ˆè¾“å‡ºï¼ˆå°è¯•{i+1}ï¼‰ finish_reason={cand.finish_reason}\")\n",
    "#         except Exception as e:\n",
    "#             logging.error(f\"Gemini è°ƒç”¨å¼‚å¸¸ï¼ˆå°è¯•{i+1}ï¼‰ï¼š{e}\")\n",
    "#         time.sleep(2**i+random.random())\n",
    "#     return None\n",
    "\n",
    "# def save_json(out_dir:Path, book:str, data:dict):\n",
    "#     (out_dir/f\"{book}.json\").write_text(json.dumps(data,ensure_ascii=False,indent=2),\"utf-8\")\n",
    "\n",
    "# # ===============================================================\n",
    "# # â‘¤ ä¸»å¾ªç¯\n",
    "# # ===============================================================\n",
    "# stats=[]\n",
    "# for outline_path in tqdm.tqdm(TXT_SRC.rglob(\"*å®Œæ•´ç»†çº²*.txt\"), desc=\"ğŸ“š å¤„ç†ä¹¦ç±\"):\n",
    "#     book = outline_path.parent.name\n",
    "#     if (DIR_1000/f\"{book}.json\").exists() and (DIR_5000/f\"{book}.json\").exists() and (DIR_10000/f\"{book}.json\").exists():\n",
    "#         logging.info(f\"è·³è¿‡ã€Š{book}ã€‹â€”ä¸‰æ¡£å·²å­˜åœ¨\"); continue\n",
    "\n",
    "#     outline = outline_path.read_text(encoding=\"utf-8\")[:250_000]  # æ§åˆ¶é•¿åº¦\n",
    "#     for tag, tgt, out_dir in [(\"1000\",1000,DIR_1000), (\"5000\",5000,DIR_5000), (\"10000\",10000,DIR_10000)]:\n",
    "#         out_file = out_dir / f\"{book}.json\"\n",
    "#         if out_file.exists(): continue\n",
    "\n",
    "#         prompt = PROMPT_TMPL.format(target_len=tgt, outline=outline)\n",
    "#         result = call_gemini(prompt, FUNC_DECL)\n",
    "#         if result:\n",
    "#             # schemaé‡Œæ˜¯ç»Ÿä¸€å­—æ®µå summary â†’ é‡æ–° key\n",
    "#             common = {k: result[k] for k in (\"total_characters\",\"total_scenes\",\"total_items\")}\n",
    "#             save_json(out_dir, book, {**common, f\"summary_{tag}\": result[\"summary\"]})\n",
    "#             logging.info(f\"ç”Ÿæˆ {tag} å­—å¤§çº²æˆåŠŸï¼šã€Š{book}ã€‹\")\n",
    "#         else:\n",
    "#             logging.error(f\"ç”Ÿæˆ {tag} å­—å¤§çº²å¤±è´¥ï¼šã€Š{book}ã€‹\")\n",
    "#     stats.append(dict(book=book))\n",
    "\n",
    "# # ===============================================================\n",
    "# # â‘¥ ç»“æœæ¦‚è§ˆ\n",
    "# # ===============================================================\n",
    "# print(\"\\nå®Œæˆï¼Œç›®å½•ï¼š\")\n",
    "# print(\"1000å­— â‡’\", DIR_1000)\n",
    "# print(\"5000å­— â‡’\", DIR_5000)\n",
    "# print(\"10000å­— â‡’\", DIR_10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3df47fc-9a47-4bec-a3c3-2e0e77af81a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# âœ… Gemini æ€»çº²ç»“æ„åŒ–è°ƒç”¨ï¼ˆå‚è€ƒç« èŠ‚è„šæœ¬ï¼Œå®Œå…¨å…¼å®¹ï¼‰\n",
    "# ===============================================================\n",
    "!pip install -q --upgrade google-generativeai tqdm chardet\n",
    "\n",
    "import os, json, logging, random, time, textwrap\n",
    "from pathlib import Path\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ===============================================================\n",
    "# â‘  è®¾ç½®å‚æ•°\n",
    "# ===============================================================\n",
    "API_KEY = \"your-default-api-key\"  # â† æ›¿æ¢\n",
    "GEMINI_MODEL = \"gemini-2.0-flash\"  # æ¨èç”¨ 1.5 å¤„ç†æ•´ä¹¦ï¼Œflash å®¹æ˜“çˆ†ä¸Šä¸‹æ–‡\n",
    "BOOK_DIR = Path(\"/content/json_results/json_gemini/30000_summary_gathered/ã€Šè´©ç½ªã€‹(ç²¾æ ¡ç‰ˆå…¨æœ¬)ä½œè€…_ä¸‰å¤©ä¸¤è§‰_utf8\")\n",
    "OUTLINE_FILE = BOOK_DIR / \"å®Œæ•´ç»†çº².txt\"\n",
    "TARGET_LEN = 1000  # å¯è®¾ 5000 æˆ– 10000\n",
    "\n",
    "# ===============================================================\n",
    "# â‘¡ API åˆå§‹åŒ–ï¼ˆä¸åŠ  safetyï¼‰\n",
    "# ===============================================================\n",
    "genai.configure(api_key=API_KEY)\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "model = genai.GenerativeModel(GEMINI_MODEL)\n",
    "\n",
    "# ===============================================================\n",
    "# â‘¢ Function Schema + Prompt\n",
    "# ===============================================================\n",
    "base_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"total_characters\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "        \"total_scenes\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "        \"total_items\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "        \"summary\": {\"type\": \"string\"}\n",
    "    },\n",
    "    \"required\": [\"total_characters\", \"total_scenes\", \"total_items\", \"summary\"]\n",
    "}\n",
    "\n",
    "function_declaration = {\n",
    "    \"name\": \"extract_book_outline\",\n",
    "    \"description\": \"æç‚¼æ•´æœ¬å°è¯´çš„æ ¸å¿ƒç»“æ„ä¿¡æ¯ä¸å‰§æƒ…å¤§çº²\",\n",
    "    \"parameters\": base_schema\n",
    "}\n",
    "\n",
    "prompt_template = textwrap.dedent(f\"\"\"\n",
    "ä½ æ˜¯ä¸€ä½ä¸“ä¸šå‡ºç‰ˆç¼–è¾‘ã€‚è¯·é˜…è¯»ä¸‹é¢æä¾›çš„ã€Šå®Œæ•´ç»†çº²ã€‹ï¼š\n",
    "\n",
    "ä»»åŠ¡ï¼š\n",
    "1. å»é‡åˆ—å‡ºã€äººç‰©ã€‘ã€åœºæ™¯ã€‘ã€é“å…·ã€‘ä¸‰ç±»ä¿¡æ¯ã€‚\n",
    "2. å†™å‡ºä¸€ç¯‡ â‰ˆ {TARGET_LEN} å­—ï¼ˆÂ±10%ï¼‰çš„å‰§æƒ…å¤§çº²ã€‚\n",
    "\n",
    "å¿…é¡»è°ƒç”¨ extract_book_outline å‡½æ•°ï¼Œè¿”å› JSON æ ¼å¼ã€‚\n",
    "è¿”å›å­—æ®µå›ºå®šä¸ºï¼š\n",
    "  - total_characters\n",
    "  - total_scenes\n",
    "  - total_items\n",
    "  - summary\n",
    "\n",
    "ã€Šå®Œæ•´ç»†çº²ã€‹ï¼š\n",
    "{{chapter_text}}\n",
    "\"\"\")\n",
    "\n",
    "# ===============================================================\n",
    "# â‘£ è°ƒç”¨å‡½æ•°ï¼ˆå®Œå…¨ç…§ç« èŠ‚ç‰ˆé£æ ¼ï¼‰\n",
    "# ===============================================================\n",
    "def analyze_outline_text(text: str, retries: int = 3) -> dict | None:\n",
    "    full_prompt = prompt_template.format(chapter_text=text)\n",
    "    print(f\"\\nğŸ“ Prompt é¢„è§ˆï¼ˆå‰500å­—ï¼‰ï¼š\\n{textwrap.shorten(full_prompt, width=500)}\\n\")\n",
    "\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            logging.info(f\"ğŸ” Gemini ç¬¬ {attempt + 1}/{retries} æ¬¡è°ƒç”¨ä¸­...\")\n",
    "            rsp = model.generate_content(\n",
    "                full_prompt,\n",
    "                generation_config={\"temperature\": 0.3},\n",
    "                tools=[{\"function_declarations\": [function_declaration]}],\n",
    "                tool_config={'function_calling_config': 'ANY'}\n",
    "            )\n",
    "\n",
    "            candidate = rsp.candidates[0]\n",
    "            logging.info(f\"âœ… æ¥æ”¶å“åº”ï¼Œfinish_reason: {candidate.finish_reason}\")\n",
    "\n",
    "            if hasattr(candidate, \"safety_ratings\"):\n",
    "                logging.info(f\"ğŸ”’ å®‰å…¨è¯„çº§: {[r.category.name for r in candidate.safety_ratings]}\")\n",
    "\n",
    "            parts = candidate.content.parts\n",
    "            print(f\"ğŸ“¦ è¿”å›å†…å®¹ parts æ•°é‡ï¼š{len(parts)}\")\n",
    "\n",
    "            for i, part in enumerate(parts):\n",
    "                print(f\"ğŸ” Part[{i}] ç±»å‹ï¼š\", \n",
    "                      \"function_call\" if part.function_call else \"text\", \n",
    "                      \" / å†…å®¹é¢„è§ˆ:\", str(part)[:120].replace(\"\\n\", \" \"))\n",
    "\n",
    "                # -- ä¸»å‡½æ•°è§£æ --\n",
    "                if part.function_call and part.function_call.name == \"extract_book_outline\":\n",
    "                    logging.info(f\"âœ… å‘ç°å‡½æ•°è°ƒç”¨ extract_book_outline\")\n",
    "                    args = part.function_call.args\n",
    "                    native = {k: list(v) if hasattr(v, '__iter__') and not isinstance(v, str) else v\n",
    "                              for k, v in dict(args).items()}\n",
    "                    return native\n",
    "\n",
    "            # -- fallback: çº¯ JSON æ–‡æœ¬ --\n",
    "            if parts and hasattr(parts[0], \"text\") and parts[0].text.strip().startswith(\"{\"):\n",
    "                logging.warning(\"âš ï¸ æœªä½¿ç”¨å‡½æ•°è°ƒç”¨ï¼Œå°è¯• fallback ä¸ºçº¯ JSON æ–‡æœ¬è§£æ\")\n",
    "                return json.loads(parts[0].text)\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Gemini è°ƒç”¨å¤±è´¥ï¼š{e}\", exc_info=True)\n",
    "            time.sleep(2 ** attempt + random.random())\n",
    "\n",
    "    logging.error(\"âŒ æ‰€æœ‰å°è¯•å¤±è´¥ï¼Œæœªè·å–ä»»ä½•ç»“æ„åŒ–æ•°æ®\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# â‘¤ è¿è¡Œåˆ†æ\n",
    "# ===============================================================\n",
    "if not OUTLINE_FILE.exists():\n",
    "    raise FileNotFoundError(f\"æœªæ‰¾åˆ°ç»†çº²æ–‡ä»¶ï¼š{OUTLINE_FILE}\")\n",
    "text = OUTLINE_FILE.read_text(encoding=\"utf-8\")[:300_000]\n",
    "\n",
    "result = analyze_outline_text(text)\n",
    "if result:\n",
    "    print(\"âœ… ç»“æœå­—æ®µï¼š\", list(result.keys()))\n",
    "    # print(\"ğŸ“Œ æ‘˜è¦å¼€å¤´ï¼š\", result[\"summary\"][:200], \"...\")\n",
    "    # ä¿å­˜\n",
    "    output_path = Path(f\"/content/{BOOK_DIR.name}_summary_{TARGET_LEN}.json\")\n",
    "    output_path.write_text(json.dumps(result, ensure_ascii=False, indent=2))\n",
    "    print(\"âœ… å·²ä¿å­˜è‡³ï¼š\", output_path)\n",
    "else:\n",
    "    print(\"âŒ æœªèƒ½è·å¾—ç»“æœ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd219dc6-2161-4e11-b652-77b68c19ee4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 17:14:47,984 - INFO - åŸç»†çº²å­—æ•°: 66,242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å·²ç”Ÿæˆ â‰¤10 000 å­—å¤§çº²: /content/json_results/json_gemini/30000_summary_gathered/ã€Šä¸Šå“å¯’å£«ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_è´¼é“ä¸‰ç—´_utf8/full_outline_trimmed.txt\n"
     ]
    }
   ],
   "source": [
    "# # ============================================================\n",
    "# # âœ… 20 000 å­—ç»†çº² â†’ â‰¤10 000 å­—å¤§çº²ï¼ˆGemini 2.0 Flashï¼‰\n",
    "# #   Â· éå† /content/json_results/json_gemini/30000_summary_gathered\n",
    "# #   Â· åªå¤„ç†ç›®æ ‡ç»†çº²ï¼š\n",
    "# #       ã€Šä¸Šå“å¯’å£«ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_è´¼é“ä¸‰ç—´_utf8/å®Œæ•´ç»†çº².txt\n",
    "# #   Â· è¾“å‡ºï¼šåŒç›®å½•ä¸‹ç”Ÿæˆ  full_outline_trimmed.txt\n",
    "# # ============================================================\n",
    "\n",
    "# # 0âƒ£ ä¾èµ–\n",
    "# # ------------------------------------------------------------\n",
    "# # !pip install -U google-generativeai chardet tqdm\n",
    "\n",
    "# import os, chardet, logging, time, random, string\n",
    "# from pathlib import Path\n",
    "# from tqdm.auto import tqdm\n",
    "# import google.generativeai as genai\n",
    "\n",
    "# # 1âƒ£ API åˆå§‹åŒ–\n",
    "# # ------------------------------------------------------------\n",
    "# os.environ[\"GEMINI_API_KEY\"] = \"your-api-key\"\n",
    "# genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "# gemini = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n",
    "# # 2âƒ£ å·¥å…·å‡½æ•°\n",
    "# # ------------------------------------------------------------\n",
    "# def _auto_decode(p: Path) -> str:\n",
    "#     raw = p.read_bytes()\n",
    "#     enc = chardet.detect(raw)[\"encoding\"] or \"utf-8\"\n",
    "#     return raw.decode(enc, errors=\"ignore\")\n",
    "\n",
    "# def _rand_tag(k=6):\n",
    "#     return ''.join(random.choices(string.ascii_uppercase, k=k))\n",
    "\n",
    "# def summarize_to_10k(text: str,\n",
    "#                      prompt_header: str,\n",
    "#                      retries: int = 3) -> str:\n",
    "#     base_prompt = f\"{prompt_header}\\n\\n#TAG:{_rand_tag()}\"\n",
    "#     for attempt in range(retries):\n",
    "#         try:\n",
    "#             rsp = gemini.generate_content(\n",
    "#                 [base_prompt, text],\n",
    "#                 generation_config={\"temperature\": 0.2,\n",
    "#                                    \"max_output_tokens\": 8192}\n",
    "#             )\n",
    "#             if rsp.text:\n",
    "#                 return rsp.text.strip()\n",
    "#         except Exception as e:\n",
    "#             logging.warning(f\"Gemini retry {attempt+1}: {e}\")\n",
    "#             time.sleep(2 ** attempt)\n",
    "#     raise RuntimeError(\"Gemini summarization failed\")\n",
    "\n",
    "# # 3âƒ£ ä¸»æµç¨‹\n",
    "# # ------------------------------------------------------------\n",
    "# ROOT = Path(\"/content/json_results/json_gemini/30000_summary_gathered\")\n",
    "# target_rel = \"ã€Šä¸Šå“å¯’å£«ã€‹(æ ¡å¯¹ç‰ˆå…¨æœ¬)ä½œè€…_è´¼é“ä¸‰ç—´_utf8/å®Œæ•´ç»†çº².txt\"\n",
    "# target_path = ROOT / target_rel\n",
    "\n",
    "# if not target_path.exists():\n",
    "#     raise FileNotFoundError(f\"æœªæ‰¾åˆ°ç›®æ ‡æ–‡ä»¶: {target_path}\")\n",
    "\n",
    "# full_outline = _auto_decode(target_path)\n",
    "# logging.info(f\"åŸç»†çº²å­—æ•°: {len(full_outline):,}\")\n",
    "\n",
    "# PROMPT_HEADER = (\n",
    "#     \"ä½ æ˜¯ä¸€ä½èµ„æ·±ä¸­æ–‡å°è¯´ç¼–è¾‘ï¼Œè¯·å°†ä¸‹é¢çº¦ 50 000 å­—çš„ã€æ•´ä¹¦ç»†çº²ã€‘\"\n",
    "#     \"ç²¾ç‚¼ä¸ºæ€»å­—æ•° â‰¤10000 å­—çš„å¤§çº²ã€‚\\n\"\n",
    "#     \"ã€è¾“å‡ºè¦æ±‚ã€‘\\n\"\n",
    "#     \"â€¢ åªç”¨ç®€ä½“ä¸­æ–‡ï¼Œä»¥ç« èŠ‚ï¼šå¤§çº²æƒ…èŠ‚çš„æ ¼å¼è¾“å‡ºï¼Œä¸è¦ç« èŠ‚è¿™ä¸¤ä¸ªå­—ï¼›\\n\"\n",
    "#     \"â€¢ ä¿æŒæƒ…èŠ‚å®Œæ•´ï¼Œçªå‡ºä¸»è¦äººç‰©ã€å†²çªã€è½¬æŠ˜ã€ç»“å±€ï¼›\\n\"\n",
    "#     \"â€¢ ä¸å¾—è¾“å‡ºä»»ä½•é¢å¤–è§£é‡Šæˆ–æ³¨é‡Šã€‚\\n\"\n",
    "#     \"â€¢ æ¯ä¸ªæ®µè½è¦ç²¾ç®€ï¼Œå¿…é¡»æ¶µç›–ä»ç¬¬ä¸€ç« åˆ°æœ€åä¸€ç« çš„å…¨éƒ¨ç»†çº²å†…å®¹ã€‚\\n\\n\"\n",
    "#     \"ã€æ•´ä¹¦ç»†çº²ã€‘ï¼š\"\n",
    "# )\n",
    "\n",
    "# trimmed_outline = summarize_to_10k(full_outline, PROMPT_HEADER)\n",
    "\n",
    "# out_path = target_path.with_name(\"full_outline_trimmed.txt\")\n",
    "# out_path.write_text(trimmed_outline, encoding=\"utf-8\")\n",
    "\n",
    "# print(\"âœ… å·²ç”Ÿæˆ â‰¤10 000 å­—å¤§çº²:\", out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2f14e923-8f79-4baa-bff9-d7da0c50ac76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d359cbf59648fb8ee50fa07459e0d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ğŸ“š Summarizing Outlines:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 14:29:29,023 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šå¥‹æ–—åœ¨æ–°æ˜æœã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šéšè½»é£å»_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:29:42,998 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šåæ­£æˆ‘æ˜¯è¶…èƒ½åŠ›è€…ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šåƒä¹¦å¦–_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:29:53,509 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šå¤©å¯æ±—ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šè¥¿é£ç´§_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:30:07,543 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šå´©åä¸–ç•Œçš„ä¼ å¥‡å¤§å†’é™©ã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå›½ç‹é™›ä¸‹_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:30:20,531 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šå…¨çƒè¿›åŒ–ã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå’¬ç‹—_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:30:33,232 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šæ­¦æ—åŠä¾ ä¼ ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šæ–‡æŠ„å…¬_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:30:43,921 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/å›½å®´å¤§å¨åœ¨å…«é›¶/summary_trimmed.txt\n",
      "2025-05-03 14:30:57,842 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šæœç¥è®°ã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šæ ‘ä¸‹é‡ç‹_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:31:14,348 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/é‡ç”Ÿå…«é›¶ï¼šæ¯’å¦»ä¸å¥½æƒ¹/summary_trimmed.txt\n",
      "2025-05-03 14:31:23,134 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šçªƒæ˜ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå¤§çˆ†ç‚¸(ç°ç†ŠçŒ«)_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:31:34,435 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šèœ€å±±ã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šæµæµªçš„è›¤èŸ†_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:31:43,489 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šé™ˆäºŒç‹—çš„å¦–å­½äººç”Ÿã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šçƒ½ç«æˆè¯¸ä¾¯_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:31:53,708 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šè´©ç½ªã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šä¸‰å¤©ä¸¤è§‰_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:32:03,245 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šé‡ç”Ÿä¹‹å‡ºäººå¤´åœ°ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šé—¹é—¹ä¸çˆ±é—¹_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:32:19,828 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/å…«é›¶å–œäº‹ï¼šå½“å®¶è‚¥å¦»å¤§ç¿»èº«/summary_trimmed.txt\n",
      "2025-05-03 14:32:32,642 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šè‚†è™éŸ©å¨±ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå§¬å‰_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:32:43,611 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/å…«é›¶å¹´ä»£å¥½æ—¶å…‰/summary_trimmed.txt\n",
      "2025-05-03 14:32:52,954 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šé£Ÿç‰©é“¾é¡¶ç«¯çš„ç”·äººã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šç†Šç‹¼ç‹—_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:33:03,559 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šé«˜æ‰‹å¯‚å¯2ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå…°å¸é­…æ™¨_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:33:14,989 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šé»‘é¾™æ³•å…¸ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šæ¬¢å£°_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:33:23,983 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šè¯›ä»™ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šè§é¼_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:33:34,850 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šå›åˆ°è¿‡å»å˜æˆçŒ«ã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šé™ˆè¯æ‡’è°ƒ_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:33:48,012 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šç¥æ¸¸ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå¾å…¬å­èƒœæ²»_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:33:55,874 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šè€å­æ˜¯ç™è›¤èŸ†ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ ä½œè€…ï¼šçƒ½ç«æˆè¯¸ä¾¯_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:34:06,449 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šæœªæ¥å¤©ç‹ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šé™ˆè¯æ‡’è°ƒ_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:34:21,674 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šå¤§ç”»å®¶ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šé†›çŸ³_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:34:33,687 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šè¶…çº§æƒŠæ‚šç›´æ’­ã€‹ä½œè€…ï¼šå®‡æ–‡é•¿å¼“_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:34:42,880 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šäººé“å¤©å ‚ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šè†æŸ¯å®ˆ_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:34:53,284 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šé“ç¼˜æµ®å›¾ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šçƒŸé›¨æ±Ÿå—_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:35:03,496 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šé‡æ´»äº†ã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼š å°è°•_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:35:15,691 - WARNING - Gemini retry 1: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 4. Meaning that the model was reciting from copyrighted material.\n",
      "2025-05-03 14:35:27,786 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šé›…éªšã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šè´¼é“ä¸‰ç—´_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:35:39,770 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/å…«é›¶ç¦æ˜Ÿä¿åª³å¦‡/summary_trimmed.txt\n",
      "2025-05-03 14:35:55,507 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šä¸Šå“å¯’å£«ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šè´¼é“ä¸‰ç—´_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:36:07,203 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šåå·é£äº‘å¿—ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šçŸ¥ç§‹_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:36:19,399 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šå²ä¸Šç¬¬ä¸€æ··ä¹±ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå¼ å°èŠ±_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:36:30,241 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šéšæ³¢é€æµä¹‹ä¸€ä»£å†›å¸ˆã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šéšæ³¢é€æµ_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:36:52,727 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/é‡ç”Ÿå…«é›¶ï¼šä½³å¦»è‡´å¯Œå¿™/summary_trimmed.txt\n",
      "2025-05-03 14:37:03,484 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/é‡å›å…«é›¶è¿‡å¥½æ—¥å­/summary_trimmed.txt\n",
      "2025-05-03 14:37:15,983 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šç»å¯¹ä¸€ç•ªã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šæµ·åº•æ¼«æ­¥è€…_utf8/summary_trimmed.txt\n",
      "2025-05-03 14:37:25,670 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/30000_outline_1000/ã€Šæˆ‘çš„å¥³å‹æ˜¯æ¶å¥³ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šæµ·åº•æ¼«æ­¥è€…_utf8/summary_trimmed.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ‰ All done! Outputs saved to /content/json_results/json_gemini_normalized/30000_outline_1000\n"
     ]
    }
   ],
   "source": [
    "import os, chardet, logging, time, random, string\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import google.generativeai as genai\n",
    "\n",
    "# åˆå§‹åŒ– Geminiï¼ˆåªåšä¸€æ¬¡ï¼‰\n",
    "def init_gemini(api_key: str):\n",
    "    os.environ[\"GEMINI_API_KEY\"] = api_key\n",
    "    genai.configure(api_key=api_key)\n",
    "    return genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n",
    "# è§£ç å™¨\n",
    "def _auto_decode(p: Path) -> str:\n",
    "    raw = p.read_bytes()\n",
    "    enc = chardet.detect(raw)[\"encoding\"] or \"utf-8\"\n",
    "    return raw.decode(enc, errors=\"ignore\")\n",
    "\n",
    "def _rand_tag(k=6):\n",
    "    return ''.join(random.choices(string.ascii_uppercase, k=k))\n",
    "\n",
    "# è°ƒç”¨ Gemini API\n",
    "def summarize(text: str, prompt: str, gemini, retries=3) -> str:\n",
    "    base_prompt = f\"{prompt.strip()}\\n\\n#TAG:{_rand_tag()}\"\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            rsp = gemini.generate_content(\n",
    "                [base_prompt, text],\n",
    "                generation_config={\"temperature\": 0.2, \"max_output_tokens\": 8192}\n",
    "            )\n",
    "            if rsp.text:\n",
    "                return rsp.text.strip()\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Gemini retry {attempt+1}: {e}\")\n",
    "            time.sleep(2 ** attempt)\n",
    "    raise RuntimeError(\"Gemini summarization failed\")\n",
    "\n",
    "# âœ… ä¸»å‡½æ•°æ¥å£\n",
    "def summarize_outlines_batch(input_dir: str,\n",
    "                              input_filename: str,\n",
    "                              output_dir: str,\n",
    "                              output_filename: str,\n",
    "                              prompt_text: str,\n",
    "                              gemini_api_key: str):\n",
    "    \"\"\"\n",
    "    æ‰¹é‡å¤„ç†ç»†çº²ï¼Œè¾“å…¥è¾“å‡ºç›®å½•å¯åˆ†ç¦»ã€‚\n",
    "    æ¯æœ¬ä¹¦è¾“å…¥è·¯å¾„ä¸º input_dir/ä¹¦å/input_filename\n",
    "    æ¯æœ¬ä¹¦è¾“å‡ºè·¯å¾„ä¸º output_dir/ä¹¦å/output_filename\n",
    "    \"\"\"\n",
    "    logging.basicConfig(level=logging.INFO,\n",
    "                        format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "    \n",
    "    gemini = init_gemini(gemini_api_key)\n",
    "    input_root = Path(input_dir)\n",
    "    output_root = Path(output_dir)\n",
    "    output_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    book_dirs = [d for d in input_root.iterdir() if d.is_dir()]\n",
    "    if not book_dirs:\n",
    "        raise FileNotFoundError(f\"âŒ No book folders found in {input_root}\")\n",
    "\n",
    "    for book_dir in tqdm(book_dirs, desc=\"ğŸ“š Summarizing Outlines\"):\n",
    "        book_name = book_dir.name\n",
    "        src = book_dir / input_filename\n",
    "        dst_dir = output_root / book_name\n",
    "        dst = dst_dir / output_filename\n",
    "\n",
    "        if not src.exists():\n",
    "            logging.warning(f\"âš ï¸ Missing file: {src}\")\n",
    "            continue\n",
    "        if dst.exists():\n",
    "            logging.info(f\"âœ… Output exists, skipping: {dst}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            content = _auto_decode(src)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"âŒ Decode failed for {src}: {e}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            trimmed = summarize(content, prompt_text, gemini)\n",
    "            dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "            dst.write_text(trimmed, encoding=\"utf-8\")\n",
    "            logging.info(f\"âœ… Written: {dst}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"âŒ Summarization failed for {book_name}: {e}\")\n",
    "\n",
    "    print(f\"\\nğŸ‰ All done! Outputs saved to {output_root}\")\n",
    "\n",
    "prompt_10000 = \"\"\"ä½ æ˜¯ä¸€ä½èµ„æ·±ä¸­æ–‡å°è¯´ç¼–è¾‘ï¼Œè¯·å°†ä¸‹é¢çš„ã€æ•´ä¹¦ç»†çº²ã€‘ç²¾ç‚¼ä¸ºæ€»å­—æ•° â‰¤10 000 å­—çš„å¤§çº²ã€‚\n",
    "ã€è¾“å‡ºè¦æ±‚ã€‘\n",
    "â€¢ åªç”¨ç®€ä½“ä¸­æ–‡ï¼Œä»¥ç« èŠ‚ï¼šå¤§çº²æƒ…èŠ‚çš„æ ¼å¼è¾“å‡ºï¼Œä¸è¦ç« èŠ‚è¿™ä¸¤ä¸ªå­—ï¼›\n",
    "â€¢ ä¿æŒæƒ…èŠ‚å®Œæ•´ï¼Œçªå‡ºä¸»è¦äººç‰©ã€å†²çªã€è½¬æŠ˜ã€ç»“å±€ï¼›\n",
    "â€¢ ä¸å¾—è¾“å‡ºä»»ä½•é¢å¤–è§£é‡Šæˆ–æ³¨é‡Šã€‚\n",
    "â€¢ æ¯ä¸ªæ®µè½è¦ç²¾ç®€ï¼Œå¿…é¡»æ¶µç›–ä»ç¬¬ä¸€ç« åˆ°æœ€åä¸€ç« çš„å…¨éƒ¨ç»†çº²å†…å®¹ã€‚\n",
    "\n",
    "ã€æ•´ä¹¦ç»†çº²ã€‘ï¼š\n",
    "\"\"\"\n",
    "\n",
    "prompt_10000 = \"\"\"ä½ æ˜¯ä¸€ä½èµ„æ·±ä¸­æ–‡å°è¯´ç¼–è¾‘ï¼Œè¯·å°†ä¸‹é¢çš„ã€æ•´ä¹¦ç»†çº²ã€‘ç²¾ç‚¼ä¸ºæ€»å­—æ•° â‰¤10000 å­—çš„å¤§çº²ã€‚\n",
    "ã€è¾“å‡ºè¦æ±‚ã€‘\n",
    "â€¢ åªç”¨ç®€ä½“ä¸­æ–‡ï¼Œä»¥ç¬¬å‡ ç« èŠ‚ï¼šå¤§çº²æƒ…èŠ‚çš„æ ¼å¼è¾“å‡ºï¼Œä¸è¦ç« èŠ‚è¿™ä¸¤ä¸ªå­—ï¼Œä¿ç•™ç« èŠ‚å·ï¼›\n",
    "â€¢ ä¿æŒæƒ…èŠ‚å®Œæ•´ï¼Œçªå‡ºä¸»è¦äººç‰©ã€å†²çªã€è½¬æŠ˜ã€ç»“å±€ï¼›\n",
    "â€¢ ä¸å¾—è¾“å‡ºä»»ä½•é¢å¤–è§£é‡Šæˆ–æ³¨é‡Šã€‚\n",
    "â€¢ æ¯ä¸ªæ®µè½è¦ç²¾ç®€ï¼Œå¿…é¡»æ¶µç›–ä»ç¬¬ä¸€ç« åˆ°æœ€åä¸€ç« çš„å…¨éƒ¨ç»†çº²å†…å®¹ã€‚\n",
    "ä¸å¾—è¶…è¿‡10000å­—ï¼ŒåŠæ¯ç« åœ¨25å­—ä»¥å†…ã€‚\n",
    "ã€æ•´ä¹¦ç»†çº²ã€‘ï¼š\n",
    "\"\"\"\n",
    "prompt_1000 = \"\"\"ä½ æ˜¯ä¸€ä½èµ„æ·±ä¸­æ–‡å°è¯´ç¼–è¾‘ï¼Œè¯·å°†ä¸‹é¢çš„ã€æ•´ä¹¦ç»†çº²ã€‘ç²¾ç‚¼ä¸ºæ€»å­—æ•° â‰¤1000 å­—çš„å¤§çº²ã€‚\n",
    "ã€è¾“å‡ºè¦æ±‚ã€‘\n",
    "â€¢ åªç”¨ç®€ä½“ä¸­æ–‡ï¼Œä»¥ç¬¬å‡ ç« èŠ‚ï¼šå¤§çº²æƒ…èŠ‚çš„æ ¼å¼è¾“å‡ºï¼Œä¸è¦ç« èŠ‚è¿™ä¸¤ä¸ªå­—ï¼Œä¿ç•™ç« èŠ‚å·ï¼›\n",
    "â€¢ ä¿æŒæƒ…èŠ‚å®Œæ•´ï¼Œçªå‡ºä¸»è¦äººç‰©ã€å†²çªã€è½¬æŠ˜ã€ç»“å±€ï¼›\n",
    "â€¢ ä¸å¾—è¾“å‡ºä»»ä½•é¢å¤–è§£é‡Šæˆ–æ³¨é‡Šã€‚\n",
    "â€¢ æ¯ä¸ªæ®µè½è¦ç²¾ç®€ï¼Œå¿…é¡»æ¶µç›–ä»ç¬¬ä¸€ç« åˆ°æœ€åä¸€ç« çš„å…¨éƒ¨ç»†çº²å†…å®¹ã€‚\n",
    "æ€»å­—æ•°å¿…é¡»ä¸å¾—è¶…è¿‡1000å­—ï¼Œå³æ¯ç« åœ¨5å­—ä»¥å†…ï¼Œéå¸¸éå¸¸ç®€çŸ­ã€‚200ç« æ€»ç»“å®Œå³åœæ­¢è¾“å‡ºã€‚\n",
    "ã€æ•´ä¹¦ç»†çº²ã€‘ï¼š\n",
    "\"\"\"\n",
    "\n",
    "prompt_5000 = \"\"\"ä½ æ˜¯ä¸€ä½èµ„æ·±ä¸­æ–‡å°è¯´ç¼–è¾‘ï¼Œè¯·å°†ä¸‹é¢çš„ã€æ•´ä¹¦ç»†çº²ã€‘ç²¾ç‚¼ä¸ºæ€»å­—æ•° â‰¤5000 å­—çš„å¤§çº²ã€‚\n",
    "ã€è¾“å‡ºè¦æ±‚ã€‘\n",
    "â€¢ åªç”¨ç®€ä½“ä¸­æ–‡ï¼Œä»¥ç¬¬å‡ ç« èŠ‚ï¼šå¤§çº²æƒ…èŠ‚çš„æ ¼å¼è¾“å‡ºï¼Œä¸è¦ç« èŠ‚è¿™ä¸¤ä¸ªå­—ï¼Œä¿ç•™ç« èŠ‚å·ï¼›\n",
    "â€¢ ä¿æŒæƒ…èŠ‚å®Œæ•´ï¼Œçªå‡ºä¸»è¦äººç‰©ã€å†²çªã€è½¬æŠ˜ã€ç»“å±€ï¼›\n",
    "â€¢ ä¸å¾—è¾“å‡ºä»»ä½•é¢å¤–è§£é‡Šæˆ–æ³¨é‡Šã€‚\n",
    "â€¢ æ¯ä¸ªæ®µè½è¦ç²¾ç®€ï¼Œå¿…é¡»æ¶µç›–ä»ç¬¬ä¸€ç« åˆ°æœ€åä¸€ç« çš„å…¨éƒ¨ç»†çº²å†…å®¹ã€‚\n",
    "ä¸å¾—è¶…è¿‡5000å­—ï¼Œå³æ¯ç« åœ¨15ä¸ªå­—ä»¥å†…ã€‚\n",
    "ã€æ•´ä¹¦ç»†çº²ã€‘ï¼š\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# summarize_outlines_batch(\n",
    "#     input_dir=\"/content/json_results/json_gemini_normalized/30000_summary_gathered\",\n",
    "#     input_filename=\"entire_section_outline.txt\",\n",
    "#     output_dir=\"/content/json_results/json_gemini_normalized/30000_outline_10000\",\n",
    "#     output_filename=\"summary_trimmed.txt\",\n",
    "#     prompt_text=prompt_10000,\n",
    "#     gemini_api_key=\"your-default-api-key\"\n",
    "# )\n",
    "\n",
    "# summarize_outlines_batch(\n",
    "#     input_dir=\"/content/json_results/json_gemini_normalized/30000_summary_gathered\",\n",
    "#     input_filename=\"entire_section_outline.txt\",\n",
    "#     output_dir=\"/content/json_results/json_gemini_normalized/30000_outline_5000\",\n",
    "#     output_filename=\"summary_trimmed.txt\",\n",
    "#     prompt_text=prompt_5000,\n",
    "#     gemini_api_key=\"your-default-api-key\"\n",
    "# )\n",
    "\n",
    "summarize_outlines_batch(\n",
    "    input_dir=\"/content/json_results/json_gemini_normalized/30000_summary_gathered\",\n",
    "    input_filename=\"entire_section_outline.txt\",\n",
    "    output_dir=\"/content/json_results/json_gemini_normalized/30000_outline_1000\",\n",
    "    output_filename=\"summary_trimmed.txt\",\n",
    "    prompt_text=prompt_1000,\n",
    "    gemini_api_key=\"your-default-api-key\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "73f9d43f-402c-4592-b21b-65171f892a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /content/json_results/json_gemini_normalized/30000_outline_1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2814e752-42a5-493d-93ac-83f2b322fc26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623fb7d8bcfc426eadca7f4fbc11cef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ğŸ“š Summarizing Outlines:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 11:02:54,609 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šå¥‹æ–—åœ¨æ–°æ˜æœã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šéšè½»é£å»_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:03:28,911 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šåæ­£æˆ‘æ˜¯è¶…èƒ½åŠ›è€…ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šåƒä¹¦å¦–_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:03:43,714 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šå¤©å¯æ±—ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šè¥¿é£ç´§_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:04:17,004 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šå´©åä¸–ç•Œçš„ä¼ å¥‡å¤§å†’é™©ã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå›½ç‹é™›ä¸‹_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:04:36,075 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šå…¨çƒè¿›åŒ–ã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå’¬ç‹—_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:04:51,199 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šæ­¦æ—åŠä¾ ä¼ ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šæ–‡æŠ„å…¬_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:05:11,754 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/å›½å®´å¤§å¨åœ¨å…«é›¶/summary_trimmed.txt\n",
      "2025-05-03 11:05:35,318 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šæœç¥è®°ã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šæ ‘ä¸‹é‡ç‹_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:06:06,104 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/é‡ç”Ÿå…«é›¶ï¼šæ¯’å¦»ä¸å¥½æƒ¹/summary_trimmed.txt\n",
      "2025-05-03 11:06:23,196 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šçªƒæ˜ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå¤§çˆ†ç‚¸(ç°ç†ŠçŒ«)_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:06:49,208 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šèœ€å±±ã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šæµæµªçš„è›¤èŸ†_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:07:04,425 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šé™ˆäºŒç‹—çš„å¦–å­½äººç”Ÿã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šçƒ½ç«æˆè¯¸ä¾¯_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:07:35,197 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šè´©ç½ªã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šä¸‰å¤©ä¸¤è§‰_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:08:04,576 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šé‡ç”Ÿä¹‹å‡ºäººå¤´åœ°ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šé—¹é—¹ä¸çˆ±é—¹_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:08:24,032 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/å…«é›¶å–œäº‹ï¼šå½“å®¶è‚¥å¦»å¤§ç¿»èº«/summary_trimmed.txt\n",
      "2025-05-03 11:08:39,889 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šè‚†è™éŸ©å¨±ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå§¬å‰_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:09:05,604 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/å…«é›¶å¹´ä»£å¥½æ—¶å…‰/summary_trimmed.txt\n",
      "2025-05-03 11:09:25,242 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šé£Ÿç‰©é“¾é¡¶ç«¯çš„ç”·äººã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šç†Šç‹¼ç‹—_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:10:02,583 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šé«˜æ‰‹å¯‚å¯2ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå…°å¸é­…æ™¨_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:10:25,086 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šé»‘é¾™æ³•å…¸ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šæ¬¢å£°_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:10:44,209 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šè¯›ä»™ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šè§é¼_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:11:02,240 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šå›åˆ°è¿‡å»å˜æˆçŒ«ã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šé™ˆè¯æ‡’è°ƒ_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:11:22,115 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šç¥æ¸¸ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå¾å…¬å­èƒœæ²»_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:11:41,631 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šè€å­æ˜¯ç™è›¤èŸ†ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ ä½œè€…ï¼šçƒ½ç«æˆè¯¸ä¾¯_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:12:01,624 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šæœªæ¥å¤©ç‹ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šé™ˆè¯æ‡’è°ƒ_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:12:30,932 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šå¤§ç”»å®¶ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šé†›çŸ³_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:13:00,969 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šè¶…çº§æƒŠæ‚šç›´æ’­ã€‹ä½œè€…ï¼šå®‡æ–‡é•¿å¼“_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:13:25,945 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šäººé“å¤©å ‚ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šè†æŸ¯å®ˆ_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:13:57,968 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šé“ç¼˜æµ®å›¾ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šçƒŸé›¨æ±Ÿå—_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:14:18,628 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šé‡æ´»äº†ã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼š å°è°•_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:14:45,073 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šé›…éªšã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šè´¼é“ä¸‰ç—´_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:15:09,569 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/å…«é›¶ç¦æ˜Ÿä¿åª³å¦‡/summary_trimmed.txt\n",
      "2025-05-03 11:15:30,190 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šä¸Šå“å¯’å£«ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šè´¼é“ä¸‰ç—´_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:15:49,271 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šåå·é£äº‘å¿—ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šçŸ¥ç§‹_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:16:12,023 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šå²ä¸Šç¬¬ä¸€æ··ä¹±ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå¼ å°èŠ±_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:16:37,079 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šéšæ³¢é€æµä¹‹ä¸€ä»£å†›å¸ˆã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šéšæ³¢é€æµ_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:16:55,972 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/é‡ç”Ÿå…«é›¶ï¼šä½³å¦»è‡´å¯Œå¿™/summary_trimmed.txt\n",
      "2025-05-03 11:17:16,402 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/é‡å›å…«é›¶è¿‡å¥½æ—¥å­/summary_trimmed.txt\n",
      "2025-05-03 11:17:35,559 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šç»å¯¹ä¸€ç•ªã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šæµ·åº•æ¼«æ­¥è€…_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:18:00,047 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_10000/ã€Šæˆ‘çš„å¥³å‹æ˜¯æ¶å¥³ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šæµ·åº•æ¼«æ­¥è€…_utf8/summary_trimmed.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ‰ All done! Outputs saved to /content/json_results/json_gemini_normalized/100000_outline_10000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14813ec8acc5460d8d63b928778b5873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ğŸ“š Summarizing Outlines:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 11:18:32,586 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šå¥‹æ–—åœ¨æ–°æ˜æœã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šéšè½»é£å»_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:18:58,143 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šåæ­£æˆ‘æ˜¯è¶…èƒ½åŠ›è€…ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šåƒä¹¦å¦–_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:19:37,091 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šå¤©å¯æ±—ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šè¥¿é£ç´§_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:19:53,281 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šå´©åä¸–ç•Œçš„ä¼ å¥‡å¤§å†’é™©ã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå›½ç‹é™›ä¸‹_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:20:05,627 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šå…¨çƒè¿›åŒ–ã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå’¬ç‹—_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:20:21,087 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šæ­¦æ—åŠä¾ ä¼ ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šæ–‡æŠ„å…¬_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:20:38,917 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/å›½å®´å¤§å¨åœ¨å…«é›¶/summary_trimmed.txt\n",
      "2025-05-03 11:20:58,092 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šæœç¥è®°ã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šæ ‘ä¸‹é‡ç‹_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:21:17,746 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/é‡ç”Ÿå…«é›¶ï¼šæ¯’å¦»ä¸å¥½æƒ¹/summary_trimmed.txt\n",
      "2025-05-03 11:21:42,315 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šçªƒæ˜ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå¤§çˆ†ç‚¸(ç°ç†ŠçŒ«)_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:21:54,308 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šèœ€å±±ã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šæµæµªçš„è›¤èŸ†_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:22:05,647 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šé™ˆäºŒç‹—çš„å¦–å­½äººç”Ÿã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šçƒ½ç«æˆè¯¸ä¾¯_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:22:23,980 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šè´©ç½ªã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šä¸‰å¤©ä¸¤è§‰_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:22:42,816 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šé‡ç”Ÿä¹‹å‡ºäººå¤´åœ°ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šé—¹é—¹ä¸çˆ±é—¹_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:23:06,882 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/å…«é›¶å–œäº‹ï¼šå½“å®¶è‚¥å¦»å¤§ç¿»èº«/summary_trimmed.txt\n",
      "2025-05-03 11:23:22,996 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šè‚†è™éŸ©å¨±ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå§¬å‰_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:23:48,014 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/å…«é›¶å¹´ä»£å¥½æ—¶å…‰/summary_trimmed.txt\n",
      "2025-05-03 11:24:14,563 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šé£Ÿç‰©é“¾é¡¶ç«¯çš„ç”·äººã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šç†Šç‹¼ç‹—_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:24:42,968 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šé«˜æ‰‹å¯‚å¯2ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå…°å¸é­…æ™¨_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:24:55,921 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šé»‘é¾™æ³•å…¸ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šæ¬¢å£°_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:25:27,981 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šè¯›ä»™ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šè§é¼_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:25:45,859 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šå›åˆ°è¿‡å»å˜æˆçŒ«ã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šé™ˆè¯æ‡’è°ƒ_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:26:24,057 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šç¥æ¸¸ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå¾å…¬å­èƒœæ²»_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:26:41,643 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šè€å­æ˜¯ç™è›¤èŸ†ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ ä½œè€…ï¼šçƒ½ç«æˆè¯¸ä¾¯_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:27:00,788 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šæœªæ¥å¤©ç‹ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šé™ˆè¯æ‡’è°ƒ_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:27:16,126 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šå¤§ç”»å®¶ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šé†›çŸ³_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:27:46,927 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šè¶…çº§æƒŠæ‚šç›´æ’­ã€‹ä½œè€…ï¼šå®‡æ–‡é•¿å¼“_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:28:12,887 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šäººé“å¤©å ‚ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šè†æŸ¯å®ˆ_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:28:29,394 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šé“ç¼˜æµ®å›¾ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šçƒŸé›¨æ±Ÿå—_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:28:43,943 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šé‡æ´»äº†ã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼š å°è°•_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:29:14,119 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šé›…éªšã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šè´¼é“ä¸‰ç—´_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:29:31,574 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/å…«é›¶ç¦æ˜Ÿä¿åª³å¦‡/summary_trimmed.txt\n",
      "2025-05-03 11:29:50,658 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šä¸Šå“å¯’å£«ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šè´¼é“ä¸‰ç—´_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:30:04,476 - WARNING - Gemini retry 1: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 4. Meaning that the model was reciting from copyrighted material.\n",
      "2025-05-03 11:30:20,533 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šåå·é£äº‘å¿—ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šçŸ¥ç§‹_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:30:37,982 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šå²ä¸Šç¬¬ä¸€æ··ä¹±ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå¼ å°èŠ±_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:30:54,421 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šéšæ³¢é€æµä¹‹ä¸€ä»£å†›å¸ˆã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šéšæ³¢é€æµ_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:31:09,309 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/é‡ç”Ÿå…«é›¶ï¼šä½³å¦»è‡´å¯Œå¿™/summary_trimmed.txt\n",
      "2025-05-03 11:31:30,619 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/é‡å›å…«é›¶è¿‡å¥½æ—¥å­/summary_trimmed.txt\n",
      "2025-05-03 11:31:49,911 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šç»å¯¹ä¸€ç•ªã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šæµ·åº•æ¼«æ­¥è€…_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:32:06,969 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_5000/ã€Šæˆ‘çš„å¥³å‹æ˜¯æ¶å¥³ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šæµ·åº•æ¼«æ­¥è€…_utf8/summary_trimmed.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ‰ All done! Outputs saved to /content/json_results/json_gemini_normalized/100000_outline_5000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016a54e91bff4c59ba5c4e0bca4d0a65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ğŸ“š Summarizing Outlines:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-03 11:32:19,748 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šå¥‹æ–—åœ¨æ–°æ˜æœã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šéšè½»é£å»_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:32:31,299 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šåæ­£æˆ‘æ˜¯è¶…èƒ½åŠ›è€…ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šåƒä¹¦å¦–_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:33:01,650 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šå¤©å¯æ±—ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šè¥¿é£ç´§_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:33:14,863 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šå´©åä¸–ç•Œçš„ä¼ å¥‡å¤§å†’é™©ã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå›½ç‹é™›ä¸‹_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:33:28,179 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šå…¨çƒè¿›åŒ–ã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå’¬ç‹—_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:33:53,035 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šæ­¦æ—åŠä¾ ä¼ ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šæ–‡æŠ„å…¬_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:34:08,834 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/å›½å®´å¤§å¨åœ¨å…«é›¶/summary_trimmed.txt\n",
      "2025-05-03 11:34:26,689 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šæœç¥è®°ã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šæ ‘ä¸‹é‡ç‹_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:34:44,217 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/é‡ç”Ÿå…«é›¶ï¼šæ¯’å¦»ä¸å¥½æƒ¹/summary_trimmed.txt\n",
      "2025-05-03 11:34:57,470 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šçªƒæ˜ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå¤§çˆ†ç‚¸(ç°ç†ŠçŒ«)_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:35:12,429 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šèœ€å±±ã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šæµæµªçš„è›¤èŸ†_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:35:27,480 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šé™ˆäºŒç‹—çš„å¦–å­½äººç”Ÿã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šçƒ½ç«æˆè¯¸ä¾¯_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:35:48,475 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šè´©ç½ªã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šä¸‰å¤©ä¸¤è§‰_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:36:05,356 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šé‡ç”Ÿä¹‹å‡ºäººå¤´åœ°ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šé—¹é—¹ä¸çˆ±é—¹_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:36:16,768 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/å…«é›¶å–œäº‹ï¼šå½“å®¶è‚¥å¦»å¤§ç¿»èº«/summary_trimmed.txt\n",
      "2025-05-03 11:36:27,850 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šè‚†è™éŸ©å¨±ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå§¬å‰_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:36:38,329 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/å…«é›¶å¹´ä»£å¥½æ—¶å…‰/summary_trimmed.txt\n",
      "2025-05-03 11:36:49,381 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šé£Ÿç‰©é“¾é¡¶ç«¯çš„ç”·äººã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šç†Šç‹¼ç‹—_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:37:19,990 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šé«˜æ‰‹å¯‚å¯2ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå…°å¸é­…æ™¨_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:37:34,962 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šé»‘é¾™æ³•å…¸ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šæ¬¢å£°_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:37:46,342 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šè¯›ä»™ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šè§é¼_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:37:58,216 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šå›åˆ°è¿‡å»å˜æˆçŒ«ã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šé™ˆè¯æ‡’è°ƒ_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:38:10,330 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šç¥æ¸¸ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå¾å…¬å­èƒœæ²»_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:38:24,718 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šè€å­æ˜¯ç™è›¤èŸ†ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ ä½œè€…ï¼šçƒ½ç«æˆè¯¸ä¾¯_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:38:40,800 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šæœªæ¥å¤©ç‹ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šé™ˆè¯æ‡’è°ƒ_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:39:00,294 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šå¤§ç”»å®¶ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šé†›çŸ³_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:39:34,520 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šè¶…çº§æƒŠæ‚šç›´æ’­ã€‹ä½œè€…ï¼šå®‡æ–‡é•¿å¼“_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:40:03,421 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šäººé“å¤©å ‚ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šè†æŸ¯å®ˆ_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:40:23,441 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šé“ç¼˜æµ®å›¾ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šçƒŸé›¨æ±Ÿå—_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:40:38,157 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šé‡æ´»äº†ã€‹ï¼ˆç²¾æ ¡ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼š å°è°•_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:40:49,381 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šé›…éªšã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šè´¼é“ä¸‰ç—´_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:41:15,703 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/å…«é›¶ç¦æ˜Ÿä¿åª³å¦‡/summary_trimmed.txt\n",
      "2025-05-03 11:41:38,607 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šä¸Šå“å¯’å£«ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šè´¼é“ä¸‰ç—´_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:41:47,160 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šåå·é£äº‘å¿—ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šçŸ¥ç§‹_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:42:05,013 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šå²ä¸Šç¬¬ä¸€æ··ä¹±ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šå¼ å°èŠ±_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:42:30,366 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šéšæ³¢é€æµä¹‹ä¸€ä»£å†›å¸ˆã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šéšæ³¢é€æµ_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:42:49,709 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/é‡ç”Ÿå…«é›¶ï¼šä½³å¦»è‡´å¯Œå¿™/summary_trimmed.txt\n",
      "2025-05-03 11:42:59,531 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/é‡å›å…«é›¶è¿‡å¥½æ—¥å­/summary_trimmed.txt\n",
      "2025-05-03 11:43:11,520 - WARNING - Gemini retry 1: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 4. Meaning that the model was reciting from copyrighted material.\n",
      "2025-05-03 11:43:29,176 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šç»å¯¹ä¸€ç•ªã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šæµ·åº•æ¼«æ­¥è€…_utf8/summary_trimmed.txt\n",
      "2025-05-03 11:43:41,364 - INFO - âœ… Written: /content/json_results/json_gemini_normalized/100000_outline_1000/ã€Šæˆ‘çš„å¥³å‹æ˜¯æ¶å¥³ã€‹ï¼ˆæ ¡å¯¹ç‰ˆå…¨æœ¬ï¼‰ä½œè€…ï¼šæµ·åº•æ¼«æ­¥è€…_utf8/summary_trimmed.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ‰ All done! Outputs saved to /content/json_results/json_gemini_normalized/100000_outline_1000\n"
     ]
    }
   ],
   "source": [
    "summarize_outlines_batch(\n",
    "    input_dir=\"/content/json_results/json_gemini_normalized/100000_summary_gathered\",\n",
    "    input_filename=\"entire_section_outline.txt\",\n",
    "    output_dir=\"/content/json_results/json_gemini_normalized/100000_outline_10000\",\n",
    "    output_filename=\"summary_trimmed.txt\",\n",
    "    prompt_text=prompt_10000,\n",
    "    gemini_api_key=\"your-default-api-key\"\n",
    ")\n",
    "\n",
    "summarize_outlines_batch(\n",
    "    input_dir=\"/content/json_results/json_gemini_normalized/100000_summary_gathered\",\n",
    "    input_filename=\"entire_section_outline.txt\",\n",
    "    output_dir=\"/content/json_results/json_gemini_normalized/100000_outline_5000\",\n",
    "    output_filename=\"summary_trimmed.txt\",\n",
    "    prompt_text=prompt_5000,\n",
    "    gemini_api_key=\"your-default-api-key\"\n",
    ")\n",
    "\n",
    "summarize_outlines_batch(\n",
    "    input_dir=\"/content/json_results/json_gemini_normalized/100000_summary_gathered\",\n",
    "    input_filename=\"entire_section_outline.txt\",\n",
    "    output_dir=\"/content/json_results/json_gemini_normalized/100000_outline_1000\",\n",
    "    output_filename=\"summary_trimmed.txt\",\n",
    "    prompt_text=prompt_1000,\n",
    "    gemini_api_key=\"your-default-api-key\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7d56ba92-a3cc-4d05-ad55-aea3ca93e4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /content/json_results/json_gemini_normalized/100000_outline_10000\n",
    "!rm -rf /content/json_results/json_gemini_normalized/100000_outline_1000\n",
    "!rm -rf /content/json_results/json_gemini_normalized/100000_outline_5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578292de-cbbd-4437-ae51-9ce1d19290c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
